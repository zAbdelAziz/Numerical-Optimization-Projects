###################
# Approx Solutions #
###################
Running: Rosenbrock
===================
	- Starting Point : [1.2 1.2]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Polak-Ribiere Method
			------------
			Iteration 0:
				X = [1.085515305178769, 1.247536897504648]
				Current Gradient = [-29.87317583941218, 13.838683944306096]
				Previous Gradient = [115.59999998800308, -47.9999999960512]
				|| Gradient || = 32.92287666718744
				||X optimum - X|| = 0.26189193008957823
				beta" = 0.3319966966380586
				alpha = 0.0009903520314283058
			Iteration 1:
				X = [1.085515305178769, 1.247536897504648]
				Current Gradient = [-29.87317583941218, 13.838683944306096]
				Previous Gradient = [-29.87317583941218, 13.838683944306096]
				|| Gradient || = 32.92287666718744
				||X optimum - X|| = 0.26189193008957823
				beta" = 0.0
				alpha = 1.0983676256209093e-17
			Iteration 2:
				X = [1.1151002655565458, 1.2338317287481102]
				Current Gradient = [4.519711806923871, -1.9233746990764828]
				Previous Gradient = [-29.87317583941218, 13.838683944306096]
				|| Gradient || = 4.911941067510337
				||X optimum - X|| = 0.2606249191856319
				beta" = 0.17138073251723615
				alpha = 0.0009903520314283058
			Iteration 3:
				X = [1.1151002655565458, 1.2338317287481102]
				Current Gradient = [4.519711806923871, -1.9233746990764828]
				Previous Gradient = [4.519711806923871, -1.9233746990764828]
				|| Gradient || = 4.911941067510337
				||X optimum - X|| = 0.2606249191856319
				beta" = 0.0
				alpha = 1.5983352577618037e-16
			Iteration 4:
				X = [1.1106241597870883, 1.2357365467885384]
				Current Gradient = [-0.7785455378491596, 0.4501044971157511]
				Previous Gradient = [4.519711806923871, -1.9233746990764828]
				|| Gradient || = 0.8992926180218875
				||X optimum - X|| = 0.2604024274471803
				beta" = 0.2152448604406954
				alpha = 0.0009903520314283058
			Iteration 5:
				X = [1.1106241597870883, 1.2357365467885384]
				Current Gradient = [-0.7785455378491596, 0.4501044971157511]
				Previous Gradient = [-0.7785455378491596, 0.4501044971157511]
				|| Gradient || = 0.8992926180218875
				||X optimum - X|| = 0.2604024274471803
				beta" = 0.0
				alpha = 4.877732109868785e-16
			Iteration 6:
				X = [1.1113951939420565, 1.2352907848854648]
				Current Gradient = [0.18210987090538922, 0.018301553591192066]
				Previous Gradient = [-0.7785455378491596, 0.4501044971157511]
				|| Gradient || = 0.18302718908683704
				||X optimum - X|| = 0.26032795217841376
				beta" = 0.20654945834807178
				alpha = 0.0009903520314283058
			Iteration 7:
				X = [1.1111987203294413, 1.2342644966479548]
				Current Gradient = [0.4437924135706692, -0.09961988275877104]
				Previous Gradient = [0.18210987090538922, 0.018301553591192066]
				|| Gradient || = 0.4548360445080745
				||X optimum - X|| = 0.25931642792662585
				beta" = 3.8174342610035183
				alpha = 0.009223372036854787
			Iteration 8:
				X = [1.1101830092938485, 1.2336355698567028]
				Current Gradient = [-0.28110619164530004, 0.2258511463725313]
				Previous Gradient = [0.4437924135706692, -0.09961988275877104]
				|| Gradient || = 0.3605959391051301
				||X optimum - X|| = 0.25831352082172265
				beta" = 1.3403281320405336
				alpha = 0.0019342813113834097
			Iteration 9:
				X = [1.1091609497663293, 1.2320357849530879]
				Current Gradient = [-0.579285706533636, 0.3595544932786729]
				Previous Gradient = [-0.28110619164530004, 0.2258511463725313]
				|| Gradient || = 0.6818000905185163
				||X optimum - X|| = 0.2564307283706122
				beta" = 1.6981137877510428
				alpha = 0.002417851639229262
			Iteration 10:
				X = [1.1088929925819628, 1.2291670119745033]
				Current Gradient = [0.4292106385844069, -0.0953314045672865]
				Previous Gradient = [-0.579285706533636, 0.3595544932786729]
				|| Gradient || = 0.4396701592908097
				||X optimum - X|| = 0.25372268958604693
				beta" = 1.0244613855548936
				alpha = 0.0019342813113834097
			Iteration 11:
				X = [1.0960322904032158, 1.1970998366457644]
				Current Gradient = [2.027675331132961, -0.8373889920816613]
				Previous Gradient = [0.4292106385844069, -0.0953314045672865]
				|| Gradient || = 2.193783848182109
				||X optimum - X|| = 0.21924996329731636
				beta" = 19.98117685470996
				alpha = 0.022517998136852502
			Iteration 12:
				X = [0.9968661138480794, 0.9933210259014202]
				Current Gradient = [0.16161366765421945, -0.0842046074327943]
				Previous Gradient = [2.027675331132961, -0.8373889920816613]
				|| Gradient || = 0.18223444648463005
				||X optimum - X|| = 0.007377664767573733
				beta" = -0.07584175358065205
				alpha = 0.00737869762948383
			Iteration 13:
				X = [0.9979278496177104, 0.9960181752170931]
				Current Gradient = [-0.06728605925312575, 0.031636434894010315]
				Previous Gradient = [0.16161366765421945, -0.0842046074327943]
				|| Gradient || = 0.07435238921929882
				||X optimum - X|| = 0.004488734321453458
				beta" = 0.5741314784815004
				alpha = 0.0012379400392853823
			Iteration 14:
				X = [0.9979278496177136, 0.9960181752171]
				Current Gradient = [-0.06728605925329643, 0.03163643489409925]
				Previous Gradient = [-0.06728605925312575, 0.031636434894010315]
				|| Gradient || = 0.07435238921949112
				||X optimum - X|| = 0.004488734321445866
				beta" = 2.5863737055052906e-12
				alpha = 5.678427533559478e-15
			Iteration 15:
				X = [0.9980111457245509, 0.9959790112076483]
				Current Gradient = [0.014879026926254244, -0.009447156556735092]
				Previous Gradient = [-0.06728605925329643, 0.03163643489409925]
				|| Gradient || = 0.017624817992809506
				||X optimum - X|| = 0.004485966138658454
				beta" = 0.2913492616214731
				alpha = 0.0012379400392853823
			Iteration 16:
				X = [0.9980111457245509, 0.9959790112076483]
				Current Gradient = [0.014879026926254244, -0.009447156556735092]
				Previous Gradient = [0.014879026926254244, -0.009447156556735092]
				|| Gradient || = 0.017624817992809506
				||X optimum - X|| = 0.004485966138658454
				beta" = 0.0
				alpha = 1.1090678776483354e-14
			Iteration 17:
				X = [0.9979927263813733, 0.9959907062210073]
				Current Gradient = [-0.004503288179689341, 0.00024486217614252856]
				Previous Gradient = [0.014879026926254244, -0.009447156556735092]
				|| Gradient || = 0.004509940344908677
				||X optimum - X|| = 0.0044837020403127445
				beta" = 0.2886268048765956
				alpha = 0.0012379400392853823
			Iteration 18:
				X = [0.9979928322566559, 0.9959919646636146]
				Current Gradient = [-0.004921082613989383, 0.00045428559058050097]
				Previous Gradient = [-0.004503288179689341, 0.00024486217614252856]
				|| Gradient || = 0.00494200662600908
				||X optimum - X|| = 0.0044825293761039525
				beta" = 0.10576132246078464
				alpha = 0.0005070602400912927
			Iteration 19:
				X = [0.9980004814352499, 0.9959916678630585]
				Current Gradient = [0.0013075641370001753, -0.0026586163864958474]
				Previous Gradient = [-0.004921082613989383, 0.00045428559058050097]
				|| Gradient || = 0.00296276307910593
				||X optimum - X|| = 0.0044793750692276825
				beta" = 0.6723202949507954
				alpha = 0.0015474250491067279
			Iteration 20:
				X = [0.9980237223331253, 0.9960208328967192]
				Current Gradient = [0.008230297868509767, -0.006103488589779494]
				Previous Gradient = [0.0013075641370001753, -0.0026586163864958474]
				|| Gradient || = 0.010246481150617753
				||X optimum - X|| = 0.004442909435541092
				beta" = 8.886102678882944
				alpha = 0.011529215046068483
			Iteration 21:
				X = [0.9980951668968698, 0.9962317333231031]
				Current Gradient = [-0.01888934280501866, 0.007554228042745011]
				Previous Gradient = [0.008230297868509767, -0.006103488589779494]
				|| Gradient || = 0.02034388441097976
				||X optimum - X|| = 0.0042223480314858034
				beta" = 5.861924864356622
				alpha = 0.00737869762948383
			Iteration 22:
				X = [0.9987928936638886, 0.997707410934068]
				Current Gradient = [-0.050422791010352394, 0.024033300117534497]
				Previous Gradient = [-0.01888934280501866, 0.007554228042745011]
				|| Gradient || = 0.0558574736970189
				||X optimum - X|| = 0.002590959345862318
				beta" = 4.7986892508178975
				alpha = 0.009223372036854787
			Iteration 23:
				X = [0.9997925122003024, 0.9995056270816417]
				Current Gradient = [0.031354579698281274, -0.015888074030491726]
				Previous Gradient = [-0.050422791010352394, 0.024033300117534497]
				|| Gradient || = 0.03515025696142573
				||X optimum - X|| = 0.0005361490179320013
				beta" = 1.0250993678056237
				alpha = 0.002417851639229262
			Iteration 24:
				X = [0.9998943993051217, 0.9997076800859589]
				Current Gradient = [0.03223724238759458, -0.016225935158709362]
				Previous Gradient = [0.031354579698281274, -0.015888074030491726]
				|| Gradient || = 0.03609045259526632
				||X optimum - X|| = 0.00031080932885578006
				beta" = 0.02746710613744753
				alpha = 0.0002596148429267419
			Iteration 25:
				X = [0.9998678360293232, 0.9997542303833267]
				Current Gradient = [-0.007679690314332266, 0.003708171473144671]
				Previous Gradient = [0.03223724238759458, -0.016225935158709362]
				|| Gradient || = 0.008528081788907325
				||X optimum - X|| = 0.000279052001649913
				beta" = 0.292101881364053
				alpha = 0.0012379400392853823
			Iteration 26:
				X = [0.9998678360293232, 0.9997542303833267]
				Current Gradient = [-0.007679690314332266, 0.003708171473144671]
				Previous Gradient = [-0.007679690314332266, 0.003708171473144671]
				|| Gradient || = 0.008528081788907325
				||X optimum - X|| = 0.000279052001649913
				beta" = 0.0
				alpha = 7.098034416949348e-15
			Iteration 27:
				X = [0.9998773430254526, 0.9997496398893875]
				Current Gradient = [0.0017789206344756506, -0.0010122412502713478]
				Previous Gradient = [-0.007679690314332266, 0.003708171473144671]
				|| Gradient || = 0.002046751321610457
				||X optimum - X|| = 0.00027879189082725026
				beta" = 0.29705562499737925
				alpha = 0.0012379400392853823
			Iteration 28:
				X = [0.9998773430254526, 0.9997496398893875]
				Current Gradient = [0.0017789206344756506, -0.0010122412502713478]
				Previous Gradient = [0.0017789206344756506, -0.0010122412502713478]
				|| Gradient || = 0.002046751321610457
				||X optimum - X|| = 0.00027879189082725026
				beta" = 0.0
				alpha = 1.0328999512347717e-13
			Iteration 29:
				X = [0.9998751408283725, 0.9997508929833606]
				Current Gradient = [-0.0004879829112001747, 0.00011914736058114626]
				Previous Gradient = [0.0017789206344756506, -0.0010122412502713478]
				|| Gradient || = 0.0005023180418388844
				||X optimum - X|| = 0.00027864694234547933
				beta" = 0.29624148589691424
				alpha = 0.0012379400392853823
			Iteration 30:
				X = [0.9998751408283725, 0.9997508929833606]
				Current Gradient = [-0.0004879829112001747, 0.00011914736058114626]
				Previous Gradient = [-0.0004879829112001747, 0.00011914736058114626]
				|| Gradient || = 0.0005023180418388844
				||X optimum - X|| = 0.00027864694234547933
				beta" = 0.0
				alpha = 2.521728396569266e-13
			Iteration 31:
				X = [0.9998757449219567, 0.9997507454860723]
				Current Gradient = [5.537134662301323e-05, -0.00015195943310779048]
				Previous Gradient = [-0.0004879829112001747, 0.00011914736058114626]
				|| Gradient || = 0.00016173328456841197
				||X optimum - X|| = 0.0002785087738884488
				beta" = 0.2825084290546225
				alpha = 0.0012379400392853823
			Iteration 32:
				X = [0.9998786472082962, 0.9997549077726419]
				Current Gradient = [0.0007177264316172673, -0.00048027409013378145]
				Previous Gradient = [5.537134662301323e-05, -0.00015195943310779048]
				|| Gradient || = 0.0008635939047352566
				||X optimum - X|| = 0.0002734898534967465
				beta" = 24.202122347517797
				alpha = 0.03518437208883203
			Iteration 33:
				X = [0.9998880820299066, 0.9997795774757194]
				Current Gradient = [-0.0015840394016103368, 0.000680178054854449]
				Previous Gradient = [0.0007177264316172673, -0.00048027409013378145]
				|| Gradient || = 0.001723897622296526
				||X optimum - X|| = 0.0002472078502799455
				beta" = 5.947217710098206
				alpha = 0.00737869762948383
			Iteration 34:
				X = [0.9999423212986672, 0.9998929352891951]
				Current Gradient = [-0.0034309117661159446, 0.001657873005659272]
				Previous Gradient = [-0.0015840394016103368, 0.000680178054854449]
				|| Gradient || = 0.003810472208239622
				||X optimum - X|| = 0.00012161284836386906
				beta" = 2.6775989552698043
				alpha = 0.005902958103587064
			Iteration 35:
				X = [0.999996546944327, 0.9999891881461018]
				Current Gradient = [0.001555390684351461, -0.0007811508951907439]
				Previous Gradient = [-0.0034309117661159446, 0.001657873005659272]
				|| Gradient || = 0.001740527765370207
				||X optimum - X|| = 1.1349880096105373e-05
				beta" = 0.6653646504973946
				alpha = 0.0019342813113834097
			Iteration 36:
				X = [0.9999965469443305, 0.9999891881461087]
				Current Gradient = [0.0015553906843583443, -0.0007811508951907439]
				Previous Gradient = [0.001555390684351461, -0.0007811508951907439]
				|| Gradient || = 0.0017405277653763582
				||X optimum - X|| = 1.1349880088501197e-05
				beta" = 3.5341054316826766e-12
				alpha = 2.017382717255413e-13
			Iteration 37:
				X = [0.9999946214639257, 0.9999901551640787]
				Current Gradient = [-0.0003756376291154324, 0.00018244145974480363]
				Previous Gradient = [0.0015553906843583443, -0.0007811508951907439]
				|| Gradient || = 0.00041759850890691404
				||X optimum - X|| = 1.1218263886136492e-05
				beta" = 0.29746983429587415
				alpha = 0.0012379400392853823
			Iteration 38:
				X = [0.9999946214639257, 0.9999901551640787]
				Current Gradient = [-0.0003756376291154324, 0.00018244145974480363]
				Previous Gradient = [-0.0003756376291154324, 0.00018244145974480363]
				|| Gradient || = 0.00041759850890691404
				||X optimum - X|| = 1.1218263886136492e-05
				beta" = 0.0
				alpha = 6.156563468186683e-13
			Iteration 39:
				X = [0.999995086480787, 0.9999899293124909]
				Current Gradient = [8.764217302122e-05, -4.8734645187467354e-05]
				Previous Gradient = [-0.0003756376291154324, 0.00018244145974480363]
				|| Gradient || = 0.00010028068674191356
				||X optimum - X|| = 1.1205419133732187e-05
				beta" = 0.2974343472819197
				alpha = 0.0012379400392853823
			Iteration 40:
				X = [0.999995086480787, 0.9999899293124909]
				Current Gradient = [8.764217302122e-05, -4.8734645187467354e-05]
				Previous Gradient = [8.764217302122e-05, -4.8734645187467354e-05]
				|| Gradient || = 0.00010028068674191356
				||X optimum - X|| = 1.1205419133732187e-05
				beta" = 0.0
				alpha = 1.87883406621908e-12
			Iteration 41:
				X = [0.9999949779850319, 0.9999899896430594]
				Current Gradient = [-2.3502672338019954e-05, 6.729555002331972e-06]
				Previous Gradient = [8.764217302122e-05, -4.8734645187467354e-05]
				|| Gradient || = 2.4447137205769913e-05
				||X optimum - X|| = 1.1199458934159846e-05
				beta" = 0.29687610416916277
				alpha = 0.0012379400392853823
			Iteration 42:
				X = [0.9999949779850319, 0.9999899896430594]
				Current Gradient = [-2.3502672338019954e-05, 6.729555002331972e-06]
				Previous Gradient = [-2.3502672338019954e-05, 6.729555002331972e-06]
				|| Gradient || = 2.4447137205769913e-05
				||X optimum - X|| = 1.1199458934159846e-05
				beta" = 0.0
				alpha = 7.167183174969023e-12
			Iteration 43:
				X = [0.999995007079931, 0.9999899813122738]
				Current Gradient = [3.1635012159192304e-06, -6.574503519563327e-06]
				Previous Gradient = [-2.3502672338019954e-05, 6.729555002331972e-06]
				|| Gradient || = 7.296015109076531e-06
				||X optimum - X|| = 1.1193898095400038e-05
				beta" = 0.28749678454091276
				alpha = 0.0012379400392853823
			Iteration 44:
				X = [0.9999950718136185, 0.9999900648950854]
				Current Gradient = [2.164644743520334e-05, -1.5751287719032426e-05]
				Previous Gradient = [3.1635012159192304e-06, -6.574503519563327e-06]
				|| Gradient || = 2.6770725641505555e-05
				||X optimum - X|| = 1.1090235825997756e-05
				beta" = 10.23140150974334
				alpha = 0.018014398509482003
			Iteration 45:
				X = [0.9999951289334573, 0.9999903037437697]
				Current Gradient = [-2.8082894873217712e-05, 9.170625570306702e-06]
				Previous Gradient = [2.164644743520334e-05, -1.5751287719032426e-05]
				|| Gradient || = 2.954233162448355e-05
				||X optimum - X|| = 1.0851021801936541e-05
				beta" = 2.267556136154395
				alpha = 0.0037778931862957215
			Iteration 46:
				X = [0.9999968844140615, 0.9999940808689192]
				Current Gradient = [-0.0001310428187053725, 6.240621783961273e-05]
				Previous Gradient = [-2.8082894873217712e-05, 9.170625570306702e-06]
				|| Gradient || = 0.000145143916025765
				||X optimum - X|| = 6.689019994889889e-06
				beta" = 19.266001687826126
				alpha = 0.028147497671065627
			Iteration 47:
				X = [1.000000911978811, 1.0000017058876363]
				Current Gradient = [4.905272757755382e-05, -2.3614163467134094e-05]
				Previous Gradient = [-0.0001310428187053725, 6.240621783961273e-05]
				|| Gradient || = 5.444078249851153e-05
				||X optimum - X|| = 1.9343624218596355e-06
				beta" = 0.5157641228729627
				alpha = 0.0030223145490365774
			Iteration 48:
				X = [1.0000009119789148, 1.000001705887852]
				Current Gradient = [4.905272458794235e-05, -2.3614161868412938e-05]
				Previous Gradient = [4.905272757755382e-05, -2.3614163467134094e-05]
				|| Gradient || = 5.444077911132547e-05
				||X optimum - X|| = 1.9343626611876958e-06
				beta" = -6.22178024223462e-08
				alpha = 1.6296287810675988e-10
			Iteration 49:
				X = [1.000000851254534, 1.0000017351206665]
				Current Gradient = [-1.1341451666867453e-05, 6.522174799702088e-06]
				Previous Gradient = [4.905272458794235e-05, -2.3614161868412938e-05]
				|| Gradient || = 1.3083091761115164e-05
				||X optimum - X|| = 1.9326867332432786e-06
				beta" = 0.2974264638005481
				alpha = 0.0012379400392853823
			Iteration 50:
				X = [1.000000851254534, 1.0000017351206665]
				Current Gradient = [-1.1341451666867453e-05, 6.522174799702088e-06]
				Previous Gradient = [-1.1341451666867453e-05, 6.522174799702088e-06]
				|| Gradient || = 1.3083091761115164e-05
				||X optimum - X|| = 1.9326867332432786e-06
				beta" = 0.0
				alpha = 3.417579257473478e-11
			Iteration 51:
				X = [1.000000865294571, 1.000001727046605]
				Current Gradient = [3.148304648043213e-06, -7.0865717732571e-07]
				Previous Gradient = [-1.1341451666867453e-05, 6.522174799702088e-06]
				|| Gradient || = 3.22707563466767e-06
				||X optimum - X|| = 1.9316895896689827e-06
				beta" = 0.29644886078982485
				alpha = 0.0012379400392853823
			Iteration 52:
				X = [1.000000865294571, 1.000001727046605]
				Current Gradient = [3.148304648043213e-06, -7.0865717732571e-07]
				Previous Gradient = [3.148304648043213e-06, -7.0865717732571e-07]
				|| Gradient || = 3.22707563466767e-06
				||X optimum - X|| = 1.9316895896689827e-06
				beta" = 0.0
				alpha = 8.343699359066107e-11
			Iteration 53:
				X = [1.0000008613971587, 1.0000017279238802]
				Current Gradient = [-3.283358055564721e-07, 1.0257641402100406e-06]
				Previous Gradient = [3.148304648043213e-06, -7.0865717732571e-07]
				|| Gradient || = 1.0770313238486898e-06
				||X optimum - X|| = 1.9307319857531257e-06
				beta" = 0.280450156065246
				alpha = 0.0012379400392853823
			Iteration 54:
				X = [1.0000008309073316, 1.000001682457913]
				Current Gradient = [-6.594815981751196e-06, 4.128511887573447e-06]
				Previous Gradient = [-3.283358055564721e-07, 1.0257641402100406e-06]
				|| Gradient || = 7.780501798662876e-06
				||X optimum - X|| = 1.876451870603931e-06
				beta" = 46.669119997720735
				alpha = 0.054975581388800036
			Iteration 55:
				X = [1.000000552935193, 1.0000010667277899]
				Current Gradient = [1.6763439713401017e-05, -7.828580361102124e-06]
				Previous Gradient = [-6.594815981751196e-06, 4.128511887573447e-06]
				|| Gradient || = 1.8501339991878002e-05
				||X optimum - X|| = 1.2015180004135525e-06
				beta" = 8.014571490739982
				alpha = 0.014411518807585602
			Iteration 56:
				X = [0.9999997437575463, 0.9999994866576619]
				Current Gradient = [-1.6908650808487344e-07, -1.7149925924324796e-07]
				Previous Gradient = [1.6763439713401017e-05, -7.828580361102124e-06]
				|| Gradient || = 2.4083654859119443e-07
				||X optimum - X|| = 5.737425826499231e-07
				beta" = 0.004527840753245805
				alpha = 0.004722366482869652
	- Starting Point : [-1.2  1. ]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Polak-Ribiere Method
			------------
			Iteration 0:
				X = [-0.9864801020462848, 1.087150978763799]
				Current Gradient = [41.01368406939088, 22.80159740397636]
				Previous Gradient = [-215.59999997755597, -87.9999999980896]
				|| Gradient || = 46.925847090029485
				||X optimum - X|| = 1.9883909296024527
				beta" = 0.24067419073090565
				alpha = 0.0009903520314283058
			Iteration 1:
				X = [0.8381547880321141, 0.8149794682666436]
				Current Gradient = [-38.03261616042164, 22.4952039137305]
				Previous Gradient = [41.01368406939088, 22.80159740397636]
				|| Gradient || = 44.187261638692675
				||X optimum - X|| = 0.24581796069413617
				beta" = 1.362124144746262
				alpha = 0.1677721600000001
			Iteration 2:
				X = [0.9035757482759518, 0.7843962398511873]
				Current Gradient = [11.392038215748968, -6.410578604433559]
				Previous Gradient = [-38.03261616042164, 22.4952039137305]
				|| Gradient || = 13.071880230200485
				||X optimum - X|| = 0.236183440805763
				beta" = 0.3832752581965729
				alpha = 0.0012379400392853823
			Iteration 3:
				X = [0.9035757482759518, 0.7843962398511873]
				Current Gradient = [11.392038215748968, -6.410578604433559]
				Previous Gradient = [11.392038215748968, -6.410578604433559]
				|| Gradient || = 13.071880230200485
				||X optimum - X|| = 0.236183440805763
				beta" = 0.0
				alpha = 5.623642243179056e-18
			Iteration 4:
				X = [0.8859474229805206, 0.7943161297629555]
				Current Gradient = [-3.5639783929220656, 1.8826586954800302]
				Previous Gradient = [11.392038215748968, -6.410578604433559]
				|| Gradient || = 4.030675594597253
				||X optimum - X|| = 0.2351889555240076
				beta" = 0.40331609301493127
				alpha = 0.0015474250491067279
			Iteration 5:
				X = [0.8859474229805206, 0.7943161297629555]
				Current Gradient = [-3.5639783929220656, 1.8826586954800302]
				Previous Gradient = [-3.5639783929220656, 1.8826586954800302]
				|| Gradient || = 4.030675594597253
				||X optimum - X|| = 0.2351889555240076
				beta" = 0.0
				alpha = 5.2374249726338796e-17
			Iteration 6:
				X = [0.8914624124202034, 0.7914028565386512]
				Current Gradient = [0.9605025337285426, -0.6604752438984716]
				Previous Gradient = [-3.5639783929220656, 1.8826586954800302]
				|| Gradient || = 1.1656726234675392
				||X optimum - X|| = 0.23514501095680632
				beta" = 0.3708804734225569
				alpha = 0.0015474250491067279
			Iteration 7:
				X = [0.8914624124202034, 0.7914028565386512]
				Current Gradient = [0.9605025337285426, -0.6604752438984716]
				Previous Gradient = [0.9605025337285426, -0.6604752438984716]
				|| Gradient || = 1.1656726234675392
				||X optimum - X|| = 0.23514501095680632
				beta" = 0.0
				alpha = 1.278668206209443e-16
			Iteration 8:
				X = [0.8899761067397813, 0.7924248924753745]
				Current Gradient = [-0.35084647374318545, 0.07348438153722409]
				Previous Gradient = [0.9605025337285426, -0.6604752438984716]
				|| Gradient || = 0.3584594851136402
				||X optimum - X|| = 0.2349312289841345
				beta" = 0.37828931335013233
				alpha = 0.0015474250491067279
			Iteration 9:
				X = [0.8899761067397813, 0.7924248924753745]
				Current Gradient = [-0.35084647374318545, 0.07348438153722409]
				Previous Gradient = [-0.35084647374318545, 0.07348438153722409]
				|| Gradient || = 0.3584594851136402
				||X optimum - X|| = 0.2349312289841345
				beta" = 0.0
				alpha = 3.1217485503160223e-16
			Iteration 10:
				X = [0.8905190153616424, 0.7923111809026657]
				Current Gradient = [0.03499119214777496, -0.1425871636049139]
				Previous Gradient = [-0.35084647374318545, 0.07348438153722409]
				|| Gradient || = 0.14681785570160394
				||X optimum - X|| = 0.23477804747341594
				beta" = 0.3448427450755241
				alpha = 0.0015474250491067279
			Iteration 11:
				X = [0.8952466772595213, 0.7987568813298856]
				Current Gradient = [0.7608447160911691, -0.5419463628810254]
				Previous Gradient = [0.03499119214777496, -0.1425871636049139]
				|| Gradient || = 0.9341255495081074
				||X optimum - X|| = 0.2268745279603786
				beta" = 35.66113979881969
				alpha = 0.054975581388800036
			Iteration 12:
				X = [0.9284776055406248, 0.8668238398162467]
				Current Gradient = [-1.9083317123469445, 0.9506351651865017]
				Previous Gradient = [0.7608447160911691, -0.5419463628810254]
				|| Gradient || = 2.1320030819954714
				||X optimum - X|| = 0.15116660527540862
				beta" = 7.4634942695796775
				alpha = 0.014411518807585602
			Iteration 13:
				X = [1.0007037304405486, 0.9964061431100958]
				Current Gradient = [2.003540635292381, -1.0003626015355187]
				Previous Gradient = [-1.9083317123469445, 0.9506351651865017]
				|| Gradient || = 2.2393973322790908
				||X optimum - X|| = 0.003662109211652039
				beta" = 2.153654336214608
				alpha = 0.0037778931862957215
			Iteration 14:
				X = [1.0007037304405502, 0.9964061431100989]
				Current Gradient = [2.003540635292381, -1.0003626015355187]
				Previous Gradient = [2.003540635292381, -1.0003626015355187]
				|| Gradient || = 2.2393973322790908
				||X optimum - X|| = 0.0036621092116492873
				beta" = 0.0
				alpha = 4.189939978107104e-17
			Iteration 15:
				X = [0.9982234672677864, 0.9976445320283434]
				Current Gradient = [-0.48048084905571803, 0.23888828485125352]
				Previous Gradient = [2.003540635292381, -1.0003626015355187]
				|| Gradient || = 0.5365905878306825
				||X optimum - X|| = 0.0029503047154703288
				beta" = 0.29702828536954806
				alpha = 0.0012379400392853823
			Iteration 16:
				X = [0.9982234672677864, 0.9976445320283434]
				Current Gradient = [-0.48048084905571803, 0.23888828485125352]
				Previous Gradient = [-0.48048084905571803, 0.23888828485125352]
				|| Gradient || = 0.5365905878306825
				||X optimum - X|| = 0.0029503047154703288
				beta" = 0.0
				alpha = 3.9021856878950277e-16
			Iteration 17:
				X = [0.9988182737489424, 0.9973488026556098]
				Current Gradient = [0.11315640122952789, -0.0578282638431487]
				Previous Gradient = [-0.48048084905571803, 0.23888828485125352]
				|| Gradient || = 0.12707666677376583
				||X optimum - X|| = 0.0029026409167068018
				beta" = 0.2928927732875362
				alpha = 0.0012379400392853823
			Iteration 18:
				X = [0.9988182737489424, 0.9973488026556098]
				Current Gradient = [0.11315640122952789, -0.0578282638431487]
				Previous Gradient = [0.11315640122952789, -0.0578282638431487]
				|| Gradient || = 0.12707666677376583
				||X optimum - X|| = 0.0029026409167068018
				beta" = 0.0
				alpha = 1.8607071341967707e-15
			Iteration 19:
				X = [0.9986781929091589, 0.9974203905788236]
				Current Gradient = [-0.027513731383656686, 0.012451517304426693]
				Previous Gradient = [0.11315640122952789, -0.0578282638431487]
				|| Gradient || = 0.03020009433486015
				||X optimum - X|| = 0.00289854424689702
				beta" = 0.2938635944286863
				alpha = 0.0012379400392853823
			Iteration 20:
				X = [0.9986781929091589, 0.9974203905788236]
				Current Gradient = [-0.027513731383656686, 0.012451517304426693]
				Previous Gradient = [-0.027513731383656686, 0.012451517304426693]
				|| Gradient || = 0.03020009433486015
				||X optimum - X|| = 0.00289854424689702
				beta" = 0.0
				alpha = 8.872543021186684e-15
			Iteration 21:
				X = [0.9987122532588689, 0.9974049763470025]
				Current Gradient = [0.005888977729854995, -0.0042376924810458225]
				Previous Gradient = [-0.027513731383656686, 0.012451517304426693]
				|| Gradient || = 0.0072552116624286294
				||X optimum - X|| = 0.002896970733181475
				beta" = 0.2932216549497175
				alpha = 0.0012379400392853823
			Iteration 22:
				X = [0.9987122532588689, 0.9974049763470025]
				Current Gradient = [0.005888977729854995, -0.0042376924810458225]
				Previous Gradient = [0.005888977729854995, -0.0042376924810458225]
				|| Gradient || = 0.0072552116624286294
				||X optimum - X|| = 0.002896970733181475
				beta" = 0.0
				alpha = 2.1661481985319047e-14
			Iteration 23:
				X = [0.9987049630575466, 0.997410222356199]
				Current Gradient = [-0.0020384369708644277, -0.00027617591532264415]
				Previous Gradient = [0.005888977729854995, -0.0042376924810458225]
				|| Gradient || = 0.002057060626328559
				||X optimum - X|| = 0.0028955256736299673
				beta" = 0.2862082942628002
				alpha = 0.0012379400392853823
			Iteration 24:
				X = [0.9987090324404164, 0.997427389803029]
				Current Gradient = [-0.0056413100427588885, 0.0015316649913051995]
				Previous Gradient = [-0.0020384369708644277, -0.00027617591532264415]
				|| Gradient || = 0.00584554331470756
				||X optimum - X|| = 0.0028783537769802017
				beta" = 5.4576247880673545
				alpha = 0.011529215046068483
			Iteration 25:
				X = [0.9987319042531375, 0.9974473218141454]
				Current Gradient = [0.004692534132347367, -0.0036189517906779216]
				Previous Gradient = [-0.0056413100427588885, 0.0015316649913051995]
				|| Gradient || = 0.005925933567506135
				||X optimum - X|| = 0.0028503039739207776
				beta" = 1.9646183896496863
				alpha = 0.0030223145490365774
			Iteration 26:
				X = [0.9987799543620381, 0.9975255974488817]
				Current Gradient = [0.011862352796137449, -0.007159957310870961]
				Previous Gradient = [0.004692534132347367, -0.0036189517906779216]
				|| Gradient || = 0.013855699280567707
				||X optimum - X|| = 0.002758836592422704
				beta" = 3.1439287441860113
				alpha = 0.004722366482869652
			Iteration 27:
				X = [0.9988407849164583, 0.9977047366235636]
				Current Gradient = [-0.011037515157227961, 0.0043646022075328516]
				Previous Gradient = [0.011862352796137449, -0.007159957310870961]
				|| Gradient || = 0.011869140376456823
				||X optimum - X|| = 0.0025713835919832367
				beta" = 1.5785869469888498
				alpha = 0.0030223145490365774
			Iteration 28:
				X = [0.999611980577471, 0.999311651394731]
				Current Gradient = [-0.03577832389439058, 0.01750793614384963]
				Previous Gradient = [-0.011037515157227961, 0.0043646022075328516]
				|| Gradient || = 0.03983235228691668
				||X optimum - X|| = 0.0007901790142970801
				beta" = 7.916844703795627
				alpha = 0.018014398509482003
			Iteration 29:
				X = [1.0001917978354733, 1.000377344429127]
				Current Gradient = [0.0028992897745946248, -0.0012576056457400807]
				Previous Gradient = [-0.03577832389439058, 0.01750793614384963]
				|| Gradient || = 0.0031602932074834885
				||X optimum - X|| = 0.0004232909494490459
				beta" = 0.0855514103076638
				alpha = 0.0015474250491067279
			Iteration 30:
				X = [1.0001917978354742, 1.000377344429129]
				Current Gradient = [0.002899289774507569, -0.0012576056456956712]
				Previous Gradient = [0.0028992897745946248, -0.0012576056457400807]
				|| Gradient || = 0.00316029320738595
				||X optimum - X|| = 0.0004232909494512298
				beta" = -3.086369506693768e-11
				alpha = 3.384606560206101e-14
			Iteration 31:
				X = [1.0001882086885756, 1.0003789012695092]
				Current Gradient = [-0.0006031544911045793, 0.0004896939694673126]
				Previous Gradient = [0.002899289774507569, -0.0012576056456956712]
				|| Gradient || = 0.0007769141032780119
				||X optimum - X|| = 0.00042307054079793893
				beta" = 0.297188585166888
				alpha = 0.0012379400392853823
			Iteration 32:
				X = [1.0001882086885754, 1.000378901269509]
				Current Gradient = [-0.0006031544911938585, 0.0004896939695117189]
				Previous Gradient = [-0.0006031544911045793, 0.0004896939694673126]
				|| Gradient || = 0.0007769141033753132
				||X optimum - X|| = 0.0004230705407976413
				beta" = 1.2524066420307819e-10
				alpha = 1.2024538023802114e-12
			Iteration 33:
				X = [1.00018895535767, 1.0003782950577371]
				Current Gradient = [0.0002384294565477539, 6.972765400052007e-05]
				Previous Gradient = [-0.0006031544911938585, 0.0004896939695117189]
				|| Gradient || = 0.0002484160853931837
				||X optimum - X|| = 0.00042286082568678186
				beta" = 0.28392380416797974
				alpha = 0.0012379400392853823
			Iteration 34:
				X = [1.000186591687776, 1.000370949847583]
				Current Gradient = [0.001280690847891892, -0.00045366888531004723]
				Previous Gradient = [0.0002384294565477539, 6.972765400052007e-05]
				|| Gradient || = 0.0013586701238242173
				||X optimum - X|| = 0.00041523517116077925
				beta" = 25.478031095320873
				alpha = 0.03518437208883203
			Iteration 35:
				X = [1.0001645124608176, 1.00033505091754]
				Current Gradient = [-0.002070942059666704, 0.0011997863108693624]
				Previous Gradient = [0.001280690847891892, -0.00045366888531004723]
				|| Gradient || = 0.0023933842579590275
				||X optimum - X|| = 0.00037326058874279707
				beta" = 4.834726640913474
				alpha = 0.00737869762948383
			Iteration 36:
				X = [0.9999412063780065, 0.9998897033250889]
				Current Gradient = [-0.003032260424168251, 0.001457422477210977]
				Previous Gradient = [-0.002070942059666704, 0.0011997863108693624]
				|| Gradient || = 0.003364325126538278
				||X optimum - X|| = 0.0001249881853759091
				beta" = 0.5744215816314969
				alpha = 0.018014398509482003
			Iteration 37:
				X = [0.9999361453613325, 0.9998703194946236]
				Current Gradient = [0.0006623628522045119, -0.00039506109125201624]
				Previous Gradient = [-0.003032260424168251, 0.001457422477210977]
				|| Gradient || = 0.0007712313620449638
				||X optimum - X|| = 0.00014454912090375242
				beta" = 0.28086529455634884
				alpha = 0.0012379400392853823
			Iteration 38:
				X = [0.9999361453613324, 0.9998703194946235]
				Current Gradient = [0.0006623628521598835, -0.0003950610912298118]
				Previous Gradient = [0.0006623628522045119, -0.00039506109125201624]
				|| Gradient || = 0.000771231361995261
				||X optimum - X|| = 0.00014454912090390104
				beta" = -6.444603435757112e-11
				alpha = 3.384606560206101e-14
			Iteration 39:
				X = [0.9999353253958373, 0.9998708085565666]
				Current Gradient = [-0.00019077767026287615, 3.0716417521498314e-05]
				Previous Gradient = [0.0006623628521598835, -0.0003950610912298118]
				|| Gradient || = 0.00019323461847268908
				||X optimum - X|| = 0.00014447571934412192
				beta" = 0.29562738286394236
				alpha = 0.0012379400392853823
			Iteration 40:
				X = [0.9999353253958373, 0.9998708085565666]
				Current Gradient = [-0.00019077767026287615, 3.0716417521498314e-05]
				Previous Gradient = [-0.00019077767026287615, 3.0716417521498314e-05]
				|| Gradient || = 0.00019323461847268908
				||X optimum - X|| = 0.00014447571934412192
				beta" = 0.0
				alpha = 6.156563468186683e-13
			Iteration 41:
				X = [0.9999355615671539, 0.9998707705314835]
				Current Gradient = [1.3816393150869204e-05, -7.13510271775332e-05]
				Previous Gradient = [-0.00019077767026287615, 3.0716417521498314e-05]
				|| Gradient || = 7.267641845185043e-05
				||X optimum - X|| = 0.00014440417985884664
				beta" = 0.2707410958968243
				alpha = 0.0012379400392853823
			Iteration 42:
				X = [0.999940639689842, 0.9998792309232364]
				Current Gradient = [0.0007020230948398, -0.00041039601882467646]
				Previous Gradient = [1.3816393150869204e-05, -7.13510271775332e-05]
				|| Gradient || = 0.0008131797574679261
				||X optimum - X|| = 0.000134569002093297
				beta" = 117.81446335887863
				alpha = 0.13421772800000006
			Iteration 43:
				X = [0.9999947618993015, 0.9999921712689401]
				Current Gradient = [-0.0010694474142081112, 0.000529488579907549]
				Previous Gradient = [0.0007020230948398, -0.00041039601882467646]
				|| Gradient || = 0.0011933465246980561
				||X optimum - X|| = 9.419486659876784e-06
				beta" = 3.6175603377234835
				alpha = 0.014411518807585602
			Iteration 44:
				X = [1.0000129040747934, 1.0000266115620413]
				Current Gradient = [-0.0002954939721755551, 0.0001606491878504102]
				Previous Gradient = [-0.0010694474142081112, 0.000529488579907549]
				|| Gradient || = 0.00033634037692356253
				||X optimum - X|| = 2.9575164928561128e-05
				beta" = -0.20220293032335865
				alpha = 0.0012379400392853823
			Iteration 45:
				X = [1.0000048410932811, 1.0000091242518652]
				Current Gradient = [0.00023286692028302118, -0.00011159162664112896]
				Previous Gradient = [-0.0002954939721755551, 0.0001606491878504102]
				|| Gradient || = 0.00025822411525361464
				||X optimum - X|| = 1.0328995897747402e-05
				beta" = 1.3561792153185472
				alpha = 0.0030223145490365774
			Iteration 46:
				X = [0.9999988821070301, 0.999997154377128]
				Current Gradient = [0.00024169961416335196, -0.00012196763639411475]
				Previous Gradient = [0.00023286692028302118, -0.00011159162664112896]
				|| Gradient || = 0.0002707301383560393
				||X optimum - X|| = 3.0573279545611842e-06
				beta" = 0.05099597642196112
				alpha = 0.0015474250491067279
			Iteration 47:
				X = [0.9999983397899425, 0.9999968170333887]
				Current Gradient = [-5.830022785040917e-05, 2.749014949089636e-05]
				Previous Gradient = [0.00024169961416335196, -0.00012196763639411475]
				|| Gradient || = 6.445637971870165e-05
				||X optimum - X|| = 3.589926724000669e-06
				beta" = 0.29468221099337194
				alpha = 0.0012379400392853823
			Iteration 48:
				X = [0.9999983397899422, 0.9999968170333883]
				Current Gradient = [-5.8300227850853264e-05, 2.749014949089636e-05]
				Previous Gradient = [-5.830022785040917e-05, 2.749014949089636e-05]
				|| Gradient || = 6.445637971910334e-05
				||X optimum - X|| = 3.589926724497103e-06
				beta" = 6.231825468183448e-12
				alpha = 3.66959778558414e-12
			Iteration 49:
				X = [0.9999984119621286, 0.9999967830022315]
				Current Gradient = [1.3194117285830426e-05, -8.18490950595051e-06]
				Previous Gradient = [-5.8300227850853264e-05, 2.749014949089636e-05]
				|| Gradient || = 1.55266697837253e-05
				||X optimum - X|| = 3.5876090817784737e-06
				beta" = 0.297331753952486
				alpha = 0.0012379400392853823
			Iteration 50:
				X = [0.9999984119621286, 0.9999967830022315]
				Current Gradient = [1.3194117285830426e-05, -8.18490950595051e-06]
				Previous Gradient = [1.3194117285830426e-05, -8.18490950595051e-06]
				|| Gradient || = 1.55266697837253e-05
				||X optimum - X|| = 3.5876090817784737e-06
				beta" = 0.0
				alpha = 1.1198723710889097e-11
			Iteration 51:
				X = [0.9999983956286025, 0.9999967931346587]
				Current Gradient = [-3.958293479794504e-06, 3.749759391987848e-07]
				Previous Gradient = [1.3194117285830426e-05, -8.18490950595051e-06]
				|| Gradient || = 3.976014867573019e-06
				||X optimum - X|| = 3.585804358611262e-06
				beta" = 0.2949426399398962
				alpha = 0.0012379400392853823
			Iteration 52:
				X = [0.9999983956286025, 0.9999967931346587]
				Current Gradient = [-3.958293479794504e-06, 3.749759391987848e-07]
				Previous Gradient = [-3.958293479794504e-06, 3.749759391987848e-07]
				|| Gradient || = 3.976014867573019e-06
				||X optimum - X|| = 3.585804358611262e-06
				beta" = 0.0
				alpha = 2.1872507247830263e-11
			Iteration 53:
				X = [0.999998401753765, 0.9999967925544115]
				Current Gradient = [1.1861696641022164e-06, -2.191134562742063e-06]
				Previous Gradient = [-3.958293479794504e-06, 3.749759391987848e-07]
				|| Gradient || = 2.4915997158611203e-06
				||X optimum - X|| = 3.583587341017407e-06
				beta" = 0.7416741296605672
				alpha = 0.0015474250491067279
			Iteration 54:
				X = [0.99999841001599, 0.9999968015884149]
				Current Gradient = [4.198857500238796e-06, -3.6892186417953334e-06]
				Previous Gradient = [1.1861696641022164e-06, -2.191134562742063e-06]
				|| Gradient || = 5.5893415081100374e-06
				||X optimum - X|| = 3.571818279255132e-06
				beta" = 2.927900158038002
				alpha = 0.004722366482869652
			Iteration 55:
				X = [0.9999984135059309, 0.9999968366864166]
				Current Gradient = [-7.041397144932494e-06, 1.9344075675166156e-06]
				Previous Gradient = [4.198857500238796e-06, -3.6892186417953334e-06]
				|| Gradient || = 7.302274056068358e-06
				||X optimum - X|| = 3.538858044387655e-06
				beta" = 2.881669461158197
				alpha = 0.0037778931862957215
			Iteration 56:
				X = [0.9999984501644332, 0.9999969305192711]
				Current Gradient = [-1.5174453467850657e-05, 6.037600530813118e-06]
				Previous Gradient = [-7.041397144932494e-06, 1.9344075675166156e-06]
				|| Gradient || = 1.633146221921478e-05
				||X optimum - X|| = 3.43856106958466e-06
				beta" = 2.7790550263073754
				alpha = 0.0037778931862957215
			Iteration 57:
				X = [0.9999986093678928, 0.9999971684765271]
				Current Gradient = [1.732358472404109e-05, -1.0052238464131455e-05]
				Previous Gradient = [-1.5174453467850657e-05, 6.037600530813118e-06]
				|| Gradient || = 2.0028831364580255e-05
				||X optimum - X|| = 3.154581245642109e-06
				beta" = 2.7171959233894345
				alpha = 0.0037778931862957215
			Iteration 58:
				X = [0.9999989030801635, 0.9999977161187426]
				Current Gradient = [3.3823635879638655e-05, -1.80085575346061e-05]
				Previous Gradient = [1.732358472404109e-05, -1.0052238464131455e-05]
				|| Gradient || = 3.831900949392609e-05
				||X optimum - X|| = 2.5336429752174494e-06
				beta" = 1.7483894014792807
				alpha = 0.0030223145490365774
			Iteration 59:
				X = [0.999999232118367, 0.9999985256542392]
				Current Gradient = [-2.6102110609780187e-05, 1.2283383088804886e-05]
				Previous Gradient = [3.3823635879638655e-05, -1.80085575346061e-05]
				|| Gradient || = 2.8847905961985133e-05
				||X optimum - X|| = 1.6623289760557863e-06
				beta" = 1.3186778389568665
				alpha = 0.002417851639229262
			Iteration 60:
				X = [0.9999993949774302, 0.9999988657261535]
				Current Gradient = [-3.151799766928301e-05, 1.5154185418078673e-05]
				Previous Gradient = [-2.6102110609780187e-05, 1.2283383088804886e-05]
				|| Gradient || = 3.497189604191397e-05
				||X optimum - X|| = 1.2855463697903412e-06
				beta" = 0.2573926394008045
				alpha = 0.0007922816251426447
			Iteration 61:
				X = [0.9999995256216773, 0.9999990132371397]
				Current Gradient = [1.4254212087491752e-05, -7.60128798773165e-06]
				Previous Gradient = [-3.151799766928301e-05, 1.5154185418078673e-05]
				|| Gradient || = 1.6154322681797262e-05
				||X optimum - X|| = 1.0948679078179918e-06
				beta" = 0.6748937650726415
				alpha = 0.0015474250491067279
			Iteration 62:
				X = [0.9999995256216776, 0.9999990132371404]
				Current Gradient = [1.4254212042846668e-05, -7.60128798773165e-06]
				Previous Gradient = [1.4254212087491752e-05, -7.60128798773165e-06]
				|| Gradient || = 1.615432264240344e-05
				||X optimum - X|| = 1.0948679070733211e-06
				beta" = -2.4385931610339005e-09
				alpha = 8.958978968711279e-12
			Iteration 63:
				X = [0.9999995079758176, 0.9999990226470789]
				Current Gradient = [-3.661727680197247e-06, 1.3390403009013463e-06]
				Previous Gradient = [1.4254212042846668e-05, -7.60128798773165e-06]
				|| Gradient || = 3.898881702663045e-06
				||X optimum - X|| = 1.094215028476361e-06
				beta" = 0.29726439349408346
				alpha = 0.0012379400392853823
			Iteration 64:
				X = [0.9999995079758176, 0.9999990226470789]
				Current Gradient = [-3.661727680197247e-06, 1.3390403009013463e-06]
				Previous Gradient = [-3.661727680197247e-06, 1.3390403009013463e-06]
				|| Gradient || = 3.898881702663045e-06
				||X optimum - X|| = 1.094215028476361e-06
				beta" = 0.0
				alpha = 5.339967589802309e-11
			Iteration 65:
				X = [0.9999995125088169, 0.9999990209894273]
				Current Gradient = [6.367945371953185e-07, -8.056888489936436e-07]
				Previous Gradient = [-3.661727680197247e-06, 1.3390403009013463e-06]
				|| Gradient || = 1.0269575473185356e-06
				||X optimum - X|| = 1.0936678449550155e-06
				beta" = 0.2937423860116991
				alpha = 0.0012379400392853823
			Iteration 66:
				X = [0.9999995131878426, 0.9999990216275172]
				Current Gradient = [9.261367748545977e-07, -9.496810337873593e-07]
				Previous Gradient = [6.367945371953185e-07, -8.056888489936436e-07]
				|| Gradient || = 1.3265079689445906e-06
				||X optimum - X|| = 1.0927940298477305e-06
				beta" = 0.3837484273753324
				alpha = 0.0015474250491067279
			Iteration 67:
				X = [0.9999995120152905, 0.9999990233419435]
				Current Gradient = [-7.00019335575671e-07, -1.3777512464625737e-07]
				Previous Gradient = [9.261367748545977e-07, -9.496810337873593e-07]
				|| Gradient || = 7.134487053398413e-07
				||X optimum - X|| = 1.0917829620113772e-06
				beta" = 0.5833522599154153
				alpha = 0.0015474250491067279
	- Starting Point : [0.2 0.8]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Polak-Ribiere Method
			------------
			Iteration 0:
				X = [0.49467566853534556, 0.08220029458736644]
				Current Gradient = [31.144006354288933, -32.50074449079321]
				Previous Gradient = [-62.400000000906175, 152.00000000348268]
				|| Gradient || = 45.013859246367836
				||X optimum - X|| = 1.0477160775829093
				beta" = 0.3300179971640129
				alpha = 0.004722366482869652
			Iteration 1:
				X = [0.4946756685353455, 0.08220029458736636]
				Current Gradient = [31.144006354288933, -32.500744490571165]
				Previous Gradient = [31.144006354288933, -32.50074449079321]
				|| Gradient || = 45.01385924620752
				||X optimum - X|| = 1.0477160775829095
				beta" = -3.5615663357037155e-12
				alpha = 4.498913794543245e-18
			Iteration 2:
				X = [0.40054868501560403, 0.1804277675159301]
				Current Gradient = [-4.40145254168578, 3.9977036896676754]
				Previous Gradient = [31.144006354288933, -32.500744490571165]
				|| Gradient || = 5.945958229511435
				||X optimum - X|| = 1.0154016561417674
				beta" = 0.14922245566921066
				alpha = 0.0030223145490365774
			Iteration 3:
				X = [0.40054868501560403, 0.1804277675159301]
				Current Gradient = [-4.40145254168578, 3.9977036896676754]
				Previous Gradient = [-4.40145254168578, 3.9977036896676754]
				|| Gradient || = 5.945958229511435
				||X optimum - X|| = 1.0154016561417674
				beta" = 0.0
				alpha = 1.3729595320261364e-17
			Iteration 4:
				X = [0.41717690258264273, 0.16532486998590532]
				Current Gradient = [0.28808149085679524, -1.7423396125315627]
				Previous Gradient = [-4.40145254168578, 3.9977036896676754]
				|| Gradient || = 1.765994980392331
				||X optimum - X|| = 1.0180203021291905
				beta" = 0.3210934591464896
				alpha = 0.0037778931862957215
			Iteration 5:
				X = [0.43014953074620194, 0.170613356739279]
				Current Gradient = [1.3405863462101486, -2.883052412361309]
				Previous Gradient = [0.28808149085679524, -1.7423396125315627]
				|| Gradient || = 3.1794909913486844
				||X optimum - X|| = 1.0062861229928892
				beta" = 1.506926205322597
				alpha = 0.011529215046068483
			Iteration 6:
				X = [0.4322450878960481, 0.19171220628877544]
				Current Gradient = [-1.97862812187366, 0.9752780557037433]
				Previous Gradient = [1.3405863462101486, -2.883052412361309]
				|| Gradient || = 2.205932122846612
				||X optimum - X|| = 0.9877625208929144
				beta" = 1.0218883762143918
				alpha = 0.005902958103587064
			Iteration 7:
				X = [0.8250667748718732, 0.6408787727421787]
				Current Gradient = [12.803813497469507, -7.971282051294493]
				Previous Gradient = [-1.97862812187366, 0.9752780557037433]
				|| Gradient || = 15.082406227763263
				||X optimum - X|| = 0.39946174925878897
				beta" = 53.551144299800676
				alpha = 0.1677721600000001
			Iteration 8:
				X = [0.8250667748718734, 0.6408787727421791]
				Current Gradient = [12.803813497011541, -7.971282051294493]
				Previous Gradient = [12.803813497469507, -7.971282051294493]
				|| Gradient || = 15.082406227374486
				||X optimum - X|| = 0.3994617492587886
				beta" = -2.5776943061265833e-11
				alpha = 2.303443862806142e-18
			Iteration 9:
				X = [0.8052538331380164, 0.6532137342558104]
				Current Gradient = [-1.929137170370021, 0.9559996944977223]
				Previous Gradient = [12.803813497011541, -7.971282051294493]
				|| Gradient || = 2.1530224425172606
				||X optimum - X|| = 0.3977270214811099
				beta" = 0.1624605568920067
				alpha = 0.0015474250491067279
			Iteration 10:
				X = [0.8052538331380164, 0.6532137342558104]
				Current Gradient = [-1.929137170370021, 0.9559996944977223]
				Previous Gradient = [-1.929137170370021, 0.9559996944977223]
				|| Gradient || = 2.1530224425172606
				||X optimum - X|| = 0.3977270214811099
				beta" = 0.0
				alpha = 1.5983352577618037e-16
			Iteration 11:
				X = [0.8089853271137581, 0.6513645619130553]
				Current Gradient = [0.6187494374539082, -0.6185395144790717]
				Previous Gradient = [-1.929137170370021, 0.9559996944977223]
				|| Gradient || = 0.8748954207912701
				||X optimum - X|| = 0.3975339909340003
				beta" = 0.5501920011138014
				alpha = 0.0019342813113834097
			Iteration 12:
				X = [0.8089853271137581, 0.6513645619130553]
				Current Gradient = [0.6187494374539082, -0.6185395144790717]
				Previous Gradient = [0.6187494374539082, -0.6185395144790717]
				|| Gradient || = 0.8748954207912701
				||X optimum - X|| = 0.3975339909340003
				beta" = 0.0
				alpha = 1.0229345649675545e-16
			Iteration 13:
				X = [0.8077884916404621, 0.6525609913362643]
				Current Gradient = [-0.39694183471411515, 0.007748821900105396]
				Previous Gradient = [0.6187494374539082, -0.6185395144790717]
				|| Gradient || = 0.39701746106065344
				||X optimum - X|| = 0.39706312934732196
				beta" = 0.5330558752746474
				alpha = 0.0019342813113834097
			Iteration 14:
				X = [0.8079913306901748, 0.6535340777925244]
				Current Gradient = [-0.605111988571938, 0.13681746441340792]
				Previous Gradient = [-0.39694183471411515, 0.007748821900105396]
				|| Gradient || = 0.6203866030806915
				||X optimum - X|| = 0.39611357505292133
				beta" = 0.9111945828716105
				alpha = 0.0030223145490365774
			Iteration 15:
				X = [0.8100049953003253, 0.6540072434868753]
				Current Gradient = [0.3006892402568351, -0.4201697849336161]
				Previous Gradient = [-0.605111988571938, 0.13681746441340792]
				|| Gradient || = 0.5166784951760561
				||X optimum - X|| = 0.3947266007889255
				beta" = 1.3157204970294496
				alpha = 0.0030223145490365774
			Iteration 16:
				X = [0.81340468736312, 0.6577034135193346]
				Current Gradient = [0.9034551589279238, -0.7847543810161894]
				Previous Gradient = [0.3006892402568351, -0.4201697849336161]
				|| Gradient || = 1.19669154869481
				||X optimum - X|| = 0.3898522333068911
				beta" = 3.111671066457449
				alpha = 0.005902958103587064
			Iteration 17:
				X = [0.8176012197431536, 0.670610323582899]
				Current Gradient = [-1.0641962281433825, 0.4277138114933132]
				Previous Gradient = [0.9034551589279238, -0.7847543810161894]
				|| Gradient || = 1.1469318709220437
				||X optimum - X|| = 0.37651942044116116
				beta" = 1.8243209950249826
				alpha = 0.004722366482869652
			Iteration 18:
				X = [0.9652315257758494, 0.9212120646281856]
				Current Gradient = [3.968927557786682, -2.0919667447372863]
				Previous Gradient = [-1.0641962281433825, 0.4277138114933132]
				|| Gradient || = 4.48650318400035
				||X optimum - X|| = 0.08611843914068942
				beta" = 19.192777748176777
				alpha = 0.054975581388800036
			Iteration 19:
				X = [0.9652315257758569, 0.9212120646281999]
				Current Gradient = [3.968927557671323, -2.091966744738154]
				Previous Gradient = [3.968927557786682, -2.0919667447372863]
				|| Gradient || = 4.486503183898703
				||X optimum - X|| = 0.08611843914067327
				beta" = -2.2655973994356235e-11
				alpha = 1.5983352577618037e-16
			Iteration 20:
				X = [0.9603182314378582, 0.9238017940198524]
				Current Gradient = [-0.6903903605397048, 0.3181376775924366]
				Previous Gradient = [3.968927557671323, -2.091966744738154]
				|| Gradient || = 0.7601647399281637
				||X optimum - X|| = 0.08591163687657444
				beta" = 0.1979010596799797
				alpha = 0.0012379400392853823
			Iteration 21:
				X = [0.9603182314378582, 0.9238017940198524]
				Current Gradient = [-0.6903903605397048, 0.3181376775924366]
				Previous Gradient = [-0.6903903605397048, 0.3181376775924366]
				|| Gradient || = 0.7601647399281637
				||X optimum - X|| = 0.08591163687657444
				beta" = 0.0
				alpha = 4.877732109868785e-16
			Iteration 22:
				X = [0.961172893307907, 0.9234079586507554]
				Current Gradient = [0.09357765341072838, -0.0890744358301044]
				Previous Gradient = [-0.6903903605397048, 0.3181376775924366]
				|| Gradient || = 0.12919377824148418
				||X optimum - X|| = 0.08587132823081033
				beta" = 0.1897274282786929
				alpha = 0.0012379400392853823
			Iteration 23:
				X = [0.961172893307907, 0.9234079586507554]
				Current Gradient = [0.09357765341072838, -0.0890744358301044]
				Previous Gradient = [0.09357765341072838, -0.0890744358301044]
				|| Gradient || = 0.12919377824148418
				||X optimum - X|| = 0.08587132823081033
				beta" = 0.0
				alpha = 1.1908525658859333e-15
			Iteration 24:
				X = [0.9610280889029826, 0.923545794663994]
				Current Gradient = [-0.06672170594777989, -0.005838599305202016]
				Previous Gradient = [0.09357765341072838, -0.0890744358301044]
				|| Gradient || = 0.06697667718264852
				||X optimum - X|| = 0.08581407441739376
				beta" = 0.6116737308826571
				alpha = 0.0015474250491067279
			Iteration 25:
				X = [0.961063913581924, 0.9237736888614652]
				Current Gradient = [-0.1277870919640274, 0.02596857441301663]
				Previous Gradient = [-0.06672170594777989, -0.005838599305202016]
				|| Gradient || = 0.1303990327021914
				||X optimum - X|| = 0.08559479736143198
				beta" = 1.9236725288268886
				alpha = 0.0037778931862957215
			Iteration 26:
				X = [0.9615052583297328, 0.9240459187069224]
				Current Gradient = [0.09471346801856809, -0.08928861776336117]
				Previous Gradient = [-0.1277870919640274, 0.02596857441301663]
				|| Gradient || = 0.1301656570920146
				||X optimum - X|| = 0.08515202640769064
				beta" = 1.8445733502785726
				alpha = 0.0030223145490365774
			Iteration 27:
				X = [0.9625361936182314, 0.9255537433292085]
				Current Gradient = [0.2801253063673508, -0.18443613917823629]
				Previous Gradient = [0.09471346801856809, -0.08928861776336117]
				|| Gradient || = 0.33539063299736904
				||X optimum - X|| = 0.08334135780573783
				beta" = 4.10120913837453
				alpha = 0.005902958103587064
			Iteration 28:
				X = [0.9645958042414493, 0.9313718416670822]
				Current Gradient = [-0.4283941288044796, 0.1853552213800739]
				Previous Gradient = [0.2801253063673508, -0.18443613917823629]
				|| Gradient || = 0.46677412919634403
				||X optimum - X|| = 0.07722228430626624
				beta" = 3.30765984957198
				alpha = 0.004722366482869652
			Iteration 29:
				X = [0.9734313296809435, 0.9497408166552586]
				Current Gradient = [-0.8989569042768898, 0.43445261018230064]
				Previous Gradient = [-0.4283941288044796, 0.1853552213800739]
				|| Gradient || = 0.9984350686155326
				||X optimum - X|| = 0.05684962403572297
				beta" = 2.4382289761258353
				alpha = 0.004722366482869652
			Iteration 30:
				X = [0.9839941920067744, 0.9672455324858099]
				Current Gradient = [0.361207190880628, -0.19980748345671628]
				Previous Gradient = [-0.8989569042768898, 0.43445261018230064]
				|| Gradient || = 0.41278767567501384
				||X optimum - X|| = 0.03645601502707253
				beta" = 0.5837358294921066
				alpha = 0.0019342813113834097
			Iteration 31:
				X = [0.9973419578337327, 0.9931357026432693]
				Current Gradient = [0.6151416030098422, -0.3110556424796825]
				Previous Gradient = [0.361207190880628, -0.19980748345671628]
				|| Gradient || = 0.6893147354234975
				||X optimum - X|| = 0.007360962325625269
				beta" = 1.119818560767794
				alpha = 0.004722366482869652
			Iteration 32:
				X = [1.0012879301452355, 1.0031172325337947]
				Current Gradient = [-0.21358757630255065, 0.1079426958440419]
				Previous Gradient = [0.6151416030098422, -0.3110556424796825]
				|| Gradient || = 0.2393141833174065
				||X optimum - X|| = 0.0033728182175674047
				beta" = 0.4677087654839954
				alpha = 0.0015474250491067279
			Iteration 33:
				X = [1.0012879301452389, 1.0031172325338014]
				Current Gradient = [-0.21358757630254385, 0.1079426958440419]
				Previous Gradient = [-0.21358757630255065, 0.1079426958440419]
				|| Gradient || = 0.2393141833174004
				||X optimum - X|| = 0.003372818217574833
				beta" = -2.5360361121845266e-14
				alpha = 2.3258839177459632e-15
			Iteration 34:
				X = [1.0015523387578376, 1.0029836059486674]
				Current Gradient = [0.05257388089984232, -0.02469626452331639]
				Previous Gradient = [-0.21358757630254385, 0.1079426958440419]
				|| Gradient || = 0.05808544081158738
				||X optimum - X|| = 0.003363281147333401
				beta" = 0.3015268403970317
				alpha = 0.0012379400392853823
			Iteration 35:
				X = [1.0015523387578376, 1.0029836059486674]
				Current Gradient = [0.05257388089984232, -0.02469626452331639]
				Previous Gradient = [0.05257388089984232, -0.02469626452331639]
				|| Gradient || = 0.05808544081158738
				||X optimum - X|| = 0.003363281147333401
				beta" = 0.0
				alpha = 8.872543021186684e-15
			Iteration 36:
				X = [1.001487255445651, 1.0030141784433415]
				Current Gradient = [-0.012030020450210614, 0.007491124655128869]
				Previous Gradient = [0.05257388089984232, -0.02469626452331639]
				|| Gradient || = 0.014171744445591912
				||X optimum - X|| = 0.0033611308288912928
				beta" = 0.30181701748275774
				alpha = 0.0012379400392853823
			Iteration 37:
				X = [1.001487255445651, 1.0030141784433415]
				Current Gradient = [-0.012030020450210614, 0.007491124655128869]
				Previous Gradient = [-0.012030020450210614, 0.007491124655128869]
				|| Gradient || = 0.014171744445591912
				||X optimum - X|| = 0.0033611308288912928
				beta" = 0.0
				alpha = 2.7076852481648806e-14
			Iteration 38:
				X = [1.0015021478896398, 1.0030049048801917]
				Current Gradient = [0.003664224951448278, -0.00032946947403149015]
				Previous Gradient = [-0.012030020450210614, 0.007491124655128869]
				|| Gradient || = 0.003679007288540582
				||X optimum - X|| = 0.0033594496009538397
				beta" = 0.29916545038380776
				alpha = 0.0012379400392853823
			Iteration 39:
				X = [1.0015021478896398, 1.0030049048801917]
				Current Gradient = [0.003664224951448278, -0.00032946947403149015]
				Previous Gradient = [0.003664224951448278, -0.00032946947403149015]
				|| Gradient || = 0.003679007288540582
				||X optimum - X|| = 0.0033594496009538397
				beta" = 0.0
				alpha = 5.2884477503220316e-14
			Iteration 40:
				X = [1.0014964777761644, 1.0030054147095087]
				Current Gradient = [-0.0011010460535395357, 0.002043942288896776]
				Previous Gradient = [0.003664224951448278, -0.00032946947403149015]
				|| Gradient || = 0.0023216378900154902
				||X optimum - X|| = 0.003357374466854243
				beta" = 0.7460531146613699
				alpha = 0.0015474250491067279
			Iteration 41:
				X = [1.0014868402503183, 1.002994800361109]
				Current Gradient = [-0.004601231679482042, 0.003781833308202603]
				Previous Gradient = [-0.0011010460535395357, 0.002043942288896776]
				|| Gradient || = 0.005955971468979664
				||X optimum - X|| = 0.0033435793893469698
				beta" = 4.207341121113391
				alpha = 0.005902958103587064
			Iteration 42:
				X = [1.0014761302655435, 1.0029412146106544]
				Current Gradient = [0.008250021987239196, -0.0026449761984668877]
				Previous Gradient = [-0.004601231679482042, 0.003781833308202603]
				|| Gradient || = 0.008663645992328318
				||X optimum - X|| = 0.0032908515534403357
				beta" = 3.467984554150377
				alpha = 0.004722366482869652
			Iteration 43:
				X = [1.0013274941540395, 1.002602652095124]
				Current Gradient = [0.024323096331834743, -0.01081969073597298]
				Previous Gradient = [0.008250021987239196, -0.0026449761984668877]
				|| Gradient || = 0.026621020318346407
				||X optimum - X|| = 0.0029216499888354095
				beta" = 6.386926812714814
				alpha = 0.009223372036854787
			Iteration 44:
				X = [1.0008467593593044, 1.0017578193372656]
				Current Gradient = [-0.02376146378519484, 0.012716723447800586]
				Previous Gradient = [0.024323096331834743, -0.01081969073597298]
				|| Gradient || = 0.02695036579460411
				||X optimum - X|| = 0.001951135627022004
				beta" = 2.034582890113672
				alpha = 0.0037778931862957215
			Iteration 45:
				X = [0.9999584328433847, 0.999990894640254]
				Current Gradient = [-0.029692793336562367, 0.014805445131642107]
				Previous Gradient = [-0.02376146378519484, 0.012716723447800586]
				|| Gradient || = 0.03317925830505961
				||X optimum - X|| = 4.2552744743247895e-05
				beta" = 0.2850555747467548
				alpha = 0.0037778931862957215
			Iteration 46:
				X = [0.9999122148167273, 0.999807523232788]
				Current Gradient = [0.0065894788725434795, -0.0033828213811122544]
				Previous Gradient = [-0.029692793336562367, 0.014805445131642107]
				|| Gradient || = 0.007407071776903955
				||X optimum - X|| = 0.0002115503351890651
				beta" = 0.2730665608758126
				alpha = 0.0012379400392853823
			Iteration 47:
				X = [0.999912214816727, 0.9998075232327873]
				Current Gradient = [0.006589478872542811, -0.0033828213811122544]
				Previous Gradient = [0.0065894788725434795, -0.0033828213811122544]
				|| Gradient || = 0.00740707177690336
				||X optimum - X|| = 0.0002115503351898094
				beta" = -8.031794752762477e-14
				alpha = 1.732918558825524e-14
			Iteration 48:
				X = [0.9999040574369926, 0.9998117109628207]
				Current Gradient = [-0.0016265006162199944, 0.0007173767720287446]
				Previous Gradient = [0.006589478872542811, -0.0033828213811122544]
				|| Gradient || = 0.0017776764856436626
				||X optimum - X|| = 0.0002113237727240371
				beta" = 0.29717977058754536
				alpha = 0.0012379400392853823
			Iteration 49:
				X = [0.9999040574369926, 0.9998117109628207]
				Current Gradient = [-0.0016265006162199944, 0.0007173767720287446]
				Previous Gradient = [-0.0016265006162199944, 0.0007173767720287446]
				|| Gradient || = 0.0017776764856436626
				||X optimum - X|| = 0.0002113237727240371
				beta" = 0.0
				alpha = 1.6139061738043305e-13
			Iteration 50:
				X = [0.9999060709472294, 0.9998108228933914]
				Current Gradient = [0.00034322189967024916, -0.0002655647468673181]
				Previous Gradient = [-0.0016265006162199944, 0.0007173767720287446]
				|| Gradient || = 0.000433965329481466
				||X optimum - X|| = 0.00021121232118222818
				beta" = 0.2965338216709174
				alpha = 0.0012379400392853823
			Iteration 51:
				X = [0.9999060709472294, 0.9998108228933914]
				Current Gradient = [0.00034322189967024916, -0.0002655647468673181]
				Previous Gradient = [0.00034322189967024916, -0.0002655647468673181]
				|| Gradient || = 0.000433965329481466
				||X optimum - X|| = 0.00021121232118222818
				beta" = 0.0
				alpha = 3.940200619639478e-13
			Iteration 52:
				X = [0.9999056460590974, 0.9998111516466246]
				Current Gradient = [-0.00012896342492713634, -2.9874847263549137e-05]
				Previous Gradient = [0.00034322189967024916, -0.0002655647468673181]
				|| Gradient || = 0.00013237851588515987
				||X optimum - X|| = 0.0002111074767421974
				beta" = 0.2859587282024599
				alpha = 0.0012379400392853823
			Iteration 53:
				X = [0.9999063399765878, 0.9998135343977067]
				Current Gradient = [-0.0005255568970298528, 0.00016913446621511608]
				Previous Gradient = [-0.00012896342492713634, -2.9874847263549137e-05]
				|| Gradient || = 0.0005521019105903543
				||X optimum - X|| = 0.0002086662905794012
				beta" = 13.814812900661284
				alpha = 0.022517998136852502
			Iteration 54:
				X = [0.9999108322501364, 0.9998196389326182]
				Current Gradient = [0.0006349997874873608, -0.0004067037084782106]
				Previous Gradient = [-0.0005255568970298528, 0.00016913446621511608]
				|| Gradient || = 0.0007540773412581251
				||X optimum - X|| = 0.00020119891213137134
				beta" = 3.1860109491243866
				alpha = 0.004722366482869652
			Iteration 55:
				X = [0.9999453590171022, 0.9998848541396146]
				Current Gradient = [0.0022373422961545187, -0.0011733760454051183]
				Previous Gradient = [0.0006349997874873608, -0.0004067037084782106]
				|| Gradient || = 0.0025263633733278606
				||X optimum - X|| = 0.00012745276056614087
				beta" = 7.886609620606961
				alpha = 0.014411518807585602
			Iteration 56:
				X = [0.9999856336689932, 0.9999739809202299]
				Current Gradient = [-0.001114067010392576, 0.000542675170438551]
				Previous Gradient = [0.0022373422961545187, -0.0011733760454051183]
				|| Gradient || = 0.0012392100888289936
				||X optimum - X|| = 2.9721776169648575e-05
				beta" = 0.7308960813851004
				alpha = 0.002417851639229262
			Iteration 57:
				X = [1.000006197018749, 1.0000148323164846]
				Current Gradient = [-0.0009629078397017297, 0.00048764811664699445]
				Previous Gradient = [-0.001114067010392576, 0.000542675170438551]
				|| Gradient || = 0.001079348040915632
				||X optimum - X|| = 1.607484537016663e-05
				beta" = -0.11225678223299379
				alpha = 0.0015474250491067279
			Iteration 58:
				X = [1.0000055423405376, 1.0000105599603213]
				Current Gradient = [0.00022098683299093293, -0.00010495029426873888]
				Previous Gradient = [-0.0009629078397017297, 0.00048764811664699445]
				|| Gradient || = 0.00024464207451388524
				||X optimum - X|| = 1.1926034572403287e-05
				beta" = 0.277957666796915
				alpha = 0.0012379400392853823
			Iteration 59:
				X = [1.0000055423405372, 1.0000105599603204]
				Current Gradient = [0.00022098683299004473, -0.0001049502942687389]
				Previous Gradient = [0.00022098683299093293, -0.00010495029426873888]
				|| Gradient || = 0.00024464207451308287
				||X optimum - X|| = 1.1926034571410466e-05
				beta" = -3.279551230438846e-12
				alpha = 9.61963041904169e-13
			Iteration 60:
				X = [1.0000052687720884, 1.0000106898824919]
				Current Gradient = [-5.03865988897277e-05, 3.0462111008925126e-05]
				Previous Gradient = [0.00022098683299004473, -0.0001049502942687389]
				|| Gradient || = 5.8879109663737153e-05
				||X optimum - X|| = 1.1917782805931367e-05
				beta" = 0.29738693281653394
				alpha = 0.0012379400392853823
			Iteration 61:
				X = [1.0000052687720884, 1.0000106898824919]
				Current Gradient = [-5.03865988897277e-05, 3.0462111008925126e-05]
				Previous Gradient = [-5.03865988897277e-05, 3.0462111008925126e-05]
				|| Gradient || = 5.8879109663737153e-05
				||X optimum - X|| = 1.1917782805931367e-05
				beta" = 0.0
				alpha = 7.167183174969023e-12
			Iteration 62:
				X = [1.0000053311476766, 1.000010652172225]
				Current Gradient = [1.4723336789224025e-05, -2.030309875610883e-06]
				Previous Gradient = [-5.03865988897277e-05, 3.0462111008925126e-05]
				|| Gradient || = 1.4862664781253753e-05
				||X optimum - X|| = 1.1911755062136757e-05
				beta" = 0.2955521240100276
				alpha = 0.0012379400392853823
			Iteration 63:
				X = [1.0000053311476766, 1.000010652172225]
				Current Gradient = [1.4723336789224025e-05, -2.030309875610883e-06]
				Previous Gradient = [1.4723336789224025e-05, -2.030309875610883e-06]
				|| Gradient || = 1.4862664781253753e-05
				||X optimum - X|| = 1.1911755062136757e-05
				beta" = 0.0
				alpha = 1.399840463861137e-11
			Iteration 64:
				X = [1.0000053083644165, 1.0000106553139774]
				Current Gradient = [-4.805739291258679e-06, 7.711393123420286e-06]
				Previous Gradient = [1.4723336789224025e-05, -2.030309875610883e-06]
				|| Gradient || = 9.086292645489751e-06
				||X optimum - X|| = 1.1904387793350694e-05
				beta" = 0.7649373667644358
				alpha = 0.0015474250491067279
			Iteration 65:
				X = [1.0000052927530951, 1.0000106404240412]
				Current Gradient = [-1.137014509320341e-05, 1.0977967556321013e-05]
				Previous Gradient = [-4.805739291258679e-06, 7.711393123420286e-06]
				|| Gradient || = 1.5804935023850443e-05
				||X optimum - X|| = 1.1884101106205575e-05
				beta" = 1.3383919440259269
				alpha = 0.002417851639229262
			Iteration 66:
				X = [1.0000052993503523, 1.0000105939523738]
				Current Gradient = [1.2509676394089535e-05, -9.55282786129467e-07]
				Previous Gradient = [-1.137014509320341e-05, 1.0977967556321013e-05]
				|| Gradient || = 1.2546097747360182e-05
				||X optimum - X|| = 1.1845460778493134e-05
				beta" = 1.2415271007518587
				alpha = 0.002417851639229262
			Iteration 67:
				X = [1.0000050425862557, 1.0000099491732801]
				Current Gradient = [6.44957104131343e-05, -2.720493177175613e-05]
				Previous Gradient = [1.2509676394089535e-05, -9.55282786129467e-07]
				|| Gradient || = 6.999860694614419e-05
				||X optimum - X|| = 1.1154090061664127e-05
				beta" = 25.83785298767976
				alpha = 0.028147497671065627
			Iteration 68:
				X = [1.0000015816195111, 1.0000034390086237]
				Current Gradient = [-0.00010714337541430382, 5.51534199598893e-05]
				Previous Gradient = [6.44957104131343e-05, -2.720493177175613e-05]
				|| Gradient || = 0.00012050561243544784
				||X optimum - X|| = 3.785274176537075e-06
				beta" = 4.6802548037417155
				alpha = 0.011529215046068483
			Iteration 69:
				X = [0.9999984436662376, 0.9999969157952979]
				Current Gradient = [-1.4496410031634473e-05, 5.6920801185216505e-06]
				Previous Gradient = [-0.00010714337541430382, 5.51534199598893e-05]
				|| Gradient || = 1.5573878125917834e-05
				||X optimum - X|| = 3.4546336165144483e-06
				beta" = -0.11187376139451423
				alpha = 0.002417851639229262
			Iteration 70:
				X = [0.9999991977771839, 0.9999983142597625]
				Current Gradient = [3.091402784155081e-05, -1.6259049795876032e-05]
				Previous Gradient = [-1.4496410031634473e-05, 5.6920801185216505e-06]
				|| Gradient || = 3.492898248808509e-05
				||X optimum - X|| = 1.8668908899507116e-06
				beta" = 7.259350304350432
				alpha = 0.004722366482869652
			Iteration 71:
				X = [0.9999993177613682, 0.9999985445901646]
				Current Gradient = [3.500911279571412e-05, -1.8186607442761745e-05]
				Previous Gradient = [3.091402784155081e-05, -1.6259049795876032e-05]
				|| Gradient || = 3.945111746224878e-05
				||X optimum - X|| = 1.6073790280429196e-06
				beta" = 0.14624268830414647
				alpha = 0.0001063382396627935
			Iteration 72:
				X = [0.9999995189270768, 0.9999990629012856]
				Current Gradient = [-1.0980501213096922e-05, 5.009380077280217e-06]
				Previous Gradient = [3.500911279571412e-05, -1.8186607442761745e-05]
				|| Gradient || = 1.2069187862050823e-05
				||X optimum - X|| = 1.0533684815579163e-06
				beta" = 0.3991199269785039
				alpha = 0.0015474250491067279
			Iteration 73:
				X = [0.999999890023671, 0.999999822471051]
				Current Gradient = [-1.718902962303675e-05, 8.484739400204962e-06]
				Previous Gradient = [-1.0980501213096922e-05, 5.009380077280217e-06]
				|| Gradient || = 1.9169077757446375e-05
				||X optimum - X|| = 2.0883323652593876e-07
				beta" = 0.9350620978298972
				alpha = 0.005902958103587064
			Iteration 74:
				X = [0.9999999840734894, 0.9999999609166033]
				Current Gradient = [2.8606972208000307e-06, -1.4460751817825764e-06]
				Previous Gradient = [-1.718902962303675e-05, 8.484739400204962e-06]
				|| Gradient || = 3.205420724407411e-06
				||X optimum - X|| = 4.220385810897052e-08
				beta" = 0.19517270661660444
				alpha = 0.0012379400392853823
			Iteration 75:
				X = [0.9999999840734932, 0.9999999609166107]
				Current Gradient = [2.8606972727584505e-06, -1.4460751929650761e-06]
				Previous Gradient = [2.8606972208000307e-06, -1.4460751817825764e-06]
				|| Gradient || = 3.2054207758228276e-06
				||X optimum - X|| = 4.220384979597816e-08
				beta" = 1.6040146377606067e-08
				alpha = 3.182868713022653e-10
			Iteration 76:
				X = [0.9999999805321218, 0.9999999627067655]
				Current Gradient = [-6.955444000490959e-07, 3.285043015300706e-07]
				Previous Gradient = [2.8606972727584505e-06, -1.4460751929650761e-06]
				|| Gradient || = 7.692184920836318e-07
				||X optimum - X|| = 4.206879628725704e-08
				beta" = 0.2974757734517702
				alpha = 0.0012379400392853823
Running: Quadratic
===================
	- Starting Point : [-0.2  1.2]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Polak-Ribiere Method
			------------
			Iteration 0:
				X = [0.060221282671646836, 1.1528518930343448]
				Current Gradient = [24.347259079460226, 2.5975385103960136]
				Previous Gradient = [-86.09999999986684, 15.600000000226544]
				|| Gradient || = 24.485428952651592
				||X optimum - X|| = 4.104987677056572
				beta" = 0.3468019801263969
				alpha = 0.0030223145490365774
			Iteration 1:
				X = [0.800081933484861, 0.0780833838858701]
				Current Gradient = [0.01964116047581399, 9.219911670355074]
				Previous Gradient = [24.347259079460226, 2.5975385103960136]
				|| Gradient || = 9.219932591094933
				||X optimum - X|| = 3.200870607701763
				beta" = 0.10104455711515069
				alpha = 0.13421772800000006
			Iteration 2:
				X = [0.803253923369504, 0.018882374703959114]
				Current Gradient = [-1.4746896612738425, -2.5874651701229823]
				Previous Gradient = [0.01964116047581399, 9.219911670355074]
				|| Gradient || = 2.978201739920839
				||X optimum - X|| = 3.1968018428621643
				beta" = 0.38531873904037256
				alpha = 0.005902958103587064
			Iteration 3:
				X = [0.8032539233695055, 0.018882374703957896]
				Current Gradient = [-1.4746896608297533, -2.587465170345027]
				Previous Gradient = [-1.4746896612738425, -2.5874651701229823]
				|| Gradient || = 2.9782017398938563
				||X optimum - X|| = 3.1968018428621625
				beta" = -9.060195404465438e-12
				alpha = 9.526820527087468e-16
			Iteration 4:
				X = [0.8141352124739819, 0.037974497822840084]
				Current Gradient = [-1.1647732436337321, 1.483099474786087]
				Previous Gradient = [-1.4746896608297533, -2.587465170345027]
				|| Gradient || = 1.8858103725443376
				||X optimum - X|| = 3.186091101472633
				beta" = 0.6399403756227704
				alpha = 0.00737869762948383
			Iteration 5:
				X = [0.9952528408078971, 0.052811372860605575]
				Current Gradient = [-0.5640105098514425, 10.106343165672271]
				Previous Gradient = [-1.1647732436337321, 1.483099474786087]
				|| Gradient || = 10.122068960323947
				||X optimum - X|| = 3.00521122914454
				beta" = 24.41050897689625
				alpha = 0.08589934592000005
			Iteration 6:
				X = [1.7451309154194323, -0.03207338707420151]
				Current Gradient = [-0.6530153343620171, -34.07000132282789]
				Previous Gradient = [-0.5640105098514425, 10.106343165672271]
				|| Gradient || = 34.07625887864462
				||X optimum - X|| = 2.2550971798917265
				beta" = 14.690619609890721
				alpha = 0.014411518807585602
			Iteration 7:
				X = [1.7451309154194323, -0.03207338707420151]
				Current Gradient = [-0.6530153343620171, -34.07000132282789]
				Previous Gradient = [-0.6530153343620171, -34.07000132282789]
				|| Gradient || = 34.07625887864462
				||X optimum - X|| = 2.2550971798917265
				beta" = 0.0
				alpha = 6.483618076376628e-20
			Iteration 8:
				X = [1.7459393092481064, 0.010103231701833082]
				Current Gradient = [-1.0533587028183078, 4.812021171751724]
				Previous Gradient = [-0.6530153343620171, -34.07000132282789]
				|| Gradient || = 4.925963084939827
				||X optimum - X|| = 2.254083333171985
				beta" = 0.16149173815860987
				alpha = 0.0012379400392853823
			Iteration 9:
				X = [1.7459393092481064, 0.01010323170183314]
				Current Gradient = [-1.0533587030403524, 4.8120211720847905]
				Previous Gradient = [-1.0533587028183078, 4.812021171751724]
				|| Gradient || = 4.925963085312672
				||X optimum - X|| = 2.254083333171985
				beta" = 7.568964047434432e-11
				alpha = 8.183476519740436e-17
			Iteration 10:
				X = [1.7475693028910213, 0.002656989603398033]
				Current Gradient = [-1.1172002307713313, -2.0492728235455004]
				Previous Gradient = [-1.0533587030403524, 4.8120211720847905]
				|| Gradient || = 2.3340213068773954
				||X optimum - X|| = 2.2524322642140855
				beta" = 0.5823994096541412
				alpha = 0.0015474250491067279
			Iteration 11:
				X = [1.7492832811037171, 0.0019110114256940714]
				Current Gradient = [-1.1196198401730584, -2.7318414456134477]
				Previous Gradient = [-1.1172002307713313, -2.0492728235455004]
				|| Gradient || = 2.952372989728858
				||X optimum - X|| = 2.250717530185411
				beta" = 0.34278568226556844
				alpha = 0.0009903520314283058
			Iteration 12:
				X = [1.752596454881393, 0.006695726438592195]
				Current Gradient = [-1.0867382027601735, 1.728725337990511]
				Previous Gradient = [-1.1196198401730584, -2.7318414456134477]
				|| Gradient || = 2.0419332054572252
				||X optimum - X|| = 2.2474135194405642
				beta" = 0.8805547602326212
				alpha = 0.0019342813113834097
			Iteration 13:
				X = [1.782514936811743, 0.011877530542288047]
				Current Gradient = [-1.0095465904358392, 6.981805469208346]
				Previous Gradient = [-1.0867382027601735, 1.728725337990511]
				|| Gradient || = 7.054416483886404
				||X optimum - X|| = 2.217516872809497
				beta" = 8.777582963794973
				alpha = 0.011529215046068483
			Iteration 14:
				X = [1.9229315701734617, -0.006048112333614164]
				Current Gradient = [-1.029528382656686, -10.911691240345078]
				Previous Gradient = [-1.0095465904358392, 6.981805469208346]
				|| Gradient || = 10.96015211643156
				||X optimum - X|| = 2.077077235406734
				beta" = 3.9238360206352
				alpha = 0.005902958103587064
			Iteration 15:
				X = [3.010918106873295, -0.017622383775944002]
				Current Gradient = [-0.2492749649474213, -50.04653477969079]
				Previous Gradient = [-1.029528382656686, -10.911691240345078]
				|| Gradient || = 50.04715557814399
				||X optimum - X|| = 0.9892388688891343
				beta" = 16.302766949910836
				alpha = 0.011529215046068483
			Iteration 16:
				X = [3.9861884884683056, 0.0037248880162580635]
				Current Gradient = [0.017136279600177273, 17.75838052349779]
				Previous Gradient = [-0.2492749649474213, -50.04653477969079]
				|| Gradient || = 17.75838879148174
				||X optimum - X|| = 0.014304986596421161
				beta" = 0.4807368165493851
				alpha = 0.0006338253001141158
			Iteration 17:
				X = [4.03652953354701, 0.0036182341662900157]
				Current Gradient = [0.04135464650237286, 17.788191172773278]
				Previous Gradient = [0.017136279600177273, 17.75838052349779]
				|| Gradient || = 17.788239244116223
				||X optimum - X|| = 0.036708288432508444
				beta" = 0.0016846728906957332
				alpha = 6.805647338418785e-05
			Iteration 18:
				X = [4.036842314852454, -0.0010005297037677346]
				Current Gradient = [0.017632434053420007, -4.825738001433588]
				Previous Gradient = [0.04135464650237286, 17.788191172773278]
				|| Gradient || = 4.82577021429853
				||X optimum - X|| = 0.03685589808125019
				beta" = 0.3448833106382035
				alpha = 0.0002596148429267419
			Iteration 19:
				X = [4.036842314852454, -0.0010005297037677346]
				Current Gradient = [0.017632434053420007, -4.825738001433588]
				Previous Gradient = [0.017632434053420007, -4.825738001433588]
				|| Gradient || = 4.82577021429853
				||X optimum - X|| = 0.03685589808125019
				beta" = 0.0
				alpha = 8.104522595470784e-20
			Iteration 20:
				X = [4.036837737210857, 0.00025230350948005553]
				Current Gradient = [0.019000567594773185, 1.3091597591030386]
				Previous Gradient = [0.017632434053420007, -4.825738001433588]
				|| Gradient || = 1.3092976347735643
				||X optimum - X|| = 0.03683860122041901
				beta" = 0.3448800760467579
				alpha = 0.0002596148429267419
			Iteration 21:
				X = [4.036837737210857, 0.00025230350948005553]
				Current Gradient = [0.019000567594773185, 1.3091597591030386]
				Previous Gradient = [0.019000567594773185, 1.3091597591030386]
				|| Gradient || = 1.3092976347735643
				||X optimum - X|| = 0.03683860122041901
				beta" = 0.0
				alpha = 6.483618076376628e-20
			Iteration 22:
				X = [4.036832804381485, -8.757379574549106e-05]
				Current Gradient = [0.018250542348544584, -0.3551662557904991]
				Previous Gradient = [0.019000567594773185, 1.3091597591030386]
				|| Gradient || = 0.3556348570489938
				||X optimum - X|| = 0.03683290848920936
				beta" = 0.34481271717609774
				alpha = 0.0002596148429267419
			Iteration 23:
				X = [4.036832804381485, -8.75737957454911e-05]
				Current Gradient = [0.018250542348544584, -0.3551662557904991]
				Previous Gradient = [0.018250542348544584, -0.3551662557904991]
				|| Gradient || = 0.3556348570489938
				||X optimum - X|| = 0.03683290848920936
				beta" = 0.0
				alpha = 4.830671903771628e-19
			Iteration 24:
				X = [4.0368280662698, 4.632635964438357e-06]
				Current Gradient = [0.01842332440009603, 0.09634119769929228]
				Previous Gradient = [0.018250542348544584, -0.3551662557904991]
				|| Gradient || = 0.09808692703966872
				||X optimum - X|| = 0.03682806656117192
				beta" = 0.34395379307973045
				alpha = 0.0002596148429267419
			Iteration 25:
				X = [4.0368280662698, 4.63263596449841e-06]
				Current Gradient = [0.018423324400123134, 0.09634119769959043]
				Previous Gradient = [0.01842332440009603, 0.09634119769929228]
				|| Gradient || = 0.09808692703996665
				||X optimum - X|| = 0.03682806656117192
				beta" = 3.037455749642992e-12
				alpha = 2.3258839177459632e-15
			Iteration 26:
				X = [4.03682328330133, -2.0378968943634583e-05]
				Current Gradient = [0.01837138666600747, -0.026144815273057263]
				Previous Gradient = [0.018423324400123134, 0.09634119769959043]
				|| Gradient || = 0.0319540171761587
				||X optimum - X|| = 0.03682328894045702
				beta" = 0.33275178832183894
				alpha = 0.0002596148429267419
			Iteration 27:
				X = [4.03677588996462, -3.181616263176715e-05]
				Current Gradient = [0.018325538549579957, -0.08224140155691016]
				Previous Gradient = [0.01837138666600747, -0.026144815273057263]
				|| Gradient || = 0.08425837343063944
				||X optimum - X|| = 0.03677590372727809
				beta" = 4.517486963785853
				alpha = 0.0019342813113834097
			Iteration 28:
				X = [4.036694118886169, 3.380153479925307e-06]
				Current Gradient = [0.01835383358887873, 0.0899390572854555]
				Previous Gradient = [0.018325538549579957, -0.08224140155691016]
				|| Gradient || = 0.09179268616183263
				||X optimum - X|| = 0.036694119041854
				beta" = 2.181326191102089
				alpha = 0.0006338253001141158
			Iteration 29:
				X = [4.036504116366988, 2.314914966873403e-05]
				Current Gradient = [0.018299005413729846, 0.1863466927665375]
				Previous Gradient = [0.01835383358887873, 0.0899390572854555]
				|| Gradient || = 0.18724300655607418
				||X optimum - X|| = 0.03650412370702419
				beta" = 2.132027039011009
				alpha = 0.0006338253001141158
			Iteration 30:
				X = [4.036087427486015, -5.2814064390643756e-05]
				Current Gradient = [0.017941463005072485, -0.1863500175067873]
				Previous Gradient = [0.018299005413729846, 0.1863466927665375]
				|| Gradient || = 0.18721171202556297
				||X optimum - X|| = 0.03608746613276932
				beta" = 1.980768270263252
				alpha = 0.0006338253001141158
			Iteration 31:
				X = [4.034453177745434, -0.0001160018931865826]
				Current Gradient = [0.017010871900923884, -0.4984639771965689]
				Previous Gradient = [0.017941463005072485, -0.1863500175067873]
				|| Gradient || = 0.4987541541936781
				||X optimum - X|| = 0.03445337303077482
				beta" = 4.438505373350121
				alpha = 0.0012379400392853823
			Iteration 32:
				X = [4.029797379541024, 9.942786545147586e-05]
				Current Gradient = [0.015109496956199195, 0.5447808759177472]
				Previous Gradient = [0.017010871900923884, -0.4984639771965689]
				|| Gradient || = 0.5449903665790591
				||X optimum - X|| = 0.02979754542596171
				beta" = 2.284615394164377
				alpha = 0.0007922816251426447
			Iteration 33:
				X = [4.003799627522656, 0.00024726542704053443]
				Current Gradient = [0.002467782538417124, 1.1987073388531098]
				Previous Gradient = [0.015109496956199195, 0.5447808759177472]
				|| Gradient || = 1.1987098790662238
				||X optimum - X|| = 0.003807664573243565
				beta" = 2.639047097281645
				alpha = 0.0019342813113834097
			Iteration 34:
				X = [3.9945904035577615, -1.157170524646305e-05]
				Current Gradient = [-0.002727781164069299, -0.06630581748589869]
				Previous Gradient = [0.002467782538417124, 1.1987073388531098]
				|| Gradient || = 0.06636190339759973
				||X optimum - X|| = 0.005409608818781777
				beta" = 0.05838373586060368
				alpha = 0.0002596148429267419
			Iteration 35:
				X = [3.9945904035577615, -1.1571705246462222e-05]
				Current Gradient = [-0.002727781164069299, -0.06630581748589445]
				Previous Gradient = [-0.002727781164069299, -0.06630581748589869]
				|| Gradient || = 0.0663619033975955
				||X optimum - X|| = 0.005409608818781777
				beta" = -6.372855158729692e-14
				alpha = 1.0229345649675545e-16
			Iteration 36:
				X = [3.99459111173024, 5.6422691452673485e-06]
				Current Gradient = [-0.0026931214463824706, 0.016237058864256422]
				Previous Gradient = [-0.002727781164069299, -0.06630581748589445]
				|| Gradient || = 0.016458887680712
				||X optimum - X|| = 0.005408891212619177
				beta" = 0.3043119786880437
				alpha = 0.0002596148429267419
			Iteration 37:
				X = [3.99459111173024, 5.642269145311052e-06]
				Current Gradient = [-0.0026931214463824706, 0.016237058864466063]
				Previous Gradient = [-0.0026931214463824706, 0.016237058864256422]
				|| Gradient || = 0.016458887680918816
				||X optimum - X|| = 0.005408891212619177
				beta" = 1.2565602370905332e-11
				alpha = 1.1090678776483354e-14
			Iteration 38:
				X = [3.994591810904541, 1.4268876586332882e-06]
				Current Gradient = [-0.0027012383328831363, -0.003974410315480397]
				Previous Gradient = [-0.0026931214463824706, 0.016237058864466063]
				|| Gradient || = 0.004805478736487579
				||X optimum - X|| = 0.005408189283692762
				beta" = 0.2966116099653671
				alpha = 0.0002596148429267419
			Iteration 39:
				X = [3.994600273504771, -6.081935379600959e-07]
				Current Gradient = [-0.0027010791917879405, -0.013715771052192587]
				Previous Gradient = [-0.0027012383328831363, -0.003974410315480397]
				|| Gradient || = 0.013979206141854906
				||X optimum - X|| = 0.005399726529480695
				beta" = 5.785822903104161
				alpha = 0.002417851639229262
			Iteration 40:
				X = [3.99461482090162, 4.998563338304439e-06]
				Current Gradient = [-0.0026825624804913484, 0.013198174240678992]
				Previous Gradient = [-0.0027010791917879405, -0.013715771052192587]
				|| Gradient || = 0.013468034182799746
				||X optimum - X|| = 0.005385181418231456
				beta" = 1.817462546102189
				alpha = 0.0006338253001141158
			Iteration 41:
				X = [3.994722165051725, 1.1959370675702748e-05]
				Current Gradient = [-0.0026148273277567338, 0.04679359725010563]
				Previous Gradient = [-0.0026825624804913484, 0.013198174240678992]
				|| Gradient || = 0.046866598613074927
				||X optimum - X|| = 0.0052778484979941675
				beta" = 8.66581062041471
				alpha = 0.002417851639229262
			Iteration 42:
				X = [3.9951057744328193, -9.675266192092145e-06]
				Current Gradient = [-0.002466351120833902, -0.05619355346860806]
				Previous Gradient = [-0.0026148273277567338, 0.04679359725010563]
				|| Gradient || = 0.05624765185570463
				||X optimum - X|| = 0.004894235130561342
				beta" = 2.6346030296274905
				alpha = 0.0009903520314283058
			Iteration 43:
				X = [4.001144326916541, -1.7705680808986373e-05]
				Current Gradient = [0.0005371283937077311, -0.0828888930611555]
				Previous Gradient = [-0.002466351120833902, -0.05619355346860806]
				|| Gradient || = 0.08289063336599016
				||X optimum - X|| = 0.0011444638845560413
				beta" = 0.6999056720374349
				alpha = 0.005902958103587064
			Iteration 44:
				X = [4.001330067261355, 3.566312499416202e-06]
				Current Gradient = [0.0006721815231468604, 0.019818351157905104]
				Previous Gradient = [0.0005371283937077311, -0.0828888930611555]
				|| Gradient || = 0.01982974711432545
				||X optimum - X|| = 0.0013300720425274675
				beta" = 0.2962627490341959
				alpha = 0.0002596148429267419
			Iteration 45:
				X = [4.001330067261355, 3.566312499416241e-06]
				Current Gradient = [0.0006721815231468604, 0.019818351157905287]
				Previous Gradient = [0.0006721815231468604, 0.019818351157905104]
				|| Gradient || = 0.019829747114325634
				||X optimum - X|| = 0.0013300720425274675
				beta" = 9.267642850408857e-15
				alpha = 8.786941004967274e-18
			Iteration 46:
				X = [4.001329892753055, -1.5788256235103428e-06]
				Current Gradient = [0.0006617917175956116, -0.004936248134364133]
				Previous Gradient = [0.0006721815231468604, 0.019818351157905287]
				|| Gradient || = 0.004980413027198802
				||X optimum - X|| = 0.0013298936902316047
				beta" = 0.3107378048618738
				alpha = 0.0002596148429267419
			Iteration 47:
				X = [4.001329892753055, -1.5788256235103432e-06]
				Current Gradient = [0.0006617917175956116, -0.004936248134364133]
				Previous Gradient = [0.0006617917175956116, -0.004936248134364133]
				|| Gradient || = 0.004980413027198802
				||X optimum - X|| = 0.0013298936902316047
				beta" = 0.0
				alpha = 3.8645375230173027e-19
			Iteration 48:
				X = [4.001329720942102, -2.9730233945997596e-07]
				Current Gradient = [0.0006642659725665589, 0.001229063288499906]
				Previous Gradient = [0.0006617917175956116, -0.004936248134364133]
				|| Gradient || = 0.0013970847681683454
				||X optimum - X|| = 0.0013297209753375093
				beta" = 0.30555734812561947
				alpha = 0.0002596148429267419
			Iteration 49:
				X = [4.001329034444893, -7.606276534883935e-08]
				Current Gradient = [0.0006643651039536661, 0.0022921164576761763]
				Previous Gradient = [0.0006642659725665589, 0.001229063288499906]
				|| Gradient || = 0.00238645738426257
				||X optimum - X|| = 0.0013290344470698924
				beta" = 1.248411868476791
				alpha = 0.0007922816251426447
			Iteration 50:
				X = [4.001328326146384, -8.644422300563157e-07]
				Current Gradient = [0.0006624350858346124, -0.0015023422337663555]
				Previous Gradient = [0.0006643651039536661, 0.0022921164576761763]
				|| Gradient || = 0.0016419051221988417
				||X optimum - X|| = 0.0013283264276625947
				beta" = 1.00072310070095
				alpha = 0.00040564819207303417
			Iteration 51:
				X = [4.001325342972934, -1.4123155560107077e-06]
				Current Gradient = [0.0006598492498024988, -0.00414422031758356]
				Previous Gradient = [0.0006624350858346124, -0.0015023422337663555]
				|| Gradient || = 0.004196422651871151
				||X optimum - X|| = 0.0013253437254316174
				beta" = 4.060614908486869
				alpha = 0.0012379400392853823
			Iteration 52:
				X = [4.001317067534605, 4.4726439114064097e-07]
				Current Gradient = [0.000659428536310316, 0.0047859962804279515]
				Previous Gradient = [0.0006598492498024988, -0.00414422031758356]
				|| Gradient || = 0.00483121168970793
				||X optimum - X|| = 0.0013170676105483073
				beta" = 2.4270184902439094
				alpha = 0.0007922816251426447
			Iteration 53:
				X = [4.00121880524865, 3.887062769317351e-06]
				Current Gradient = [0.0006171948865824777, 0.021137980198513918]
				Previous Gradient = [0.000659428536310316, 0.0047859962804279515]
				|| Gradient || = 0.021146988825853908
				||X optimum - X|| = 0.0012188114470224806
				beta" = 14.80774921130296
				alpha = 0.0037778931862957215
			Iteration 54:
				X = [4.000741252613988, -5.589888358347613e-06]
				Current Gradient = [0.000359484033498213, -0.025403623366793936]
				Previous Gradient = [0.0006171948865824777, 0.021137980198513918]
				|| Gradient || = 0.025406166750067963
				||X optimum - X|| = 0.0007412736907485519
				beta" = 2.643661857411656
				alpha = 0.0012379400392853823
			Iteration 55:
				X = [3.999730906450116, -4.7444172801345917e-07]
				Current Gradient = [-0.00013549538832126522, -0.0028189965322779433]
				Previous Gradient = [0.000359484033498213, -0.025403623366793936]
				|| Gradient || = 0.0028222509543361658
				||X optimum - X|| = 0.00026909396813046445
				beta" = -0.09853066954159072
				alpha = 0.0009903520314283058
			Iteration 56:
				X = [3.999810653867818, 1.355774720658311e-06]
				Current Gradient = [-9.195931101662834e-05, 0.0061392565014748235]
				Previous Gradient = [-0.00013549538832126522, -0.0028189965322779433]
				|| Gradient || = 0.006139945187522732
				||X optimum - X|| = 0.00018935098599505873
				beta" = 6.9042455876144615
				alpha = 0.0007922816251426447
			Iteration 57:
				X = [3.9998147170850182, 1.4131237569853482e-06]
				Current Gradient = [-8.981281379791047e-05, 0.006423104821712133]
				Previous Gradient = [-9.195931101662834e-05, 0.0061392565014748235]
				|| Gradient || = 0.006423732707096705
				||X optimum - X|| = 0.00018528830374012504
				beta" = 0.04835667434121199
				alpha = 5.846006549323628e-06
			Iteration 58:
				X = [3.999825653265714, -5.173489236854879e-07]
				Current Gradient = [-8.820774383687471e-05, -0.0028358906229511596]
				Previous Gradient = [-8.981281379791047e-05, 0.006423104821712133]
				|| Gradient || = 0.0028372621012897467
				||X optimum - X|| = 0.0001743475018637369
				beta" = 0.6363207451229517
				alpha = 0.00032451855365842736
			Iteration 59:
				X = [3.9998256532657153, -5.173489237356968e-07]
				Current Gradient = [-8.820774383620799e-05, -0.002835890623170337]
				Previous Gradient = [-8.820774383687471e-05, -0.0028358906229511596]
				|| Gradient || = 0.002837262101508797
				||X optimum - X|| = 0.00017434750186240476
				beta" = 7.720501634396705e-11
				alpha = 5.2884477503220316e-14
			Iteration 60:
				X = [3.9998256761657554, 2.1889037493706085e-07]
				Current Gradient = [-8.672407889148313e-05, 0.0007036856774510052]
				Previous Gradient = [-8.820774383620799e-05, -0.002835890623170337]
				|| Gradient || = 0.0007090095898570458
				||X optimum - X|| = 0.0001743239716698547
				beta" = 0.3093916869067806
				alpha = 0.0002596148429267419
			Iteration 61:
				X = [3.9998256761657554, 2.1889037493706125e-07]
				Current Gradient = [-8.672407889148395e-05, 0.000703685677451006]
				Previous Gradient = [-8.672407889148313e-05, 0.0007036856774510052]
				|| Gradient || = 0.0007090095898570467
				||X optimum - X|| = 0.0001743239716698547
				beta" = 1.2050088392711097e-15
				alpha = 2.303443862806142e-18
			Iteration 62:
				X = [3.9998256986806133, 3.620312831582043e-08]
				Current Gradient = [-8.707825187622961e-05, -0.00017455314209876806]
				Previous Gradient = [-8.672407889148395e-05, 0.000703685677451006]
				|| Gradient || = 0.00019506773532896926
				||X optimum - X|| = 0.00017430132314644374
				beta" = 0.30501657802689874
				alpha = 0.0002596148429267419
			Iteration 63:
				X = [3.999825756247433, 1.587880752436326e-08]
				Current Gradient = [-8.709011837809866e-05, -0.0002721488386817896]
				Previous Gradient = [-8.707825187622961e-05, -0.00017455314209876806]
				|| Gradient || = 0.00028574407975487083
				||X optimum - X|| = 0.00017424375329043275
				beta" = 0.6980445929921398
				alpha = 0.0005070602400912927
			Iteration 64:
				X = [3.999825810227685, 9.511629440298106e-08]
				Current Gradient = [-8.690464272484189e-05, 0.00010889983582951006]
				Previous Gradient = [-8.709011837809866e-05, -0.0002721488386817896]
				|| Gradient || = 0.00013932548643671283
				||X optimum - X|| = 0.000174189798284208
				beta" = 0.5080242794775846
				alpha = 0.00032451855365842736
			Iteration 65:
				X = [3.9998282804937886, 3.1336615534637134e-07]
				Current Gradient = [-8.523290297395028e-05, 0.00116309631864942]
				Previous Gradient = [-8.690464272484189e-05, 0.00010889983582951006]
				|| Gradient || = 0.0011662151148931314
				||X optimum - X|| = 0.0001717197921377774
				beta" = 63.157602603517475
				alpha = 0.014411518807585602
			Iteration 66:
				X = [3.9998926878084182, -9.063597651202042e-07]
				Current Gradient = [-5.5467829569718084e-05, -0.004572168704712599]
				Previous Gradient = [-8.523290297395028e-05, 0.00116309631864942]
				|| Gradient || = 0.004572505149747833
				||X optimum - X|| = 0.00010731601907500919
				beta" = 19.279291136508046
				alpha = 0.005902958103587064
			Iteration 67:
				X = [4.000059393580966, -4.401049365415674e-07]
				Current Gradient = [2.881681304846348e-05, -0.001997300108001856]
				Previous Gradient = [-5.5467829569718084e-05, -0.004572168704712599]
				|| Gradient || = 0.0019975079799936964
				||X optimum - X|| = 5.939521152714974e-05
				beta" = -0.2458582772575797
				alpha = 0.0007922816251426447
			Iteration 68:
				X = [4.000038397062526, 3.1140434553096703e-07]
				Current Gradient = [1.982145632490559e-05, 0.00157405491533392]
				Previous Gradient = [2.881681304846348e-05, -0.001997300108001856]
				|| Gradient || = 0.0015741797123002552
				||X optimum - X|| = 3.8398325266713114e-05
				beta" = 1.4088413304508
				alpha = 0.00040564819207303417
			Iteration 69:
				X = [4.000038397062526, 3.1140434553096703e-07]
				Current Gradient = [1.982145632490559e-05, 0.00157405491533392]
				Previous Gradient = [1.982145632490559e-05, 0.00157405491533392]
				|| Gradient || = 0.0015741797123002552
				||X optimum - X|| = 3.8398325266713114e-05
				beta" = 0.0
				alpha = 2.1245519712670938e-20
			Iteration 70:
				X = [4.000038391916582, -9.724367407151465e-08]
				Current Gradient = [1.9001482293277743e-05, -0.0003907727119037711]
				Previous Gradient = [1.982145632490559e-05, 0.00157405491533392]
				|| Gradient || = 0.0003912344165560712
				||X optimum - X|| = 3.8392039736889114e-05
				beta" = 0.30983555238660637
				alpha = 0.0002596148429267419
			Iteration 71:
				X = [4.000038391916582, -9.724367411925287e-08]
				Current Gradient = [1.9001482292833623e-05, -0.0003907727121329183]
				Previous Gradient = [1.9001482293277743e-05, -0.0003907727119037711]
				|| Gradient || = 0.0003912344167849264
				||X optimum - X|| = 3.8392039736889236e-05
				beta" = 5.849567725667805e-10
				alpha = 4.925250774549347e-13
			Iteration 72:
				X = [4.0000383869835145, 4.206722146472196e-09]
				Current Gradient = [1.9201905225358073e-05, 9.700027467387253e-05]
				Previous Gradient = [1.9001482292833623e-05, -0.0003907727121329183]
				|| Gradient || = 9.888258922120897e-05
				||X optimum - X|| = 3.83869837450504e-05
				beta" = 0.309137668995456
				alpha = 0.0002596148429267419
			Iteration 73:
				X = [4.0000383869835145, 4.206722191192751e-09]
				Current Gradient = [1.9201905225358073e-05, 9.700027488853541e-05]
				Previous Gradient = [1.9201905225358073e-05, 9.700027467387253e-05]
				|| Gradient || = 9.888258943178556e-05
				||X optimum - X|| = 3.838698374505041e-05
				beta" = 2.129561867279452e-09
				alpha = 1.87883406621908e-12
			Iteration 74:
				X = [4.000038381998415, -2.0975988924685683e-08]
				Current Gradient = [1.9149047760332922e-05, -2.4090490176317455e-05]
				Previous Gradient = [1.9201905225358073e-05, 9.700027488853541e-05]
				|| Gradient || = 3.0773978408109006e-05
				||X optimum - X|| = 3.838200414685511e-05
				beta" = 0.298240269726429
				alpha = 0.0002596148429267419
			Iteration 75:
				X = [4.00003828802019, -3.9256828537530685e-08]
				Current Gradient = [1.906549829004304e-05, -0.00011217439860292358]
				Previous Gradient = [1.9149047760332922e-05, -2.4090490176317455e-05]
				|| Gradient || = 0.00011378307838591473
				||X optimum - X|| = 3.828804031497285e-05
				beta" = 10.431650240665546
				alpha = 0.0037778931862957215
			Iteration 76:
				X = [4.000038067321073, 9.6243392158877e-09]
				Current Gradient = [1.905290932904024e-05, 0.00012240934439738515]
				Previous Gradient = [1.906549829004304e-05, -0.00011217439860292358]
				|| Gradient || = 0.00012388325532410857
				||X optimum - X|| = 3.806732228977585e-05
				beta" = 2.217958915092301
				alpha = 0.0007922816251426447
			Iteration 77:
				X = [4.000030724470592, 1.7600726338941852e-07]
				Current Gradient = [1.5714286999468267e-05, 0.0009077048421628164]
				Previous Gradient = [1.905290932904024e-05, 0.00012240934439738515]
				|| Gradient || = 0.0009078408557130072
				||X optimum - X|| = 3.072497472249373e-05
				beta" = 46.44303323724562
				alpha = 0.011529215046068483
			Iteration 78:
				X = [3.9999940878173366, -1.1796141306854503e-07]
				Current Gradient = [-3.1919974604791655e-06, -0.0005789811655795378]
				Previous Gradient = [1.5714286999468267e-05, 0.0009077048421628164]
				|| Gradient || = 0.0005789899644584765
				||X optimum - X|| = 5.913359344806897e-06
				beta" = 1.0444669230023085
				alpha = 0.0012379400392853823
			Iteration 79:
				X = [3.99998997948559, -7.3969844618368e-08]
				Current Gradient = [-5.1581903289536715e-06, -0.00037568626282838847]
				Previous Gradient = [-3.1919974604791655e-06, -0.0005789811655795378]
				|| Gradient || = 0.00037572167225944085
				||X optimum - X|| = 1.0020787422890591e-05
				beta" = -0.22779912819765855
				alpha = 0.00013292279957849188
			Iteration 80:
				X = [3.9999928376399825, 4.78442083520072e-08]
				Current Gradient = [-3.485488845624798e-06, 0.0002157094112960439]
				Previous Gradient = [-5.1581903289536715e-06, -0.00037568626282838847]
				|| Gradient || = 0.00021573756917648535
				||X optimum - X|| = 7.162519814203193e-06
				beta" = 0.9036388521388177
				alpha = 0.00040564819207303417
			Iteration 81:
				X = [3.9999949049625716, 6.590323098812578e-08]
				Current Gradient = [-2.415707040696299e-06, 0.0003066718538636706]
				Previous Gradient = [-3.485488845624798e-06, 0.0002157094112960439]
				|| Gradient || = 0.00030668136818640774
				||X optimum - X|| = 5.095463632751648e-06
				beta" = 0.5992999409437814
				alpha = 0.00032451855365842736
			Iteration 82:
				X = [3.999996144692819, -2.279470427613291e-08]
				Current Gradient = [-1.973242375756424e-06, -0.00011730734160835037]
				Previous Gradient = [-2.415707040696299e-06, 0.0003066718538636706]
				|| Gradient || = 0.00011732393652060815
				||X optimum - X|| = 3.855374567903947e-06
				beta" = 0.5287949894223815
				alpha = 0.00032451855365842736
			Iteration 83:
				X = [3.9999964806690094, -2.7318027108820955e-08]
				Current Gradient = [-1.8143006541658166e-06, -0.0001383835055816243]
				Previous Gradient = [-1.973242375756424e-06, -0.00011730734160835037]
				|| Gradient || = 0.00013839539842033457
				||X optimum - X|| = 3.5194370141007113e-06
				beta" = 0.21186523683267872
				alpha = 0.00016615349947311482
			Iteration 84:
				X = [3.9999965923613963, 7.110986732626039e-09]
				Current Gradient = [-1.6895972680482497e-06, 2.7374288847274355e-05]
				Previous Gradient = [-1.8143006541658166e-06, -0.0001383835055816243]
				|| Gradient || = 2.74263819856394e-05
				||X optimum - X|| = 3.407646023255058e-06
				beta" = 0.23689360524798955
				alpha = 0.0002596148429267419
			Iteration 85:
				X = [3.999996694968577, 1.1113525469796902e-08]
				Current Gradient = [-1.6302885127521304e-06, 4.682367945941132e-05]
				Previous Gradient = [-1.6895972680482497e-06, 2.7374288847274355e-05]
				|| Gradient || = 4.685205223629493e-05
				||X optimum - X|| = 3.3050501083689953e-06
				beta" = 1.2105657522057047
				alpha = 0.0009903520314283058
			Iteration 86:
				X = [3.999996736199666, -2.4939074609511485e-09]
				Current Gradient = [-1.6368879745915805e-06, -1.851828820498859e-05]
				Previous Gradient = [-1.6302885127521304e-06, 4.682367945941132e-05]
				|| Gradient || = 1.859049220124045e-05
				||X optimum - X|| = 3.2638012868084504e-06
				beta" = 0.5512386834427938
				alpha = 0.00032451855365842736
			Iteration 87:
				X = [3.9999967652738806, -4.358176597537224e-09]
				Current Gradient = [-1.6260793903323609e-06, -2.742353148603442e-05]
				Previous Gradient = [-1.6368879745915805e-06, -1.851828820498859e-05]
				|| Gradient || = 2.747169840670913e-05
				||X optimum - X|| = 3.2347290553100587e-06
				beta" = 0.7065715325049479
				alpha = 0.00040564819207303417
			Iteration 88:
				X = [3.9999967822359834, 3.48747657584557e-09]
				Current Gradient = [-1.6019070408553798e-06, 1.0332232411275236e-05]
				Previous Gradient = [-1.6260793903323609e-06, -2.742353148603442e-05]
				|| Gradient || = 1.0455674668243485e-05
				||X optimum - X|| = 3.2177659064696816e-06
				beta" = 0.5168485443453923
				alpha = 0.00032451855365842736
			Iteration 89:
				X = [3.999996817661882, 6.16544480678711e-09]
				Current Gradient = [-1.5788381239192837e-06, 2.3278735305887874e-05]
				Previous Gradient = [-1.6019070408553798e-06, 1.0332232411275236e-05]
				|| Gradient || = 2.3332214795495338e-05
				||X optimum - X|| = 3.1823440903572705e-06
				beta" = 2.7564825235954795
				alpha = 0.0012379400392853823
			Iteration 90:
				X = [3.9999968584602446, -2.6147022382819336e-09]
				Current Gradient = [-1.5759992742047295e-06, -1.8854548158731726e-05]
				Previous Gradient = [-1.5788381239192837e-06, 2.3278735305887874e-05]
				|| Gradient || = 1.892030020856508e-05
				||X optimum - X|| = 3.1415408435544495e-06
				beta" = 1.4592411117862654
				alpha = 0.0005070602400912927
			Iteration 91:
				X = [3.999996906727264, -5.216270093893209e-09]
				Current Gradient = [-1.5570688758196568e-06, -3.1266333359065106e-05]
				Previous Gradient = [-1.5759992742047295e-06, -1.8854548158731726e-05]
				|| Gradient || = 3.130508050148144e-05
				||X optimum - X|| = 3.0932771343426083e-06
				beta" = 1.083982250014265
				alpha = 0.00040564819207303417
			Iteration 92:
				X = [3.9999969596794784, 4.646808128274053e-09]
				Current Gradient = [-1.5108666187605768e-06, 1.6261178531025242e-05]
				Previous Gradient = [-1.5570688758196568e-06, -3.1266333359065106e-05]
				|| Gradient || = 1.6331216891510604e-05
				||X optimum - X|| = 3.0403240726385722e-06
				beta" = 0.7885481538065036
				alpha = 0.00040564819207303417
			Iteration 93:
				X = [3.9999972753475497, 1.3447392584985306e-08]
				Current Gradient = [-1.335431223285039e-06, 5.9205670713574584e-05]
				Previous Gradient = [-1.5108666187605768e-06, 1.6261178531025242e-05]
				|| Gradient || = 5.9220729657750316e-05
				||X optimum - X|| = 2.7246856346066875e-06
				beta" = 9.532211375131839
				alpha = 0.0030223145490365774
			Iteration 94:
				X = [3.999998065200758, -1.1469166213412811e-08]
				Current Gradient = [-9.903377957098916e-07, -5.9013296381136734e-05]
				Previous Gradient = [-1.335431223285039e-06, 5.9205670713574584e-05]
				|| Gradient || = 5.902160552473558e-05
				||X optimum - X|| = 1.9348332355043053e-06
				beta" = 1.989153284879806
				alpha = 0.0007922816251426447
			Iteration 95:
				X = [4.00000003010542, -1.4978796738241418e-08]
				Current Gradient = [-1.4904613984706505e-08, -7.19578449591336e-05]
				Previous Gradient = [-9.903377957098916e-07, -5.9013296381136734e-05]
				|| Gradient || = 7.195784650272843e-05
				||X optimum - X|| = 3.362589311695004e-08
				beta" = 0.2673845080220213
				alpha = 0.0009903520314283058
			Iteration 96:
				X = [4.000000167835832, 3.4565264877914647e-09]
				Current Gradient = [9.083098340908821e-08, 1.695465241048171e-05]
				Previous Gradient = [-1.4904613984706505e-08, -7.19578449591336e-05]
				|| Gradient || = 1.69548957126784e-05
				||X optimum - X|| = 1.6787142161093628e-07
				beta" = 0.2911375018114634
				alpha = 0.0002596148429267419
			Iteration 97:
				X = [4.000000167835832, 3.456526487791465e-09]
				Current Gradient = [9.083098340908821e-08, 1.695465241048171e-05]
				Previous Gradient = [9.083098340908821e-08, 1.695465241048171e-05]
				|| Gradient || = 1.69548957126784e-05
				||X optimum - X|| = 1.6787142161093628e-07
				beta" = 0.0
				alpha = 1.5829145694278876e-19
			Iteration 98:
				X = [4.000000167812251, -9.451529346332498e-10]
				Current Gradient = [8.201582090392456e-08, -4.208671188124801e-06]
				Previous Gradient = [9.083098340908821e-08, 1.695465241048171e-05]
				|| Gradient || = 4.209470247505067e-06
				||X optimum - X|| = 1.6781491283235037e-07
				beta" = 0.30983829816195735
				alpha = 0.0002596148429267419
			Iteration 99:
				X = [4.000000167812251, -9.451529346332498e-10]
				Current Gradient = [8.201582090392456e-08, -4.208671188124801e-06]
				Previous Gradient = [8.201582090392456e-08, -4.208671188124801e-06]
				|| Gradient || = 4.209470247505067e-06
				||X optimum - X|| = 1.6781491283235037e-07
				beta" = 0.0
				alpha = 8.104522595470784e-20
			Iteration 100:
				X = [4.000000167790959, 1.4748057480207467e-10]
				Current Gradient = [8.419044052717751e-08, 1.0446685809265243e-06]
				Previous Gradient = [8.201582090392456e-08, -4.208671188124801e-06]
				|| Gradient || = 1.0480555683031308e-06
				||X optimum - X|| = 1.6779102371917118e-07
				beta" = 0.30972311834457134
				alpha = 0.0002596148429267419
			Iteration 101:
				X = [4.000000167790959, 1.4748057480207821e-10]
				Current Gradient = [8.419044052717751e-08, 1.0446685809265243e-06]
				Previous Gradient = [8.419044052717751e-08, 1.0446685809265243e-06]
				|| Gradient || = 1.0480555683031308e-06
				||X optimum - X|| = 1.6779102371917118e-07
				beta" = 0.0
				alpha = 1.3729595320261364e-17
			Iteration 102:
				X = [4.000000167769102, -1.2373089474566375e-10]
				Current Gradient = [8.363708919190659e-08, -2.593599884595895e-07]
				Previous Gradient = [8.419044052717751e-08, 1.0446685809265243e-06]
				|| Gradient || = 2.725119562555987e-07
				||X optimum - X|| = 1.6776914734831218e-07
				beta" = 0.30786621511448586
				alpha = 0.0002596148429267419
	- Starting Point : [3.8 0.1]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Polak-Ribiere Method
			------------
			Iteration 0:
				X = [3.7970144293060404, -0.012568995892813503]
				Current Gradient = [0.05332453489881317, -54.86988849992547]
				Previous Gradient = [11.500000001163357, 433.5999999991458]
				|| Gradient || = 54.869914411271644
				||X optimum - X|| = 0.20337433851817696
				beta" = 0.1424551161809335
				alpha = 0.0002596148429267419
			Iteration 1:
				X = [3.7970144293060404, -0.012568995892813503]
				Current Gradient = [0.05332453489881317, -54.86988849992547]
				Previous Gradient = [0.05332453489881317, -54.86988849992547]
				|| Gradient || = 54.869914411271644
				||X optimum - X|| = 0.20337433851817696
				beta" = 0.0
				alpha = 1.013065324433848e-19
			Iteration 2:
				X = [3.7970005854652884, 0.001676041591502489]
				Current Gradient = [-0.09494776023223628, 6.856564314382946]
				Previous Gradient = [0.05332453489881317, -54.86988849992547]
				|| Gradient || = 6.857221687713093
				||X optimum - X|| = 0.20300633344024546
				beta" = 0.14058006986330215
				alpha = 0.0002596148429267419
			Iteration 3:
				X = [3.7970005854652884, 0.0016760415915024892]
				Current Gradient = [-0.094947760233971, 6.856564314381211]
				Previous Gradient = [-0.09494776023223628, 6.856564314382946]
				|| Gradient || = 6.857221687711382
				||X optimum - X|| = 0.20300633344024546
				beta" = -2.494343314398232e-13
				alpha = 3.0916300184138424e-19
			Iteration 4:
				X = [3.7970252353131477, -0.00010402427599274827]
				Current Gradient = [-0.10168310456918489, -0.8567096225009855]
				Previous Gradient = [-0.094947760233971, 6.856564314381211]
				|| Gradient || = 0.862722916723909
				||X optimum - X|| = 0.2029747913429967
				beta" = 0.14054682179176883
				alpha = 0.0002596148429267419
			Iteration 5:
				X = [3.7970252353131477, -0.00010402427599275528]
				Current Gradient = [-0.10168310457005225, -0.8567096225001181]
				Previous Gradient = [-0.10168310456918489, -0.8567096225009855]
				|| Gradient || = 0.8627229167231499
				||X optimum - X|| = 0.2029747913429967
				beta" = -8.799365012207668e-13
				alpha = 6.546781215792349e-17
			Iteration 6:
				X = [3.7970582333671743, 0.0001739938916062709]
				Current Gradient = [-0.10108841004812658, 0.3480833913509576]
				Previous Gradient = [-0.10168310457005225, -0.8567096225001181]
				|| Gradient || = 0.3624650520814967
				||X optimum - X|| = 0.20294184122040138
				beta" = 0.5633662325626555
				alpha = 0.00032451855365842736
			Iteration 7:
				X = [3.7970582333671747, 0.00017399389160652128]
				Current Gradient = [-0.10108841004812658, 0.348083391351825]
				Previous Gradient = [-0.10108841004812658, 0.3480833913509576]
				|| Gradient || = 0.3624650520823296
				||X optimum - X|| = 0.20294184122040093
				beta" = 2.2980066597250246e-12
				alpha = 1.8607071341967707e-15
			Iteration 8:
				X = [3.7970910384317955, 6.1034372892607036e-05]
				Current Gradient = [-0.10132816858146598, -0.1413333962016483]
				Previous Gradient = [-0.10108841004812658, 0.348083391351825]
				|| Gradient || = 0.1739037855538691
				||X optimum - X|| = 0.20290897074767728
				beta" = 0.5266764322106993
				alpha = 0.00032451855365842736
			Iteration 9:
				X = [3.7973302224542493, -3.948074643335455e-06]
				Current Gradient = [-0.10134276717983781, -0.4224501752008586]
				Previous Gradient = [-0.10132816858146598, -0.1413333962016483]
				|| Gradient || = 0.43443584910421806
				||X optimum - X|| = 0.20266977758420557
				beta" = 3.926897823570059
				alpha = 0.0015474250491067279
			Iteration 10:
				X = [3.797891411089737, 0.00020009956762543192]
				Current Gradient = [-0.10060847524875904, 0.4632532173412182]
				Previous Gradient = [-0.10134276717983781, -0.4224501752008586]
				|| Gradient || = 0.474052326931184
				||X optimum - X|| = 0.20210868796549722
				beta" = 2.1735880563804018
				alpha = 0.0007922816251426447
			Iteration 11:
				X = [3.8040879250369635, 0.0005648251873245022]
				Current Gradient = [-0.09646230453123905, 2.0647844304081886]
				Previous Gradient = [-0.10060847524875904, 0.4632532173412182]
				|| Gradient || = 2.06703645837502
				||X optimum - X|| = 0.19591288917224073
				beta" = 14.713128530193385
				alpha = 0.0037778931862957215
			Iteration 12:
				X = [3.862670024510694, -0.0009931140830254088]
				Current Gradient = [-0.06950831878300978, -4.727848960843842]
				Previous Gradient = [-0.09646230453123905, 2.0647844304081886]
				|| Gradient || = 4.7283598850904145
				||X optimum - X|| = 0.13733356633931595
				beta" = 7.51588556408862
				alpha = 0.002417851639229262
			Iteration 13:
				X = [4.043084249530034, -0.0011070057844761647]
				Current Gradient = [0.02081450679782687, -5.351398609673274]
				Previous Gradient = [-0.06950831878300978, -4.727848960843842]
				|| Gradient || = 5.351439089002723
				||X optimum - X|| = 0.04309846887504387
				beta" = 0.14933510425749794
				alpha = 0.0009903520314283058
			Iteration 14:
				X = [4.050141575849557, 0.0002778381722294799]
				Current Gradient = [0.025720258322182565, 1.4697736292133532]
				Previous Gradient = [0.02081450679782687, -5.351398609673274]
				|| Gradient || = 1.4699986574208668
				||X optimum - X|| = 0.05014234560455725
				beta" = 0.350085206703337
				alpha = 0.0002596148429267419
			Iteration 15:
				X = [4.050141575849557, 0.00027783817222948]
				Current Gradient = [0.025720258322236775, 1.4697736292132988]
				Previous Gradient = [0.025720258322182565, 1.4697736292133532]
				|| Gradient || = 1.4699986574208133
				||X optimum - X|| = 0.05014234560455725
				beta" = -3.635656216912753e-14
				alpha = 3.0916300184138424e-19
			Iteration 16:
				X = [4.050134898488733, -0.00010373687765660169]
				Current Gradient = [0.02487305095585533, -0.41105734462966187]
				Previous Gradient = [0.025720258322236775, 1.4697736292132988]
				|| Gradient || = 0.4118091903270751
				||X optimum - X|| = 0.050135005812459596
				beta" = 0.35777209744289046
				alpha = 0.0002596148429267419
			Iteration 17:
				X = [4.050134898488733, -0.00010373687765660177]
				Current Gradient = [0.02487305095585533, -0.41105734462966187]
				Previous Gradient = [0.02487305095585533, -0.41105734462966187]
				|| Gradient || = 0.4118091903270751
				||X optimum - X|| = 0.050135005812459596
				beta" = 0.0
				alpha = 7.5479248496431685e-19
			Iteration 18:
				X = [4.0501284410755165, 2.9797103033115025e-06]
				Current Gradient = [0.025070190749819452, 0.11494405932887262]
				Previous Gradient = [0.02487305095585533, -0.41105734462966187]
				|| Gradient || = 0.11764629717603407
				||X optimum - X|| = 0.05012844116407575
				beta" = 0.3565470639353652
				alpha = 0.0002596148429267419
			Iteration 19:
				X = [4.0501284410755165, 2.979710303491039e-06]
				Current Gradient = [0.025070190749819452, 0.1149440593298484]
				Previous Gradient = [0.025070190749819452, 0.11494405932887262]
				|| Gradient || = 0.11764629717698744
				||X optimum - X|| = 0.05012844116407575
				beta" = 8.103631789608273e-12
				alpha = 5.678427533559478e-15
			Iteration 20:
				X = [4.050121932481883, -2.6861473604723136e-05]
				Current Gradient = [0.025008119993244482, -0.032157582127755394]
				Previous Gradient = [0.025070190749819452, 0.1149440593298484]
				|| Gradient || = 0.04073715937445623
				||X optimum - X|| = 0.05012193967971681
				beta" = 0.34166606480851364
				alpha = 0.0002596148429267419
			Iteration 21:
				X = [4.050020462038483, -4.836494633041697e-05]
				Current Gradient = [0.024916343233549916, -0.1383402099905547]
				Previous Gradient = [0.025008119993244482, -0.032157582127755394]
				|| Gradient || = 0.1405661334047531
				||X optimum - X|| = 0.05002048542058894
				beta" = 8.850194232896596
				alpha = 0.0030223145490365774
			Iteration 22:
				X = [4.04976530727996, 1.1350858936694216e-05]
				Current Gradient = [0.024905511895282218, 0.15546968730218186]
				Previous Gradient = [0.024916343233549916, -0.1383402099905547]
				|| Gradient || = 0.15745192343253306
				||X optimum - X|| = 0.049765308574456574
				beta" = 2.3117889534382274
				alpha = 0.0007922816251426447
			Iteration 23:
				X = [4.040894516049259, 0.00022780423070970982]
				Current Gradient = [0.020965776873448343, 1.1995443297020398]
				Previous Gradient = [0.024905511895282218, 0.15546968730218186]
				|| Gradient || = 1.1997275368683604
				||X optimum - X|| = 0.040895150539772294
				beta" = 50.515338311686484
				alpha = 0.011529215046068483
			Iteration 24:
				X = [3.992753007265742, -8.310729549304335e-05]
				Current Gradient = [-0.003781437787670519, -0.41262970449003084]
				Previous Gradient = [0.020965776873448343, 1.1995443297020398]
				|| Gradient || = 0.41264703112862955
				||X optimum - X|| = 0.007247469248845114
				beta" = 0.4622407677875321
				alpha = 0.0012379400392853823
			Iteration 25:
				X = [3.99036411566194, -4.3690786110962116e-05]
				Current Gradient = [-0.00490303859832624, -0.22832788683959573]
				Previous Gradient = [-0.003781437787670519, -0.41262970449003084]
				|| Gradient || = 0.2283805238984531
				||X optimum - X|| = 0.009635983388386475
				beta" = -0.24710092318443067
				alpha = 0.00013292279957849188
			Iteration 26:
				X = [3.992618407372999, 3.49306055041048e-05]
				Current Gradient = [-0.0036194736283452094, 0.15256491259791105]
				Previous Gradient = [-0.00490303859832624, -0.22832788683959573]
				|| Gradient || = 0.15260784103496952
				||X optimum - X|| = 0.00738167527450204
				beta" = 1.1140497236287639
				alpha = 0.0005070602400912927
			Iteration 27:
				X = [3.9987542187715612, 5.99026230545693e-05]
				Current Gradient = [-0.0004987807201605998, 0.28534117572756534]
				Previous Gradient = [-0.0036194736283452094, 0.15256491259791105]
				|| Gradient || = 0.2853416116653793
				||X optimum - X|| = 0.001247220587297703
				beta" = 1.6267220303040044
				alpha = 0.0012379400392853823
			Iteration 28:
				X = [4.000847570110637, -5.65701923032844e-06]
				Current Gradient = [0.00041250942729253076, -0.025515316786251248]
				Previous Gradient = [-0.0004987807201605998, 0.28534117572756534]
				|| Gradient || = 0.025518651115024868
				||X optimum - X|| = 0.0008475889890224528
				beta" = 0.0974207054515309
				alpha = 0.0002596148429267419
			Iteration 29:
				X = [4.000847570110637, -5.657019230327995e-06]
				Current Gradient = [0.0004125094272925043, -0.025515316786249104]
				Previous Gradient = [0.00041250942729253076, -0.025515316786251248]
				|| Gradient || = 0.025518651115022724
				||X optimum - X|| = 0.0008475889890224528
				beta" = -8.402739192348341e-14
				alpha = 4.877732109868785e-16
			Iteration 30:
				X = [4.000847463017067, 9.671357293601067e-07]
				Current Gradient = [0.000425666902711056, 0.006346881897554733]
				Previous Gradient = [0.0004125094272925043, -0.025515316786249104]
				|| Gradient || = 0.006361140002670245
				||X optimum - X|| = 0.0008474635689204364
				beta" = 0.3105508751865721
				alpha = 0.0002596148429267419
			Iteration 31:
				X = [4.000847463017067, 9.67135729360107e-07]
				Current Gradient = [0.000425666902711056, 0.006346881897554733]
				Previous Gradient = [0.000425666902711056, 0.006346881897554733]
				|| Gradient || = 0.006361140002670245
				||X optimum - X|| = 0.0008474635689204364
				beta" = 0.0
				alpha = 3.0916300184138424e-19
			Iteration 32:
				X = [4.000847352507621, -6.806090175481465e-07]
				Current Gradient = [0.0004223155918263075, -0.0015790474055039762]
				Previous Gradient = [0.000425666902711056, 0.006346881897554733]
				|| Gradient || = 0.0016345461657378917
				||X optimum - X|| = 0.0008473527809594467
				beta" = 0.30926184275767465
				alpha = 0.0002596148429267419
			Iteration 33:
				X = [4.000847352507621, -6.806090175481486e-07]
				Current Gradient = [0.0004223155918263075, -0.0015790474055039894]
				Previous Gradient = [0.0004223155918263075, -0.0015790474055039762]
				|| Gradient || = 0.0016345461657379045
				||X optimum - X|| = 0.0008473527809594467
				beta" = 7.817554000470714e-15
				alpha = 5.623642243179056e-18
			Iteration 34:
				X = [4.0008472428682245, -2.706648733943518e-07]
				Current Gradient = [0.0004230801923545671, 0.00039257860142217853]
				Previous Gradient = [0.0004223155918263075, -0.0015790474055039894]
				|| Gradient || = 0.0005771609892026411
				||X optimum - X|| = 0.0008472429114585071
				beta" = 0.2898266033253588
				alpha = 0.0002596148429267419
			Iteration 35:
				X = [4.000840953929458, 4.795566518907816e-07]
				Current Gradient = [0.0004214363541194556, 0.003988584227120605]
				Previous Gradient = [0.0004230801923545671, 0.00039257860142217853]
				|| Gradient || = 0.00401078704712788
				||X optimum - X|| = 0.0008409540661926073
				beta" = 43.05506157345024
				alpha = 0.011529215046068483
			Iteration 36:
				X = [4.000783150238735, -2.3902724047453213e-06]
				Current Gradient = [0.00038680143203736854, -0.009930622346074718]
				Previous Gradient = [0.0004214363541194556, 0.003988584227120605]
				|| Gradient || = 0.009938152520875532
				||X optimum - X|| = 0.0007831538864319903
				beta" = 8.591908541332582
				alpha = 0.002417851639229262
			Iteration 37:
				X = [3.999811315761158, -3.653040502113813e-06]
				Current Gradient = [-0.00010163218754894166, -0.017939533000075506]
				Previous Gradient = [0.00038680143203736854, -0.009930622346074718]
				|| Gradient || = 0.017939820884343972
				||X optimum - X|| = 0.00018871959806107967
				beta" = 1.455202027812655
				alpha = 0.004722366482869652
			Iteration 38:
				X = [3.999733594826925, 9.033063628201658e-07]
				Current Gradient = [-0.00013139499474055887, 0.0038097091163360455]
				Previous Gradient = [-0.00010163218754894166, -0.017939533000075506]
				|| Gradient || = 0.003811974317297645
				||X optimum - X|| = 0.0002664067045017617
				beta" = 0.2574662080905614
				alpha = 0.0002596148429267419
			Iteration 39:
				X = [3.999733594826925, 9.033063628218147e-07]
				Current Gradient = [-0.00013139499474056052, 0.0038097091163439615]
				Previous Gradient = [-0.00013139499474055887, 0.0038097091163360455]
				|| Gradient || = 0.003811974317305556
				||X optimum - X|| = 0.0002664067045017617
				beta" = 2.075389102823543e-12
				alpha = 2.3258839177459632e-15
			Iteration 40:
				X = [3.999733628939016, -8.575067101401742e-08]
				Current Gradient = [-0.00013335702302944932, -0.0009449765304507372]
				Previous Gradient = [-0.00013139499474056052, 0.0038097091163439615]
				|| Gradient || = 0.0009543399492287799
				||X optimum - X|| = 0.0002663710747865466
				beta" = 0.30922043706382973
				alpha = 0.0002596148429267419
			Iteration 41:
				X = [3.999733628939016, -8.575067101402719e-08]
				Current Gradient = [-0.00013335702302944932, -0.0009449765304507852]
				Previous Gradient = [-0.00013335702302944932, -0.0009449765304507372]
				|| Gradient || = 0.0009543399492288274
				||X optimum - X|| = 0.0002663710747865466
				beta" = 4.9834351807268444e-14
				alpha = 4.189939978107104e-17
			Iteration 42:
				X = [3.9997336635604785, 1.5957926250840792e-07]
				Current Gradient = [-0.0001328490306977397, 0.00023448221425357646]
				Previous Gradient = [-0.00013335702302944932, -0.0009449765304507852]
				|| Gradient || = 0.000269500971721048
				||X optimum - X|| = 0.00026633648732854004
				beta" = 0.3035851082537633
				alpha = 0.0002596148429267419
			Iteration 43:
				X = [3.999733835222392, 2.1147231061837848e-07]
				Current Gradient = [-0.0001326593905400805, 0.00048429423119269375]
				Previous Gradient = [-0.0001328490306977397, 0.00023448221425357646]
				|| Gradient || = 0.0005021348586435599
				||X optimum - X|| = 0.00026616486161698815
				beta" = 1.6653734344140168
				alpha = 0.0009903520314283058
			Iteration 44:
				X = [3.99973400613237, 5.041739732093753e-08]
				Current Gradient = [-0.00013289609598882444, -0.00028961307358135876]
				Previous Gradient = [-0.0001326593905400805, 0.00048429423119269375]
				|| Gradient || = 0.00031864887371260605
				||X optimum - X|| = 0.0002659938724082982
				beta" = 0.8890523098424562
				alpha = 0.00040564819207303417
			Iteration 45:
				X = [3.9997355398863275, -1.411014382502739e-07]
				Current Gradient = [-0.00013251223584123166, -0.0012072463877130489]
				Previous Gradient = [-0.00013289609598882444, -0.00028961307358135876]
				|| Gradient || = 0.0012144971524436965
				||X optimum - X|| = 0.00026446015131453637
				beta" = 10.909889942572319
				alpha = 0.0030223145490365774
			Iteration 46:
				X = [3.9997425578009143, 4.975587207648345e-07]
				Current Gradient = [-0.00012772568506066962, 0.0018770705188772031]
				Previous Gradient = [-0.00013251223584123166, -0.0012072463877130489]
				|| Gradient || = 0.0018814110617996669
				||X optimum - X|| = 0.00025744267990134175
				beta" = 3.9246480601710765
				alpha = 0.0012379400392853823
			Iteration 47:
				X = [3.999948946048001, 1.8596411001277084e-06]
				Current Gradient = [-2.1803543937214817e-05, 0.008838818646001832]
				Previous Gradient = [-0.00012772568506066962, 0.0018770705188772031]
				|| Gradient || = 0.008838845538385535
				||X optimum - X|| = 5.10878095021349e-05
				beta" = 17.38316463320862
				alpha = 0.009223372036854787
			Iteration 48:
				X = [4.0000751834225845, -1.7564853069322037e-07]
				Current Gradient = [3.7240451259821105e-05, -0.0006941829847562942]
				Previous Gradient = [-2.1803543937214817e-05, 0.008838818646001832]
				|| Gradient || = 0.0006951811760506699
				||X optimum - X|| = 7.518362776513302e-05
				beta" = 0.08473382672732772
				alpha = 0.00032451855365842736
			Iteration 49:
				X = [4.0000751834225845, -1.756485306914153e-07]
				Current Gradient = [3.7240451259821105e-05, -0.0006941829847476298]
				Previous Gradient = [3.7240451259821105e-05, -0.0006941829847562942]
				|| Gradient || = 0.000695181176042018
				||X optimum - X|| = 7.518362776513302e-05
				beta" = -1.2445619913594175e-11
				alpha = 1.1090678776483354e-14
			Iteration 50:
				X = [4.000075173754411, 4.571675855731587e-09]
				Current Gradient = [3.759602058753151e-05, 0.000172328951155572]
				Previous Gradient = [3.7240451259821105e-05, -0.0006941829847476298]
				|| Gradient || = 0.00017638233519941165
				||X optimum - X|| = 7.517375454969727e-05
				beta" = 0.3090122269561975
				alpha = 0.0002596148429267419
			Iteration 51:
				X = [4.000075173754411, 4.57167601052285e-09]
				Current Gradient = [3.759602058753151e-05, 0.00017232895190037452]
				Previous Gradient = [3.759602058753151e-05, 0.000172328951155572]
				|| Gradient || = 0.00017638233592709812
				||X optimum - X|| = 7.517375454969728e-05
				beta" = 4.125619857045067e-09
				alpha = 3.66959778558414e-12
			Iteration 52:
				X = [4.000075163993926, -4.016747772364289e-08]
				Current Gradient = [3.7501663948722925e-05, -4.28044910623541e-05]
				Previous Gradient = [3.759602058753151e-05, 0.00017232895190037452]
				|| Gradient || = 5.690869225373306e-05
				||X optimum - X|| = 7.51640046585261e-05
				beta" = 0.29588310756276964
				alpha = 0.0002596148429267419
			Iteration 53:
				X = [4.000074876958506, -8.848162373179575e-08]
				Current Gradient = [3.726152540576374e-05, -0.0002756816305976248]
				Previous Gradient = [3.7501663948722925e-05, -4.28044910623541e-05]
				|| Gradient || = 0.00027818839430236773
				||X optimum - X|| = 7.48770107854535e-05
				beta" = 19.820606562450006
				alpha = 0.005902958103587064
			Iteration 54:
				X = [4.00007332790522, 8.70818323654879e-08]
				Current Gradient = [3.6838125379961664e-05, 0.0005653605858652064]
				Previous Gradient = [3.726152540576374e-05, -0.0002756816305976248]
				|| Gradient || = 0.0005665594757228575
				||X optimum - X|| = 7.332795692761138e-05
				beta" = 6.143997957249838
				alpha = 0.0015474250491067279
			Iteration 55:
				X = [4.000061359924638, 3.4184231147043417e-07]
				Current Gradient = [3.136378717616257e-05, 0.00176634802422016]
				Previous Gradient = [3.6838125379961664e-05, 0.0005653605858652064]
				|| Gradient || = 0.0017666264545207328
				||X optimum - X|| = 6.136087684974308e-05
				beta" = 6.60828211144154
				alpha = 0.0019342813113834097
			Iteration 56:
				X = [4.000028940716087, -3.6802924549661024e-07]
				Current Gradient = [1.3734462090041316e-05, -0.0017116287427432373]
				Previous Gradient = [3.136378717616257e-05, 0.00176634802422016]
				|| Gradient || = 0.0017116838459346685
				||X optimum - X|| = 2.8943056043511283e-05
				beta" = 1.9073444224431528
				alpha = 0.0007922816251426447
			Iteration 57:
				X = [3.9999972758312627, -3.6694255257662564e-07]
				Current Gradient = [-2.0958078979574823e-06, -0.001769705731191664]
				Previous Gradient = [1.3734462090041316e-05, -0.0017116287427432373]
				|| Gradient || = 0.0017697069721915454
				||X optimum - X|| = 2.7487710246460733e-06
				beta" = 0.035091199160491304
				alpha = 0.00040564819207303417
			Iteration 58:
				X = [3.9999965652337464, 9.25237282021692e-08]
				Current Gradient = [-1.532325397805829e-06, 0.000437983789975345]
				Previous Gradient = [-2.0958078979574823e-06, -0.001769705731191664]
				|| Gradient || = 0.0004379864704557572
				||X optimum - X|| = 3.4360122027472277e-06
				beta" = 0.308740015746777
				alpha = 0.0002596148429267419
			Iteration 59:
				X = [3.9999965652337464, 9.25237282021692e-08]
				Current Gradient = [-1.532325397805829e-06, 0.000437983789975345]
				Previous Gradient = [-1.532325397805829e-06, 0.000437983789975345]
				|| Gradient || = 0.0004379864704557572
				||X optimum - X|| = 3.4360122027472277e-06
				beta" = 0.0
				alpha = 5.1868944611013025e-20
			Iteration 60:
				X = [3.9999965656315606, -2.1183364636739093e-08]
				Current Gradient = [-1.7595504107076843e-06, -0.00010871817944890247]
				Previous Gradient = [-1.532325397805829e-06, 0.000437983789975345]
				|| Gradient || = 0.0001087324172467971
				||X optimum - X|| = 3.434433768845094e-06
				beta" = 0.3098377574187256
				alpha = 0.0002596148429267419
			Iteration 61:
				X = [3.9999965656315606, -2.1183364636739107e-08]
				Current Gradient = [-1.7595504107076845e-06, -0.00010871817944890247]
				Previous Gradient = [-1.7595504107076843e-06, -0.00010871817944890247]
				|| Gradient || = 0.0001087324172467971
				||X optimum - X|| = 3.434433768845094e-06
				beta" = 3.1515481007609394e-20
				alpha = 4.830671903771628e-19
			Iteration 62:
				X = [3.999996566088366, 7.041488444169046e-09]
				Current Gradient = [-1.7028727810313617e-06, 2.6987595139855425e-05]
				Previous Gradient = [-1.7595504107076845e-06, -0.00010871817944890247]
				|| Gradient || = 2.7041266004777322e-05
				||X optimum - X|| = 3.43391885369165e-06
				beta" = 0.30976545486989915
				alpha = 0.0002596148429267419
			Iteration 63:
				X = [3.999996566088366, 7.0414884687169716e-09]
				Current Gradient = [-1.7028727808093167e-06, 2.698759525768503e-05]
				Previous Gradient = [-1.7028727810313617e-06, 2.6987595139855425e-05]
				|| Gradient || = 2.7041266122359078e-05
				||X optimum - X|| = 3.4339188536917006e-06
				beta" = 4.348234174014346e-09
				alpha = 3.66959778558414e-12
			Iteration 64:
				X = [3.999996566530457, 3.510817247418511e-11]
				Current Gradient = [-1.7166645554120808e-06, -6.6981392814931095e-06]
				Previous Gradient = [-1.7028727808093167e-06, 2.698759525768503e-05]
				|| Gradient || = 6.914622696148299e-06
				||X optimum - X|| = 3.4334695430811855e-06
				beta" = 0.3085970144981456
				alpha = 0.0002596148429267419
			Iteration 65:
				X = [3.9999965665304575, 3.510800245545404e-11]
				Current Gradient = [-1.7166645554120808e-06, -6.698140098406963e-06]
				Previous Gradient = [-1.7166645554120808e-06, -6.6981392814931095e-06]
				|| Gradient || = 6.914623487486169e-06
				||X optimum - X|| = 3.433469542637095e-06
				beta" = 1.1444412768498173e-07
				alpha = 1.0429624198832633e-10
			Iteration 66:
				X = [3.999996566976129, 1.7740445435705995e-09]
				Current Gradient = [-1.7129638427858919e-06, 1.663543806782811e-06]
				Previous Gradient = [-1.7166645554120808e-06, -6.698140098406963e-06]
				|| Gradient || = 2.3878071789357815e-06
				||X optimum - X|| = 3.4330243293342363e-06
				beta" = 0.2907990266271988
				alpha = 0.0002596148429267419
			Iteration 67:
				X = [3.9999965924806933, 5.051440206122776e-09]
				Current Gradient = [-1.6936567426659716e-06, 1.7472244586989254e-05]
				Previous Gradient = [-1.7129638427858919e-06, 1.663543806782811e-06]
				|| Gradient || = 1.7554139228955464e-05
				||X optimum - X|| = 3.407523050944004e-06
				beta" = 48.43897624208963
				alpha = 0.011529215046068483
			Iteration 68:
				X = [3.9999971065047335, -1.2433390328169761e-08]
				Current Gradient = [-1.4716142285825702e-06, -6.556664488877404e-05]
				Previous Gradient = [-1.6936567426659716e-06, 1.7472244586989254e-05]
				|| Gradient || = 6.558315767335671e-05
				||X optimum - X|| = 2.893521979602552e-06
				beta" = 17.667672932900764
				alpha = 0.004722366482869652
			Iteration 69:
				X = [4.000000829178141, -1.2141157501336343e-08]
				Current Gradient = [3.9030693272368663e-07, -5.6716353145281556e-05]
				Previous Gradient = [-1.4716142285825702e-06, -6.556664488877404e-05]
				|| Gradient || = 5.671769612389084e-05
				||X optimum - X|| = 8.292670243341496e-07
				beta" = -0.11653383042985593
				alpha = 0.0019342813113834097
			Iteration 70:
				X = [4.000000770850827, 2.57867882569196e-09]
				Current Gradient = [3.9058277904898907e-07, 1.3939994217559244e-05]
				Previous Gradient = [3.9030693272368663e-07, -5.6716353145281556e-05]
				|| Gradient || = 1.3945464986613921e-05
				||X optimum - X|| = 7.708551398597188e-07
				beta" = 0.3061798885698924
				alpha = 0.0002596148429267419
			Iteration 71:
				X = [4.000000770850826, 2.5786788563318638e-09]
				Current Gradient = [3.905827786049e-07, 1.393999436427358e-05]
				Previous Gradient = [3.9058277904898907e-07, 1.3939994217559244e-05]
				|| Gradient || = 1.3945465133258264e-05
				||X optimum - X|| = 7.708551389716478e-07
				beta" = 1.0515557873893079e-08
				alpha = 8.958978968711279e-12
			Iteration 72:
				X = [4.000000770749424, -1.0403505816120465e-09]
				Current Gradient = [3.832940125234239e-07, -3.4605086722337763e-06]
				Previous Gradient = [3.905827786049e-07, 1.393999436427358e-05]
				|| Gradient || = 3.4816712324171966e-06
				||X optimum - X|| = 7.707501264112481e-07
				beta" = 0.30961043319019654
				alpha = 0.0002596148429267419
			Iteration 73:
				X = [4.000000770749424, -1.0403506529889746e-09]
				Current Gradient = [3.8329401210524875e-07, -3.460509014842887e-06]
				Previous Gradient = [3.832940125234239e-07, -3.4605086722337763e-06]
				|| Gradient || = 3.4816715728977984e-06
				||X optimum - X|| = 7.707501264113444e-07
				beta" = 9.779229929376596e-08
				alpha = 8.343699359066107e-11
			Iteration 74:
				X = [4.000000770649915, -1.4195117037264182e-10]
				Current Gradient = [3.8504105556198156e-07, 8.587983411144745e-07]
				Previous Gradient = [3.8329401210524875e-07, -3.460509014842887e-06]
				|| Gradient || = 9.411648129680892e-07
				||X optimum - X|| = 7.706499285115392e-07
				beta" = 0.3060613239683621
				alpha = 0.0002596148429267419
	- Starting Point : [1.9 0.6]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Polak-Ribiere Method
			------------
			Iteration 0:
				X = [1.6457890130010624, -0.20515620154852698]
				Current Gradient = [19.19349932855141, -173.05681957680008]
				Previous Gradient = [205.34999994481495, 650.3999999978305]
				|| Gradient || = 174.11792905531652
				||X optimum - X|| = 2.363133182522799
				beta" = 0.29865686538226116
				alpha = 0.0012379400392853823
			Iteration 1:
				X = [-0.16742069424456574, -0.6823037024826049]
				Current Gradient = [-26.83054349805758, -19.530699153946784]
				Previous Gradient = [19.19349932855141, -173.05681957680008]
				|| Gradient || = 33.18623621086214
				||X optimum - X|| = 4.222905822444934
				beta" = -0.05817261903800895
				alpha = 0.022517998136852502
			Iteration 2:
				X = [0.19591974020567188, -0.44291852900073525]
				Current Gradient = [8.742596491195798, -16.25187656184579]
				Previous Gradient = [-26.83054349805758, -19.530699153946784]
				|| Gradient || = 18.45417256853695
				||X optimum - X|| = 3.8297785113879703
				beta" = 0.23400385057239928
				alpha = 0.011529215046068483
			Iteration 3:
				X = [0.12071196185676787, 0.7176479542507382]
				Current Gradient = [18.146323070844517, 1.119743384458971]
				Previous Gradient = [8.742596491195798, -16.25187656184579]
				|| Gradient || = 18.180837886040997
				||X optimum - X|| = 3.945110171987778
				beta" = 0.5581888038065557
				alpha = 0.054975581388800036
			Iteration 4:
				X = [-0.053701425663564575, 0.8160055026710719]
				Current Gradient = [-11.122209331415611, -0.8733892739587468]
				Previous Gradient = [18.146323070844517, 1.119743384458971]
				|| Gradient || = 11.156448773498433
				||X optimum - X|| = 4.135016351698779
				beta" = 0.9901031252344544
				alpha = 0.009223372036854787
			Iteration 5:
				X = [-0.053701425663564575, 0.8160055026710719]
				Current Gradient = [-11.122209331415611, -0.8733892739587468]
				Previous Gradient = [-11.122209331415611, -0.8733892739587468]
				|| Gradient || = 11.156448773498433
				||X optimum - X|| = 4.135016351698779
				beta" = 0.0
				alpha = 3.8645375230173027e-19
			Iteration 6:
				X = [0.01195251003910687, 0.8211610829633726]
				Current Gradient = [2.066191485031177, -1.371612379619247]
				Previous Gradient = [-11.122209331415611, -0.8733892739587468]
				|| Gradient || = 2.4800136638212527
				||X optimum - X|| = 4.0717107346122905
				beta" = 0.22442315227517054
				alpha = 0.005902958103587064
			Iteration 7:
				X = [0.021632767605702, 0.8564607731804276]
				Current Gradient = [4.4841910509241245, -0.9848071903517663]
				Previous Gradient = [2.066191485031177, -1.371612379619247]
				|| Gradient || = 4.591058111520321
				||X optimum - X|| = 4.069512365356012
				beta" = 1.7009833836099744
				alpha = 0.022517998136852502
			Iteration 8:
				X = [-0.01298213864357834, 0.8901381150743832]
				Current Gradient = [-3.3121179968328973, -0.8598532818676619]
				Previous Gradient = [4.4841910509241245, -0.9848071903517663]
				|| Gradient || = 3.4219107661192676
				||X optimum - X|| = 4.110519615447731
				beta" = 1.2199961896410214
				alpha = 0.009223372036854787
			Iteration 9:
				X = [-0.01378486165500576, 0.8935065359821747]
				Current Gradient = [-3.5214389012758196, -0.8285815556591247]
				Previous Gradient = [-3.3121179968328973, -0.8598532818676619]
				|| Gradient || = 3.6176068511928086
				||X optimum - X|| = 4.112033906170249
				beta" = 0.06073711280719838
				alpha = 0.0006338253001141158
			Iteration 10:
				X = [0.006547977594968977, 0.9003029939158401]
				Current Gradient = [1.3961100711439023, -0.7728996732937754]
				Previous Gradient = [-3.5214389012758196, -0.8285815556591247]
				|| Gradient || = 1.5957748073356268
				||X optimum - X|| = 4.093678606840632
				beta" = 0.5213083045593268
				alpha = 0.005902958103587064
			Iteration 11:
				X = [0.010233131811099059, 0.9129677507160545]
				Current Gradient = [2.389877725612888, -0.6471107611358273]
				Previous Gradient = [1.3961100711439023, -0.7728996732937754]
				|| Gradient || = 2.4759377780062284
				||X optimum - X|| = 4.092890149557572
				beta" = 0.9006818428790356
				alpha = 0.009223372036854787
			Iteration 12:
				X = [-0.004745732105094972, 0.9268681185508064]
				Current Gradient = [-1.3717321098415114, -0.5882840461383237]
				Previous Gradient = [2.389877725612888, -0.6471107611358273]
				|| Gradient || = 1.492557235120691
				||X optimum - X|| = 4.110604929690992
				beta" = 0.8360669187594799
				alpha = 0.00737869762948383
			Iteration 13:
				X = [-0.009436622991336158, 0.9580446962889478]
				Current Gradient = [-2.6870492237790478, -0.3289215537299883]
				Previous Gradient = [-1.3717321098415114, -0.5882840461383237]
				|| Gradient || = 2.7071060044851833
				||X optimum - X|| = 4.122309022122377
				beta" = 1.5482201190059954
				alpha = 0.014411518807585602
			Iteration 14:
				X = [0.003450183036648567, 0.9797569631653618]
				Current Gradient = [0.9548127648292393, -0.15154509020614584]
				Previous Gradient = [-2.6870492237790478, -0.3289215537299883]
				|| Gradient || = 0.9667643612827508
				||X optimum - X|| = 4.1148917539032315
				beta" = 0.47082650935906206
				alpha = 0.005902958103587064
			Iteration 15:
				X = [0.004123980148189566, 0.9971277055747142]
				Current Gradient = [1.2264144815103164, -0.00964288634380285]
				Previous Gradient = [0.9548127648292393, -0.15154509020614584]
				|| Gradient || = 1.2264523903173974
				||X optimum - X|| = 4.11840853088319
				beta" = 0.35492842057054075
				alpha = 0.009223372036854787
			Iteration 16:
				X = [-0.001545153824173584, 1.0003299123437368]
				Current Gradient = [-0.4639648091217541, 0.00026547750337033854]
				Previous Gradient = [1.2264144815103164, -0.00964288634380285]
				|| Gradient || = 0.46396488507395744
				||X optimum - X|| = 4.1246846608708605
				beta" = 0.5213978949040285
				alpha = 0.004722366482869652
			Iteration 17:
				X = [-0.001545153824173584, 1.0003299123437368]
				Current Gradient = [-0.4639648091217541, 0.00026547750337033854]
				Previous Gradient = [-0.4639648091217541, 0.00026547750337033854]
				|| Gradient || = 0.46396488507395744
				||X optimum - X|| = 4.1246846608708605
				beta" = 0.0
				alpha = 6.038339879714535e-19
			Iteration 18:
				X = [0.0002076556668884858, 1.0003289093980856]
				Current Gradient = [0.06309933337585509, 0.0030595270358657646]
				Previous Gradient = [-0.4639648091217541, 0.00026547750337033854]
				|| Gradient || = 0.06317346419312854
				||X optimum - X|| = 4.122983958829252
				beta" = 0.15453598825719606
				alpha = 0.0037778931862957215
			Iteration 19:
				X = [0.0002076556668884858, 1.0003289093980856]
				Current Gradient = [0.06309933337585509, 0.0030595270358657646]
				Previous Gradient = [0.06309933337585509, 0.0030595270358657646]
				|| Gradient || = 0.06317346419312854
				||X optimum - X|| = 4.122983958829252
				beta" = 0.0
				alpha = 1.474204072195931e-18
			Iteration 20:
				X = [-3.0726874731959355e-05, 1.0003173508317436]
				Current Gradient = [-0.008604575841297195, 0.0024776362364175965]
				Previous Gradient = [0.06309933337585509, 0.0030595270358657646]
				|| Gradient || = 0.008954183755577327
				||X optimum - X|| = 4.123212414891698
				beta" = 0.1542364081742067
				alpha = 0.0037778931862957215
			Iteration 21:
				X = [-3.072687473218684e-05, 1.000317350831743]
				Current Gradient = [-0.00860457584164199, 0.00247763623641045]
				Previous Gradient = [-0.008604575841297195, 0.0024776362364175965]
				|| Gradient || = 0.008954183755906682
				||X optimum - X|| = 4.123212414891699
				beta" = 3.6782322020433006e-11
				alpha = 2.017382717255413e-13
			Iteration 22:
				X = [9.907085821497348e-06, 1.0003056505254229]
				Current Gradient = [0.003590197481272839, 0.002465047828928731]
				Previous Gradient = [-0.00860457584164199, 0.00247763623641045]
				|| Gradient || = 0.004354994690403662
				||X optimum - X|| = 4.123170156309908
				beta" = 0.5456725931151915
				alpha = 0.004722366482869652
			Iteration 23:
				X = [2.5833020792882076e-05, 1.0002506413831624]
				Current Gradient = [0.008267990895953092, 0.0020569973603840564]
				Previous Gradient = [0.003590197481272839, 0.002465047828928731]
				|| Gradient || = 0.0085200300231977
				||X optimum - X|| = 4.123141360915052
				beta" = 1.9949718978860993
				alpha = 0.014411518807585602
			Iteration 24:
				X = [-1.8906826161358205e-05, 1.000179275674832]
				Current Gradient = [-0.005324983814485171, 0.001396499005866251]
				Previous Gradient = [0.008267990895953092, 0.0020569973603840564]
				|| Gradient || = 0.005505057865083207
				||X optimum - X|| = 4.123167452148432
				beta" = 0.984420548757512
				alpha = 0.00737869762948383
			Iteration 25:
				X = [-2.8186863741512152e-05, 1.000021935413775]
				Current Gradient = [-0.008426652705150715, 0.000119347937720772]
				Previous Gradient = [-0.005324983814485171, 0.001396499005866251]
				|| Gradient || = 0.008427497834082313
				||X optimum - X|| = 4.123138291036713
				beta" = 0.8574061545962964
				alpha = 0.014411518807585602
			Iteration 26:
				X = [8.999607001458303e-06, 0.9999771662998284]
				Current Gradient = [0.002658591208400055, -0.00016464609005202802]
				Previous Gradient = [-0.008426652705150715, 0.000119347937720772]
				|| Gradient || = 0.0026636845812429604
				||X optimum - X|| = 4.123091356779039
				beta" = 0.4156119425506014
				alpha = 0.004722366482869652
			Iteration 27:
				X = [8.999607001458303e-06, 0.9999771662998284]
				Current Gradient = [0.002658591208400055, -0.00016464609005202802]
				Previous Gradient = [0.002658591208400055, -0.00016464609005202802]
				|| Gradient || = 0.0026636845812429604
				||X optimum - X|| = 4.123091356779039
				beta" = 0.0
				alpha = 1.179363257756745e-18
			Iteration 28:
				X = [-1.0442666099019738e-06, 0.9999777883151701]
				Current Gradient = [-0.00035821156913359625, -0.00017978168472358597]
				Previous Gradient = [0.002658591208400055, -0.00016464609005202802]
				|| Gradient || = 0.0004007954371287229
				||X optimum - X|| = 4.123101251637858
				beta" = 0.15269088754716967
				alpha = 0.0037778931862957215
			Iteration 29:
				X = [-2.3877771322085716e-06, 0.9999835563466208]
				Current Gradient = [-0.0007503907769101969, -0.00013632307088548177]
				Previous Gradient = [-0.00035821156913359625, -0.00017978168472358597]
				|| Gradient || = 0.0007626731263965822
				||X optimum - X|| = 4.12310395396313
				beta" = 1.7951236655888403
				alpha = 0.028147497671065627
			Iteration 30:
				X = [7.51215673203393e-07, 0.9999859372823909]
				Current Gradient = [0.00019760853613986367, -0.0001109991402341483]
				Previous Gradient = [-0.0007503907769101969, -0.00013632307088548177]
				|| Gradient || = 0.00022664938272155062
				||X optimum - X|| = 4.123101486143377
				beta" = 0.31722751308543584
				alpha = 0.004722366482869652
			Iteration 31:
				X = [1.479916838359883e-06, 1.0000008323545122]
				Current Gradient = [0.00044638045804042733, 9.619326819469119e-06]
				Previous Gradient = [0.00019760853613986367, -0.0001109991402341483]
				|| Gradient || = 0.00044648409240290014
				||X optimum - X|| = 4.123104391763226
				beta" = 2.184296633967314
				alpha = 0.054975581388800036
			Iteration 32:
				X = [-9.708009565314308e-08, 1.0000030318194837]
				Current Gradient = [-2.3109106376015755e-05, 2.406039850298691e-05]
				Previous Gradient = [0.00044638045804042733, 9.619326819469119e-06]
				|| Gradient || = 3.336065907053616e-05
				||X optimum - X|| = 4.123106455124454
				beta" = 0.05616780560365261
				alpha = 0.0037778931862957215
			Iteration 33:
				X = [-9.708009565691577e-08, 1.0000030318194837]
				Current Gradient = [-2.3109106377147585e-05, 2.406039850298691e-05]
				Previous Gradient = [-2.3109106376015755e-05, 2.406039850298691e-05]
				|| Gradient || = 3.336065907132019e-05
				||X optimum - X|| = 4.123106455124454
				beta" = 2.3501456547893296e-11
				alpha = 1.1198723710889097e-11
			Iteration 34:
				X = [1.1606378989869686e-07, 1.000002809901477]
				Current Gradient = [4.049716749631589e-05, 2.2711343435181806e-05]
				Previous Gradient = [-2.3109106377147585e-05, 2.406039850298691e-05]
				|| Gradient || = 4.6430870074288294e-05
				||X optimum - X|| = 4.123106194521377
				beta" = 2.2869604566898065
				alpha = 0.009223372036854787
			Iteration 35:
				X = [3.38585656292367e-07, 1.000001409524766]
				Current Gradient = [0.00010456432559548323, 1.195340383207039e-05]
				Previous Gradient = [4.049716749631589e-05, 2.2711343435181806e-05]
				|| Gradient || = 0.00010524534217917097
				||X optimum - X|| = 4.12310563900155
				beta" = 3.047809104239479
				alpha = 0.018014398509482003
			Iteration 36:
				X = [-5.641923430796646e-08, 0.9999999403995783]
				Current Gradient = [-1.707317873542763e-05, -5.896408879199893e-07]
				Previous Gradient = [0.00010456432559548323, 1.195340383207039e-05]
				|| Gradient || = 1.708335764738786e-05
				||X optimum - X|| = 4.123105665897133
				beta" = 0.18815684612038033
				alpha = 0.005902958103587064
			Iteration 37:
				X = [-4.2872029519333755e-08, 0.999999800651566]
				Current Gradient = [-1.3281736610682022e-05, -1.680530979819221e-06]
				Previous Gradient = [-1.707317873542763e-05, -5.896408879199893e-07]
				|| Gradient || = 1.3387632791859184e-05
				||X optimum - X|| = 4.123105618860547
				beta" = -0.1662673957362561
				alpha = 0.0030223145490365774
			Iteration 38:
				X = [1.632973194195427e-08, 0.9999998448931774]
				Current Gradient = [4.5968692836890855e-06, -1.2081950369456722e-06]
				Previous Gradient = [-1.3281736610682022e-05, -1.680530979819221e-06]
				|| Gradient || = 4.7529930000605265e-06
				||X optimum - X|| = 4.123105572156566
				beta" = 0.45536755536107487
				alpha = 0.004722366482869652
			Iteration 39:
				X = [1.9690026315246983e-08, 0.9999998614382872]
				Current Gradient = [5.639727845275134e-06, -1.0691135332722024e-06]
				Previous Gradient = [4.5968692836890855e-06, -1.2081950369456722e-06]
				|| Gradient || = 5.740168457092307e-06
				||X optimum - X|| = 4.123105572909379
				beta" = 0.2537629654519664
				alpha = 0.0030223145490365774
			Iteration 40:
				X = [-5.610463144789619e-09, 0.9999998730472459]
				Current Gradient = [-1.939849255891171e-06, -1.026842950079917e-06]
				Previous Gradient = [5.639727845275134e-06, -1.0691135332722024e-06]
				|| Gradient || = 2.194862542327049e-06
				||X optimum - X|| = 4.123105600270046
				beta" = 0.4449177274186532
				alpha = 0.004722366482869652
			Iteration 41:
				X = [-1.3605905212122735e-08, 0.9999999112482355]
				Current Gradient = [-4.266077320765771e-06, -7.372258706099822e-07]
				Previous Gradient = [-1.939849255891171e-06, -1.026842950079917e-06]
				|| Gradient || = 4.3293091470867155e-06
				||X optimum - X|| = 4.123105617291864
				beta" = 2.015674863879872
				alpha = 0.018014398509482003
			Iteration 42:
				X = [6.295610261693e-09, 0.9999999408316628]
				Current Gradient = [1.7734939855740202e-06, -4.607554654501059e-07]
				Previous Gradient = [-4.266077320765771e-06, -7.372258706099822e-07]
				|| Gradient || = 1.8323690992290191e-06
				||X optimum - X|| = 4.1231056051595925
				beta" = 0.5646803934950347
				alpha = 0.005902958103587064
			Iteration 43:
				X = [8.642823686664648e-09, 1.000000000112063]
				Current Gradient = [2.59739264441515e-06, 1.8182173304020314e-08]
				Previous Gradient = [1.7734939855740202e-06, -4.607554654501059e-07]
				|| Gradient || = 2.5974562827289283e-06
				||X optimum - X|| = 4.1231056172600695
				beta" = 0.639954572367845
				alpha = 0.018014398509482003
			Iteration 44:
				X = [-3.2292471658668086e-09, 1.000000009971095]
				Current Gradient = [-9.504466025014588e-07, 7.331026898433423e-08]
				Previous Gradient = [2.59739264441515e-06, 1.8182173304020314e-08]
				|| Gradient || = 9.53269709864486e-07
				||X optimum - X|| = 1.0480971995405012e-08
				beta" = 0.5003977666344475
				alpha = 0.004722366482869652