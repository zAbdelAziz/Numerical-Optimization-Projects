C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe "C:\Users\User\Desktop\JKU\Numerical Optimization\Project01-2\main.py" 
###################
# Exact Solutions #
###################
Running: Rosenbrock
===================
	- Starting Point : [1.2 1.2]
	------------------------------
		- Newton Method:
			Iteration 0:
				X = [1.1959183673469387, 1.430204081632653]
				Gradient = [115.6, -48.0]
				||Gradient|| = 125.16932531574977
				Hessian = [[1250.0, -480.0], [-480.0, 200.0]]
				||X optimum - X|| = 0.47271509233076564
				alpha = 1.0
				
			Iteration 1:
				X = [1.0959412814191771, 1.1910837446622453]
				Gradient = [0.3998062031976558, -0.003331945022910787]
				||Gradient|| = 0.3998200870053441
				Hessian = [[1146.1832569762598, -478.3673469387755], [-478.3673469387755, 200.0]]
				||X optimum - X|| = 0.21381704084216466
				alpha = 0.5120000000000001
				
			Iteration 2:
				X = [1.063968416195581, 1.1310065265511267]
				Gradient = [4.577202897782929, -2.0007095312925216]
				||Gradient|| = 4.995360346969694
				Hessian = [[966.8712529175514, -438.37651256767083], [-438.37651256767083, 200.0]]
				||X optimum - X|| = 0.14578980852433449
				alpha = 1.0
				
			Iteration 3:
				X = [1.0108584769595008, 1.0190141947952214]
				Gradient = [0.5629995230692373, -0.20445282212122606]
				||Gradient|| = 0.5989736383594209
				Hessian = [[908.0319381736286, -425.58736647823235], [-425.58736647823235, 200.0]]
				||X optimum - X|| = 0.021896258255479032
				alpha = 1.0
				
			Iteration 4:
				X = [1.0039163076791107, 1.0077997591097412]
				Gradient = [1.162234465352621, -0.5641331291320384]
				||Gradient|| = 1.291911428789837
				Hessian = [[820.5961546109693, -404.3433907838003], [-404.3433907838003, 200.0]]
				||X optimum - X|| = 0.008727755038235871
				alpha = 1.0
				
			Iteration 5:
				X = [1.00003738791024, 1.0000597311997623]
				Gradient = [0.027185597650617455, -0.009638742863504746]
				||Gradient|| = 0.02884375293906847
				Hessian = [[808.2976397449739, -401.56652307164427], [-401.56652307164427, 200.0]]
				||X optimum - X|| = 7.046752484060057e-05
				alpha = 1.0
				
			Iteration 6:
				X = [1.000000112170295, 1.000000222951122]
				Gradient = [0.006093408265554601, -0.003009203714698927]
				||Gradient|| = 0.006795949623657238
				Hessian = [[802.065840182098, -400.014955164096], [-400.014955164096, 200.0]]
				||X optimum - X|| = 2.495784003015045e-07
				alpha = 1.0
				
			Iteration 7:
				X = [1.000000000000031, 1.0000000000000497]
				Gradient = [7.801329535194528e-07, -2.778961505356392e-07]
				||Gradient|| = 8.281507686704827e-07
				Hessian = [[802.0001800282744, -400.00004486811804], [-400.00004486811804, 200.0]]
				||X optimum - X|| = 5.865340917345583e-14
				alpha = 1.0
				
		____________________________________________________________________________________________________

	- Starting Point : [-1.2  1. ]
	------------------------------
		- Newton Method:
			Iteration 0:
				X = [-1.1752808988764043, 1.3806741573033705]
				Gradient = [-215.6, -87.99999999999999]
				||Gradient|| = 232.86768775422664
				Hessian = [[1330.0, 480.0], [480.0, 200.0]]
				||X optimum - X|| = 2.208338697540567
				alpha = 1.0
				
			Iteration 1:
				X = [-0.9151138226550966, 0.7692173784944115]
				Gradient = [-4.63781641462244, -0.1222067920716885]
				||Gradient|| = 4.639426214066757
				Hessian = [[1107.2725665951266, 470.11235955056173], [470.11235955056173, 200.0]]
				||X optimum - X|| = 1.9289690438453408
				alpha = 0.13421772800000006
				
			Iteration 2:
				X = [-0.7843284986998217, 0.59806639291063]
				Gradient = [-28.80036380333994, -13.643185984002404]
				||Gradient|| = 31.86844017203875
				Hessian = [[699.2330186995437, 366.0455290620386], [366.0455290620386, 200.0]]
				||X optimum - X|| = 1.8290376747842654
				alpha = 1.0
				
			Iteration 3:
				X = [-0.5260203055777598, 0.20381651089978448]
				Gradient = [-8.934970141060584, -3.420960192417244]
				||Gradient|| = 9.567479294973552
				Hessian = [[500.9788754830075, 313.73139947992865], [313.73139947992865, 200.0]]
				||X optimum - X|| = 1.7212338950158497
				alpha = 0.6400000000000001
				
			Iteration 4:
				X = [-0.4280488346469222, 0.17362739572623623]
				Gradient = [-18.386763612532782, -14.576170196067062]
				||Gradient|| = 23.46354222464872
				Hessian = [[252.51022989622993, 210.40812223110393], [210.40812223110393, 200.0]]
				||X optimum - X|| = 1.6499136811453607
				alpha = 1.0
				
			Iteration 5:
				X = [-0.22770892157509565, 0.0060483714529718235]
				Gradient = [-4.49953280398138, -1.919681823270386]
				||Gradient|| = 4.891929451320741
				Hessian = [[152.42000752061128, 171.2195338587689], [171.2195338587689, 200.0]]
				||X optimum - X|| = 1.5796230676988652
				alpha = 0.40960000000000013
				
			Iteration 6:
				X = [-0.10687852097281936, -0.003176967464369178]
				Gradient = [-6.627316853151642, -9.160596302384247]
				||Gradient|| = 11.306540288139592
				Hessian = [[61.80227497668294, 91.08356863003826], [91.08356863003826, 200.0]]
				||X optimum - X|| = 1.493835361826056
				alpha = 1.0
				
			Iteration 7:
				X = [0.11901521943427823, -0.03978335664006112]
				Gradient = [-2.8379269934967333, -2.919997141941313]
				||Gradient|| = 4.071880760700496
				Hessian = [[16.978408880152536, 42.75140838912775], [42.75140838912775, 200.0]]
				||X optimum - X|| = 1.3628219297964448
				alpha = 0.8
				
			Iteration 8:
				X = [0.1937408329379481, 0.031951593033990075]
				Gradient = [0.8062826669770855, -10.789595819410104]
				||Gradient|| = 10.819679740422064
				Hessian = [[34.91088960441173, -47.606087773711295], [-47.606087773711295, 200.0]]
				||X optimum - X|| = 1.2598299737270198
				alpha = 1.0
				
			Iteration 9:
				X = [0.3887559116221117, 0.11037532625796068]
				Gradient = [-1.179785217574468, -1.1167834626999689]
				||Gradient|| = 1.6245302281482386
				Hessian = [[34.26197520339188, -77.49633317517925], [-77.49633317517925, 200.0]]
				||X optimum - X|| = 1.079375465585329
				alpha = 0.5120000000000001
				
			Iteration 10:
				X = [0.45555002880202533, 0.20306437465168206]
				Gradient = [5.1151401600508555, -8.151166512635688]
				||Gradient|| = 9.623210190662913
				Hessian = [[139.20726008218267, -155.5023646488447], [-155.5023646488447, 200.0]]
				||X optimum - X|| = 0.9651591382185583
				alpha = 1.0
				
			Iteration 11:
				X = [0.6028626842386692, 0.33956520799981416]
				Gradient = [-0.2759337267450006, -0.8922908179688105]
				||Gradient|| = 0.9339819727311837
				Hessian = [[169.8052446291585, -182.22001152081015], [-182.22001152081015, 200.0]]
				||X optimum - X|| = 0.7706439917721046
				alpha = 0.5120000000000001
				
			Iteration 12:
				X = [0.6716234112038239, 0.4463499689042841]
				Gradient = [4.963837607840998, -4.7756416095278365]
				||Gradient|| = 6.888137381010215
				Hessian = [[302.3060160570183, -241.14507369546766], [-241.14507369546766, 200.0]]
				||X optimum - X|| = 0.6437076518122961
				alpha = 1.0
				
			Iteration 13:
				X = [0.8066461581204754, 0.6315012747110496]
				Gradient = [0.6134311115788658, -0.9456075145553133]
				||Gradient|| = 1.1271518532284637
				Hessian = [[364.75362021075915, -268.6493644815295], [-268.6493644815295, 200.0]]
				||X optimum - X|| = 0.41614542975882074
				alpha = 0.8
				
			Iteration 14:
				X = [0.8466337173008839, 0.7151896463815063]
				Gradient = [5.800832904368217, -3.835349939894672]
				||Gradient|| = 6.95410465450809
				Hessian = [[530.2131194082077, -322.6584632481901], [-322.6584632481901, 200.0]]
				||X optimum - X|| = 0.3234782128633034
				alpha = 1.0
				
			Iteration 15:
				X = [0.9395969960218638, 0.8738805427649143]
				Gradient = [0.23477601593431818, -0.31980097784134465]
				||Gradient|| = 0.39672716454292795
				Hessian = [[576.0705229722531, -338.65348692035354], [-338.65348692035354, 200.0]]
				||X optimum - X|| = 0.13983790753173955
				alpha = 0.8
				
			Iteration 16:
				X = [0.9612282538590855, 0.9234918447013661]
				Gradient = [3.247450843186259, -1.7923944336791786]
				||Gradient|| = 3.7092606790026568
				Hessian = [[711.8588008140065, -375.8387984087455], [-375.8387984087455, 200.0]]
				||X optimum - X|| = 0.08577147617952832
				alpha = 1.0
				
			Iteration 17:
				X = [0.9966821446621001, 0.9921183191151715]
				Gradient = [0.1023643384680552, -0.09358226312408124]
				||Gradient|| = 0.1386942600161497
				Hessian = [[741.3549693398375, -384.4913015436342], [-384.4913015436342, 200.0]]
				||X optimum - X|| = 0.0085515529357832
				alpha = 1.0
				
			Iteration 18:
				X = [0.9993334686239816, 0.9986603519932877]
				Gradient = [0.49448744959112656, -0.2513956746144075]
				||Gradient|| = 0.5547230146820754
				Hessian = [[797.2030293398236, -398.67285786484007], [-398.67285786484007, 200.0]]
				||X optimum - X|| = 0.0014963023949406329
				alpha = 1.0
				
			Iteration 19:
				X = [0.9999990642366321, 0.9999976854566203]
				Gradient = [0.0014768705903435392, -0.0014059037501512606]
				||Gradient|| = 0.0020390468595182045
				Hessian = [[800.9367170171311, -399.73338744959267], [-399.73338744959267, 200.0]]
				||X optimum - X|| = 2.496550447593398e-06
				alpha = 1.0
				
			Iteration 20:
				X = [0.9999999999170954, 0.9999999998333153]
				Gradient = [0.00017533531526356437, -8.860350391159955e-05]
				||Gradient|| = 0.0001964511483396988
				Hessian = [[801.9986799863196, -399.9996256946528], [-399.9996256946528, 200.0]]
				||X optimum - X|| = 1.8616376118149183e-10
				alpha = 1.0
				
			Iteration 21:
				X = [1.0, 1.0]
				Gradient = [1.8439960666621747e-10, -1.751043754438797e-10]
				||Gradient|| = 2.5429266060633147e-10
				Hessian = [[801.9999998677029, -399.9999999668382], [-399.9999999668382, 200.0]]
				||X optimum - X|| = 0.0
				alpha = 1.0
				
		____________________________________________________________________________________________________

	- Starting Point : [0.2 0.8]
	------------------------------
		- Newton Method:
			Iteration 0:
				X = [0.19470198675496692, 0.0378807947019868]
				Gradient = [-62.4, 152.0]
				||Gradient|| = 164.3099510072351
				Hessian = [[-270.0, -80.0], [-80.0, 200.0]]
				||X optimum - X|| = 1.2546626061773254
				alpha = 1.0
				
			Iteration 1:
				X = [0.36264243842403443, 0.10328336037925169]
				Gradient = [-1.60840999479807, -0.005613788868902292]
				||Gradient|| = 1.6084197915941572
				Hessian = [[32.33831849480285, -77.88079470198677], [-77.88079470198677, 200.0]]
				||X optimum - X|| = 1.1001478959988915
				alpha = 0.2097152000000001
				
			Iteration 2:
				X = [0.45855439767011513, 0.20107303169618024]
				Gradient = [2.8196888499564166, -5.64523555337558]
				||Gradient|| = 6.3102559111072685
				Hessian = [[118.49810162365483, -145.05697536961378], [-145.05697536961378, 200.0]]
				||X optimum - X|| = 0.9651153511189761
				alpha = 1.0
				
			Iteration 3:
				X = [0.6110839108381566, 0.348318472912692]
				Gradient = [0.6044246193742939, -1.8398207852843684]
				||Gradient|| = 1.9365612932386493
				Hessian = [[173.89735006865038, -183.42175906804604], [-183.42175906804604, 200.0]]
				||X optimum - X|| = 0.7589100982038575
				alpha = 0.8
				
			Iteration 4:
				X = [0.6756770255820655, 0.4523671724271075]
				Gradient = [5.358690340143738, -5.021014634512822]
				||Gradient|| = 7.3434426614185355
				Hessian = [[310.7808661372306, -244.43356433526264], [-244.43356433526264, 200.0]]
				||X optimum - X|| = 0.6364645359882809
				alpha = 1.0
				
			Iteration 5:
				X = [0.817113314621589, 0.6468354909801444]
				Gradient = [0.47899697222849236, -0.8344540944639545]
				||Gradient|| = 0.962159932221105
				Hessian = [[368.90046250846973, -270.2708102328262], [-270.2708102328262, 200.0]]
				||X optimum - X|| = 0.39770932868105774
				alpha = 0.8
				
			Iteration 6:
				X = [0.8525034157947277, 0.7255096146806332]
				Gradient = [6.445251114632926, -4.167735590347088]
				||Gradient|| = 7.675368517649349
				Hessian = [[544.474806326198, -326.8453258486356], [-326.8453258486356, 200.0]]
				||X optimum - X|| = 0.31160907237273666
				alpha = 1.0
				
			Iteration 7:
				X = [0.9468641004771321, 0.8873971941064274]
				Gradient = [0.13209715086333518, -0.2504918522090227]
				||Gradient|| = 0.2831886743662564
				Hessian = [[583.9106428577608, -341.00136631789104], [-341.00136631789104, 200.0]]
				||X optimum - X|| = 0.12451030364275043
				alpha = 0.8
				
			Iteration 8:
				X = [0.9656341593996454, 0.932097014687505]
				Gradient = [3.3609289041089117, -1.8308861331882254]
				||Gradient|| = 3.8272688867096423
				Hessian = [[722.9030720842711, -378.74564019085284], [-378.74564019085284, 200.0]]
				||X optimum - X|| = 0.07610404992191866
				alpha = 1.0
				
			Iteration 9:
				X = [0.9977378751577075, 0.9944502189587427]
				Gradient = [0.06735132158974264, -0.07046302239093194]
				||Gradient|| = 0.09747429427469535
				Hessian = [[748.1003898843496, -386.25366375985817], [-386.25366375985817, 200.0]]
				||X optimum - X|| = 0.005993102569455594
				alpha = 1.0
				
			Iteration 10:
				X = [0.9996133988412157, 0.9992234295538]
				Gradient = [0.40680259421572684, -0.20612971309488248]
				||Gradient|| = 0.4560458412059295
				Hessian = [[798.7969534455635, -399.095150063083], [-399.095150063083, 200.0]]
				||X optimum - X|| = 0.0008674803247824803
				alpha = 1.0
				
			Iteration 11:
				X = [0.9999997282104054, 0.9999993071705031]
				Gradient = [0.0006332893558060227, -0.0007035178174907841]
				||Gradient|| = 0.0009465689239058102
				Hessian = [[801.3829647499449, -399.8453595364863], [-399.8453595364863, 200.0]]
				||X optimum - X|| = 7.442326890767022e-07
				alpha = 1.0
				
			Iteration 12:
				X = [0.9999999999918873, 0.9999999999837007]
				Gradient = [5.915655718416605e-05, -2.9850076299631212e-05]
				||Gradient|| = 6.62610391782178e-05
				Hessian = [[801.9996248368603, -399.9998912841622], [-399.9998912841622, 200.0]]
				||X optimum - X|| = 1.8206687165216637e-11
				alpha = 1.0
				
			Iteration 13:
				X = [1.0, 1.0]
				Gradient = [1.3306467039102766e-11, -1.4765966227514582e-11]
				||Gradient|| = 1.9877017474833328e-11
				Hessian = [[801.9999999870493, -399.9999999967549], [-399.9999999967549, 200.0]]
				||X optimum - X|| = 0.0
				alpha = 1.0
				
		____________________________________________________________________________________________________

Running: Quadratic
===================
	- Starting Point : [-0.2  1.2]
	------------------------------
		- Newton Method:
			Iteration 0:
				X = [-0.10816326530612252, 1.10204081632653]
				Gradient = [-172.64999999999998, 15.000000000000002]
				||Gradient|| = 173.30038228463314
				Hessian = [[1728.5, -142.0], [-142.0, 20.0]]
				||X optimum - X|| = 4.253410322936209
				alpha = 1.0
				
			Iteration 1:
				X = [-0.05655506657270731, 1.0516387666431766]
				Gradient = [-78.74317950003824, 4.167929179168546]
				||Gradient|| = 78.85340798860761
				Hessian = [[1457.8927530195738, -69.5201999167014], [-69.5201999167014, 11.509787588504794]]
				||X optimum - X|| = 4.190654257230425
				alpha = 1.0
				
			Iteration 2:
				X = [-0.02896715532367682, 1.0259917888309191]
				Gradient = [-37.490545168247166, 1.159092266353242]
				||Gradient|| = 37.50845867126908
				Hessian = [[1327.632914608138, -33.685300274766796], [-33.685300274766796, 8.959542666513007]]
				||X optimum - X|| = 4.157551621979628
				alpha = 1.0
				
			Iteration 3:
				X = [-0.014666391111122926, 1.0130415977777807]
				Gradient = [-18.276774673572387, 0.33327170875870876]
				||Gradient|| = 18.279812977719327
				Hessian = [[1263.6909808981632, -15.83203810472936], [-15.83203810472936, 8.251728826263806]]
				||X optimum - X|| = 4.140507156224388
				alpha = 1.0
				
			Iteration 4:
				X = [-0.007380312982140621, 1.0065325782455352]
				Gradient = [-9.02148417981964, 0.10287249461979299]
				||Gradient|| = 9.022070691193088
				Hessian = [[1232.0039345937907, -6.914598570907485], [-6.914598570907485, 8.064530908467328]]
				||X optimum - X|| = 4.131852466381932
				alpha = 1.0
				
			Iteration 5:
				X = [-0.0037021204166093244, 1.0032692801041525]
				Gradient = [-4.481544226770798, 0.03519745285427832]
				||Gradient|| = 4.481682442698289
				Hessian = [[1216.2293972835253, -2.4571152725037972], [-2.4571152725037972, 8.016340705914306]]
				||X optimum - X|| = 4.127490753160952
				alpha = 1.0
				
			Iteration 6:
				X = [-0.0018540747749610734, 1.0016353936937403]
				Gradient = [-2.233476163696211, 0.013500151001084107]
				||Gradient|| = 2.2335169638657764
				Hessian = [[1208.3590980808453, -0.2285342111383133], [-0.2285342111383133, 8.004111708673722]]
				||X optimum - X|| = 4.125301140243337
				alpha = 1.0
				
			Iteration 7:
				X = [-0.0009277940102986148, 1.0008178860025747]
				Gradient = [-1.1149145358580115, 0.005720464526851448]
				||Gradient|| = 1.1149292111976832
				Hessian = [[1204.428154280017, 0.8857358497065393], [0.8857358497065393, 8.001031277981344]]
				||X optimum - X|| = 4.124204123685778
				alpha = 1.0
				
			Iteration 8:
				X = [-0.00046408653558793793, 1.000408990383897]
				Gradient = [-0.5570014367420546, 0.0026022017289690238]
				||Gradient|| = 0.5570075151975521
				Hessian = [[1202.4637291311951, 1.4428682959802535], [1.4428682959802535, 8.000258240517663]]
				||X optimum - X|| = 4.123655060222902
				alpha = 1.0
				
			Iteration 9:
				X = [-0.0002320906973768847, 1.0002045070493442]
				Gradient = [-0.27838676749671004, 0.001236514319807136]
				||Gradient|| = 0.2783895136044646
				Hessian = [[1201.4817776491138, 1.7214341944890263], [1.7214341944890263, 8.000064612893754]]
				||X optimum - X|| = 4.1233803893610075
				alpha = 1.0
				
			Iteration 10:
				X = [-0.00011605721196407455, 1.0001022564904911]
				Gradient = [-0.13916489689562797, 0.0006021006323407823]
				||Gradient|| = 0.1391661993917425
				Hessian = [[1200.9908671061858, 1.8607171030636487], [1.8607171030636487, 8.000016159827542]]
				||X optimum - X|| = 4.123243019105515
				alpha = 1.0
				
			Iteration 11:
				X = [-5.803157253644949e-05, 1.000051128986884]
				Gradient = [-0.0695753268428983, 0.0002970099461311216]
				||Gradient|| = 0.06957596079253398
				Hessian = [[1200.7454281248463, 1.9303585522596403], [1.9303585522596403, 8.000004040782935]]
				||X optimum - X|| = 4.123174325266383
				alpha = 1.0
				
			Iteration 12:
				X = [-2.9016527998798107e-05, 1.0000255646788747]
				Gradient = [-0.03478588303375583, 0.0001474947256785262]
				||Gradient|| = 0.034786195726641975
				Hessian = [[1200.6227127055297, 1.9651792762208236], [1.9651792762208236, 8.000001010299023]]
				||X optimum - X|| = 4.123139976168314
				alpha = 1.0
				
			Iteration 13:
				X = [-1.4508449443540702e-05, 1.0000127823857985]
				Gradient = [-0.017392496421646624, 7.349478162627652e-05]
				||Gradient|| = 0.01739265170294389
				Hessian = [[1200.5613560135625, 1.982589638121789], [1.982589638121789, 8.00000025258767]]
				||X optimum - X|| = 4.123122801074572
				alpha = 1.0
				
			Iteration 14:
				X = [-7.254271084243178e-06, 1.0000063912044899]
				Gradient = [-0.008696136937226899, 3.66842430891209e-05]
				||Gradient|| = 0.0086962143122564
				Hessian = [[1200.5306779219836, 1.9912948190623168], [1.9912948190623168, 8.000000063148532]]
				||X optimum - X|| = 4.1231142133915135
				alpha = 1.0
				
			Iteration 15:
				X = [-3.6271471329194795e-06, 1.0000031956051427]
				Gradient = [-0.0043480406502408135, 1.8326334310766824e-05]
				||Gradient|| = 0.004348079271434207
				Hessian = [[1200.5153389397926, 1.9956474095313361], [1.9956474095313361, 8.000000015787334]]
				||X optimum - X|| = 4.1231099195159375
				alpha = 1.0
				
			Iteration 16:
				X = [-1.8135764641816738e-06, 1.000001597803296]
				Gradient = [-0.002174013370530441, 9.159220309542663e-06]
				||Gradient|| = 0.0021740326645572298
				Hessian = [[1200.5076694645968, 1.9978237047656904], [1.9978237047656904, 8.000000003946859]]
				||X optimum - X|| = 4.123107772569637
				alpha = 1.0
				
			Iteration 17:
				X = [-9.06788956524128e-07, 1.0000007989018291]
				Gradient = [-0.0010870049466180595, 4.5786234389145535e-06]
				||Gradient|| = 0.0010870145894902818
				Hessian = [[1200.5038347309737, 1.998911852382848], [1.998911852382848, 8.000000000986718]]
				||X optimum - X|| = 4.1231066990943575
				alpha = 1.0
				
			Iteration 18:
				X = [-4.533946593707378e-07, 1.0000003994509599]
				Gradient = [-0.0005435020386473187, 2.2890650397908464e-06]
				||Gradient|| = 0.0005435068590482993
				Hessian = [[1200.5019173651558, 1.9994559261914242], [1.9994559261914242, 8.00000000024668]]
				||X optimum - X|| = 4.123106162356187
				alpha = 1.0
				
			Iteration 19:
				X = [-2.2669737496258125e-07, 1.0000001997254913]
				Gradient = [-0.0002717509106582381, 1.1444708499049135e-06]
				||Gradient|| = 0.00027175332059996613
				Hessian = [[1200.5009586824954, 1.999727963095712], [1.999727963095712, 8.00000000006167]]
				||X optimum - X|| = 4.123105893986967
				alpha = 1.0
				
			Iteration 20:
				X = [-1.133486988005992e-07, 1.0000000998627485]
				Gradient = [-0.0001358754281626535, 5.722200078896808e-07]
				||Gradient|| = 0.00013587663306883138
				Hessian = [[1200.500479341227, 1.999863981547856], [1.999863981547856, 8.000000000015417]]
				||X optimum - X|| = 4.123105759802325
				alpha = 1.0
				
			Iteration 21:
				X = [-5.667435223012742e-08, 1.0000000499313748]
				Gradient = [-6.793770728962723e-05, 2.8610615001105857e-07]
				||Gradient|| = 6.793830972654634e-05
				Hessian = [[1200.5002396706084, 1.9999319907739281], [1.9999319907739281, 8.000000000003855]]
				||X optimum - X|| = 4.123105692709996
				alpha = 1.0
				
			Iteration 22:
				X = [-2.8337176822520754e-08, 1.0000000249656875]
				Gradient = [-3.396885194713851e-05, 1.4305211052273876e-07]
				||Gradient|| = 3.3969153161551455e-05
				Hessian = [[1200.5001198353025, 1.999965995386964], [1.999965995386964, 8.000000000000963]]
				||X optimum - X|| = 4.123105659163829
				alpha = 1.0
				
			Iteration 23:
				X = [-1.4168588588124647e-08, 1.0000000124828439]
				Gradient = [-1.6984425549206003e-05, 7.152581391860911e-08]
				||Gradient|| = 1.6984576155399884e-05
				Hessian = [[1200.5000599176508, 1.999982997693482], [1.999982997693482, 8.000000000000242]]
				||X optimum - X|| = 4.123105642390745
				alpha = 1.0
				
			Iteration 24:
				X = [-7.084294338278393e-09, 1.000000006241422]
				Gradient = [-8.492212668484434e-06, 3.576284673463453e-08]
				||Gradient|| = 8.492287971328698e-06
				Hessian = [[1200.5000299588255, 1.999991498846741], [1.999991498846741, 8.00000000000006]]
				||X optimum - X|| = 4.123105634004203
				alpha = 1.0
				
			Iteration 25:
				X = [-3.5421471801932146e-09, 1.000000003120711]
				Gradient = [-4.24610630749053e-06, 1.7881409199327897e-08]
				||Gradient|| = 4.246143958853235e-06
				Hessian = [[1200.500014979413, 1.9999957494233704], [1.9999957494233704, 8.000000000000014]]
				||X optimum - X|| = 4.123105629810931
				alpha = 1.0
				
			Iteration 26:
				X = [-1.7710735928601114e-09, 1.0000000015603554]
				Gradient = [-2.1230531471128553e-06, 8.940700835621967e-09]
				||Gradient|| = 2.1230719727784153e-06
				Hessian = [[1200.5000074897064, 1.9999978747116853], [1.9999978747116853, 8.000000000000004]]
				||X optimum - X|| = 4.123105627714296
				alpha = 1.0
				
			Iteration 27:
				X = [-8.855367971209317e-10, 1.0000000007801777]
				Gradient = [-1.061526572120369e-06, 4.470348588622064e-09]
				||Gradient|| = 1.0615359849454586e-06
				Hessian = [[1200.500003744853, 1.9999989373558427], [1.9999989373558427, 8.000000000000002]]
				||X optimum - X|| = 4.1231056266659785
				alpha = 1.0
				
			Iteration 28:
				X = [-4.427683987331849e-10, 1.0000000003900889]
				Gradient = [-5.307632856456589e-07, 2.2351740590584064e-09]
				||Gradient|| = 5.307679920572167e-07
				Hessian = [[1200.5000018724265, 1.9999994686779212], [1.9999994686779212, 8.0]]
				||X optimum - X|| = 4.123105626141819
				alpha = 1.0
				
		____________________________________________________________________________________________________

	- Starting Point : [3.8 0.1]
	------------------------------
		- Newton Method:
			Iteration 0:
				X = [4.179999999999983, -0.019999999999999102]
				Gradient = [22.850000000000005, 433.40000000000003]
				||Gradient|| = 434.0019383597267
				Hessian = [[12.500000000000002, 230.0], [230.0, 4340.0]]
				||X optimum - X|| = 0.18110770276273117
				alpha = 1.0
				
			Iteration 1:
				X = [4.054792626728103, -0.0011981566820275028]
				Gradient = [1.0281999999999023, -104.73439999999447]
				||Gradient|| = 104.7394469080243
				Hessian = [[0.9799999999999569, -48.15999999999754], [-48.15999999999754, 5249.7199999999575]]
				||X optimum - X|| = 0.054805725277565026
				alpha = 1.0
				
			Iteration 2:
				X = [4.025070261645625, -1.7565411406979e-05]
				Gradient = [0.015992586144109363, -5.859791581427623]
				||Gradient|| = 5.85981340492866
				Hessian = [[0.5017226953216246, -0.9149661279700756], [-0.9149661279700756, 4940.402973730576]]
				||X optimum - X|| = 0.025070267799203027
				alpha = 1.0
				
			Iteration 3:
				X = [4.012500438837772, -1.0970944335391539e-07]
				Gradient = [0.006250745145988592, -0.060374173510502824]
				||Gradient|| = 0.06069689153454566
				Hessian = [[0.5000003702524135, 1.9575787909473188], [1.9575787909473188, 4868.357183355193]]
				||X optimum - X|| = 0.012500438838253062
				alpha = 1.0
				
			Iteration 4:
				X = [4.0062500013671904, -3.4179785202235065e-10]
				Gradient = [0.0031250000289766633, 0.011970098130060587]
				||Gradient|| = 0.012371292350614956
				Hessian = [[0.5000000000144434, 1.9997358744862386], [1.9997358744862386, 4838.047931501994]]
				||X optimum - X|| = 0.006250001367190458
				alpha = 1.0
				
			Iteration 5:
				X = [4.003125000002132, -5.332262109783976e-13]
				Gradient = [0.00156249999999997, 0.0062483542393347025]
				||Gradient|| = 0.006440755930029631
				Hessian = [[0.5000000000000001, 1.999999178403413], [1.999999178403413, 4823.011722036384]]
				||X optimum - X|| = 0.0031250000021323388
				alpha = 1.0
				
			Iteration 6:
				X = [4.001562500000001, -4.1625776957962844e-16]
				Gradient = [0.0007812499999999556, 0.003124997436513251]
				||Gradient|| = 0.003221173783066403
				Hessian = [[0.5, 1.9999999987192574], [1.9999999987192574, 4815.502929692621]]
				||X optimum - X|| = 0.0015625000000012434
				alpha = 1.0
				
			Iteration 7:
				X = [4.00078125, -1.6258220292042142e-19]
				Gradient = [0.0003906249999998668, 0.0015624999979998685]
				||Gradient|| = 0.0016105881330664537
				Hessian = [[0.5, 1.9999999999990006], [1.9999999999990006, 4811.750732421878]]
				||X optimum - X|| = 0.0007812500000001776
				alpha = 1.0
				
			Iteration 8:
				X = [4.000390625, -3.796463650618866e-23]
				Gradient = [0.0001953125000000444, 0.0007812499999993969]
				||Gradient|| = 0.0008052940675028749
				Hessian = [[0.5, 1.9999999999999996], [1.9999999999999996, 4809.87518310547]]
				||X optimum - X|| = 0.00039062499999964473
				alpha = 1.0
				
			Iteration 9:
				X = [4.0001953125, -4.0899350916909854e-24]
				Gradient = [9.765624999991118e-05, 0.00039062499999964457]
				||Gradient|| = 0.00040264703375135827
				Hessian = [[0.5, 2.0], [2.0, 4808.937545776366]]
				||X optimum - X|| = 0.00019531249999982236
				alpha = 1.0
				
			Iteration 10:
				X = [4.00009765625, 1.5563998099830313e-24]
				Gradient = [4.882812499995559e-05, 0.00019531249999982234]
				||Gradient|| = 0.00020132351687567922
				Hessian = [[0.5, 2.0], [2.0, 4808.468761444091]]
				||X optimum - X|| = 9.765625000035527e-05
				alpha = 1.0
				
			Iteration 11:
				X = [4.000048828125, -1.2669054891444224e-24]
				Gradient = [2.4414062500088818e-05, 9.765625000035528e-05]
				||Gradient|| = 0.00010066175843829739
				Hessian = [[0.5, 2.0], [2.0, 4808.234377861024]]
				||X optimum - X|| = 4.8828125000177636e-05
				alpha = 1.0
				
			Iteration 12:
				X = [4.0000244140625, 1.4478162438496657e-25]
				Gradient = [1.2207031250044409e-05, 4.882812500017763e-05]
				||Gradient|| = 5.033087921914868e-05
				Hessian = [[0.5, 2.0], [2.0, 4808.117188215257]]
				||X optimum - X|| = 2.441406249964473e-05
				alpha = 1.0
				
			Iteration 13:
				X = [4.00001220703125, 1.4478162438496657e-25]
				Gradient = [6.103515624911182e-06, 2.441406249964473e-05]
				||Gradient|| = 2.5165439609116586e-05
				Hessian = [[0.5, 2.0], [2.0, 4808.058593928813]]
				||X optimum - X|| = 1.2207031249822364e-05
				alpha = 1.0
				
			Iteration 14:
				X = [4.000006103515625, 1.4478162438496657e-25]
				Gradient = [3.051757812455591e-06, 1.2207031249822364e-05]
				||Gradient|| = 1.2582719804558293e-05
				Hessian = [[0.5, 2.0], [2.0, 4808.029296919703]]
				||X optimum - X|| = 6.103515625355271e-06
				alpha = 1.0
				
			Iteration 15:
				X = [4.000003051757813, -3.168303443186726e-26]
				Gradient = [1.5258789063388178e-06, 6.103515625355272e-06]
				||Gradient|| = 6.291359902736904e-06
				Hessian = [[0.5, 2.0], [2.0, 4808.014648448677]]
				||X optimum - X|| = 3.0517578126776357e-06
				alpha = 1.0
				
			Iteration 16:
				X = [4.000001525878906, -3.168303443186726e-26]
				Gradient = [7.629394531694089e-07, 3.0517578126776357e-06]
				||Gradient|| = 3.1456799513684517e-06
				Hessian = [[0.5, 2.0], [2.0, 4808.007324221544]]
				||X optimum - X|| = 1.5258789058947286e-06
				alpha = 1.0
				
			Iteration 17:
				X = [4.000000762939453, 1.2433231246248194e-26]
				Gradient = [3.8146972647368216e-07, 1.5258789058947284e-06]
				||Gradient|| = 1.572839975226469e-06
				Hessian = [[0.5, 2.0], [2.0, 4808.003662110073]]
				||X optimum - X|| = 7.629394529473643e-07
				alpha = 1.0
				
			Iteration 18:
				X = [4.000000381469727, -9.624910007318629e-27]
				Gradient = [1.9073486323684108e-07, 7.629394529473644e-07]
				||Gradient|| = 7.864199876132347e-07
				Hessian = [[0.5, 2.0], [2.0, 4808.001831054862]]
				||X optimum - X|| = 3.8146972691777137e-07
				alpha = 1.0
				
		____________________________________________________________________________________________________

	- Starting Point : [1.9 0.6]
	------------------------------
		- Newton Method:
			Iteration 0:
				X = [0.42586206896545153, 0.9310344827586621]
				Gradient = [410.47499999999997, 650.0999999999999]
				||Gradient|| = 768.8431150924093
				Hessian = [[432.5, 686.0], [686.0, 1091.0]]
				||X optimum - X|| = 3.693411317216864
				alpha = 1.0
				
			Iteration 1:
				X = [0.20456644682811875, 0.9676083882929835]
				Gradient = [221.52628592806786, 50.80530567057591]
				||Gradient|| = 227.27752735667627
				Hessian = [[1040.6902497028273, 239.8953626634697], [239.8953626634697, 62.407550535060494]]
				||X optimum - X|| = 3.916833140387509
				alpha = 1.0
				
			Iteration 2:
				X = [0.10052473812709735, 0.984243815468232]
				Gradient = [114.93591449605974, 12.222577627966679]
				||Gradient|| = 115.5839774575924
				Hessian = [[1124.019191713934, 120.76412594850697], [120.76412594850697, 20.554229350364462]]
				||X optimum - X|| = 4.0217711528934865
				alpha = 1.0
				
			Iteration 3:
				X = [0.04985485598820203, 0.9922237860029527]
				Gradient = [58.43852789065097, 3.021300965275382]
				||Gradient|| = 58.516577151685524
				Hessian = [[1162.9830659449558, 61.36451108189549], [61.36451108189549, 11.03156689265645]]
				||X optimum - X|| = 4.072855840840678
				alpha = 1.0
				
			Iteration 4:
				X = [0.02482913052899202, 0.9961364673677535]
				Gradient = [29.454191477225724, 0.7586036501644742]
				||Gradient|| = 29.463958917211368
				Hessian = [[1181.9096498120398, 31.680304375547475], [31.680304375547475, 8.745651999681309]]
				||X optimum - X|| = 4.098081417335531
				alpha = 1.0
				
			Iteration 5:
				X = [0.012390414966159325, 0.998074271258461]
				Gradient = [14.784930653097035, 0.19360617303548738]
				||Gradient|| = 14.786198218850096
				Hessian = [[1191.2454339438889, 16.839921423777774], [16.839921423777774, 8.184945716847716]]
				||X optimum - X|| = 4.110618256856488
				alpha = 1.0
				
			Iteration 6:
				X = [0.006189221540182843, 0.9990386321149547]
				Gradient = [7.406815730232444, 0.050655522170448004]
				||Gradient|| = 7.406988945823069
				Hessian = [[1195.8827011377298, 9.41993263276364], [9.41993263276364, 8.046056714910087]]
				||X optimum - X|| = 4.116868072042136
				alpha = 1.0
				
			Iteration 7:
				X = [0.0030931206550055437, 0.9995196885862488]
				Gradient = [3.706982151175, 0.013824641000966174]
				||Gradient|| = 3.707007929561095
				Hessian = [[1198.1938261497437, 5.709962852816409], [5.709962852816409, 8.011491938982038]]
				||X optimum - X|| = 4.119988374986863
				alpha = 1.0
				
			Iteration 8:
				X = [0.0015461885899356548, 0.9997599372275162]
				Gradient = [1.854382996515682, 0.004040715017166097]
				||Gradient|| = 1.85438739888523
				Hessian = [[1199.3475294458622, 3.854980996310501], [3.854980996310501, 8.002870218615927]]
				||X optimum - X|| = 4.121547381028737
				alpha = 1.0
				
			Iteration 9:
				X = [0.0007730014591587764, 0.9998799918227104]
				Gradient = [0.9274142730170077, 0.001302975071334274]
				||Gradient|| = 0.927415188327052
				Hessian = [[1199.9239185022006, 2.927490444569583], [2.927490444569583, 8.000717209746695]]
				||X optimum - X|| = 4.122326598403548
				alpha = 1.0
				
			Iteration 10:
				X = [0.00038647753293018114, 0.9999400017105174]
				Gradient = [0.4637628045670217, 0.00047220661416759]
				||Gradient|| = 0.4637630449690402
				Hessian = [[1200.21199765686, 2.463745215597572], [2.463745215597572, 8.00017925937676]]
				||X optimum - X|| = 4.122716135768053
				alpha = 1.0
				
			Iteration 11:
				X = [0.00019323296883943662, 0.9999700023046652]
				Gradient = [0.23189531609752337, 0.00019129115154632958]
				||Gradient|| = 0.2318953949958363
				Hessian = [[1200.3560084249957, 2.2318726069635693], [2.2318726069635693, 8.000044809465038]]
				||X optimum - X|| = 4.122910886630641
				alpha = 1.0
				
			Iteration 12:
				X = [9.661503520530876e-05, 0.9999850015146362]
				Gradient = [0.11595113610239323, 8.444354554876711e-05]
				||Gradient|| = 0.11595116685117103
				Hessian = [[1200.4280066110305, 2.1159363033774254], [2.1159363033774254, 8.000011201694074]]
				||X optimum - X|| = 4.123008257608399
				alpha = 1.0
				
			Iteration 13:
				X = [4.830715532304766e-05, 0.9999925008478879]
				Gradient = [0.0579764375146335, 3.942139125782106e-05]
				||Gradient|| = 0.05797645091702571
				Hessian = [[1200.4640039050723, 2.0579681516756705], [2.0579681516756705, 8.000002800339509]]
				||X optimum - X|| = 4.123056941984068
				alpha = 1.0
				
			Iteration 14:
				X = [2.4153487094621308e-05, 0.9999962504465857]
				Gradient = [0.028988436116930347, 1.901061600183491e-05]
				||Gradient|| = 0.02898844235051053
				Hessian = [[1200.4820021024157, 2.028984075836205], [2.028984075836205, 8.000000700074377]]
				||X optimum - X|| = 4.12308128389362
				alpha = 1.0
				
			Iteration 15:
				X = [1.20767209059599e-05, 0.9999981252289533]
				Gradient = [0.014494272397587814, 9.330290062557094e-06]
				||Gradient|| = 0.014494275400646583
				Hessian = [[1200.4910010886767, 2.0144920379178988], [2.0144920379178988, 8.000000175017282]]
				||X optimum - X|| = 4.123093454778829
				alpha = 1.0
				
			Iteration 16:
				X = [6.0383547926891206e-06, 0.9999990626158918]
				Gradient = [0.007247149783477018, 4.621390792895474e-06]
				||Gradient|| = 0.007247151256970138
				Hessian = [[1200.4955005537056, 2.007246018958924], [2.007246018958924, 8.000000043754156]]
				||X optimum - X|| = 4.123099540204042
				alpha = 1.0
				
			Iteration 17:
				X = [3.01917598127771e-06, 0.9999995313082997]
				Gradient = [0.003623578287897202, 2.299756868057395e-06]
				||Gradient|| = 0.003623579017684266
				Hessian = [[1200.4977502791949, 2.0036230094794587], [2.0036230094794587, 8.00000001093852]]
				||X optimum - X|| = 4.123102582912301
				alpha = 1.0
				
			Iteration 18:
				X = [1.5095876368728746e-06, 0.9999997656542383]
				Gradient = [0.0018117899929867213, 1.147143805665216e-06]
				||Gradient|| = 0.0018117903561465755
				Hessian = [[1200.498875140183, 2.001811504739729], [2.001811504739729, 8.000000002734627]]
				||X optimum - X|| = 4.123104104265343
				alpha = 1.0
				
			Iteration 19:
				X = [7.547937299950337e-07, 0.9999998828271413]
				Gradient = [0.0009058952087528112, 5.728882466664649e-07]
				||Gradient|| = 0.0009058953899000935
				Hessian = [[1200.499437570238, 2.0009057523698646], [2.0009057523698646, 8.000000000683656]]
				||X optimum - X|| = 4.123104864941592
				alpha = 1.0
				
			Iteration 20:
				X = [3.773968428871774e-07, 0.9999999414135762]
				Gradient = [0.00045294765744110556, 2.862732087966648e-07]
				||Gradient|| = 0.00045294774790668205
				Hessian = [[1200.4997187851554, 2.0004528761849323], [2.0004528761849323, 8.000000000170914]]
				||X optimum - X|| = 4.123105245279649
				alpha = 1.0
				
			Iteration 21:
				X = [1.886984159160053e-07, 0.9999999707067895]
				Gradient = [0.0002264738419868636, 1.430938763268119e-07]
				||Gradient|| = 0.00022647388719264813
				Hessian = [[1200.499859392587, 2.000226438092466], [2.000226438092466, 8.000000000042728]]
				||X optimum - X|| = 4.123105435448661
				alpha = 1.0
				
			Iteration 22:
				X = [9.434920657610696e-08, 0.9999999853533951]
				Gradient = [0.0001132369243099814, 7.153625603544228e-08]
				||Gradient|| = 0.00011323694690612417
				Hessian = [[1200.4999296962958, 2.000113219046233], [2.000113219046233, 8.000000000010683]]
				||X optimum - X|| = 4.123105530533162
				alpha = 1.0
				
			Iteration 23:
				X = [4.7174602942579583e-08, 0.9999999926766977]
				Gradient = [5.661846298401701e-05, 3.5765457041758353e-08]
				||Gradient|| = 5.661847428040093e-05
				Hessian = [[1200.4999648481485, 2.0000566095231167], [2.0000566095231167, 8.00000000000267]]
				||X optimum - X|| = 4.123105578075411
				alpha = 1.0
				
			Iteration 24:
				X = [2.3587301384921323e-08, 0.9999999963383488]
				Gradient = [2.8309231699514887e-05, 1.788206177610387e-08]
				||Gradient|| = 2.8309237347285637e-05
				Hessian = [[1200.4999824240745, 2.000028304761558], [2.000028304761558, 8.000000000000668]]
				||X optimum - X|| = 4.123105601846536
				alpha = 1.0
				
			Iteration 25:
				X = [1.1793650670868543e-08, 0.9999999981691744]
				Gradient = [1.4154615901356478e-05, 8.940863091636918e-09]
				||Gradient|| = 1.4154618725135852e-05
				Hessian = [[1200.499991212037, 2.0000141523807793], [2.0000141523807793, 8.000000000000167]]
				||X optimum - X|| = 4.123105613732099
				alpha = 1.0
				
			Iteration 26:
				X = [5.896825330036242e-09, 0.9999999990845871]
				Gradient = [7.077307963744532e-06, 4.470390262848749e-09]
				||Gradient|| = 7.07730937560814e-06
				Hessian = [[1200.4999956060185, 2.0000070761903896], [2.0000070761903896, 8.00000000000004]]
				||X optimum - X|| = 4.123105619674879
				alpha = 1.0
				
			Iteration 27:
				X = [2.9484126636686134e-09, 0.9999999995422936]
				Gradient = [3.538653985000061e-06, 2.235184255570463e-09]
				||Gradient|| = 3.5386546909249946e-06
				Hessian = [[1200.4999978030091, 2.0000035380951946], [2.0000035380951946, 8.00000000000001]]
				||X optimum - X|| = 4.12310562264627
				alpha = 1.0
				
			Iteration 28:
				X = [1.4742063314969297e-09, 0.9999999997711468]
				Gradient = [1.7693269933097349e-06, 1.1175895198440597e-09]
				||Gradient|| = 1.7693273462705542e-06
				Hessian = [[1200.4999989015046, 2.0000017690475973], [2.0000017690475973, 8.000000000000002]]
				||X optimum - X|| = 4.1231056241319655
				alpha = 1.0
				
			Iteration 29:
				X = [7.371031656641207e-10, 0.9999999998855734]
				Gradient = [8.846634969683159e-07, 5.587945520259472e-10]
				||Gradient|| = 8.846636734485942e-07
				Hessian = [[1200.4999994507525, 2.0000008845237986], [2.0000008845237986, 8.0]]
				||X optimum - X|| = 4.123105624874813
				alpha = 1.0
				
		____________________________________________________________________________________________________
