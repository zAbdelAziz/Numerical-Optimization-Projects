###################
# Approx Solutions #
###################
Running: Rosenbrock
===================
	- Starting Point : [1.2 1.2]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Fletcher-Reevers Method
			------------
			Iteration 0:
				X = [1.085515305178769, 1.247536897504648]
				Current Gradient = [115.59999998800308, -47.9999999960512]
				Next Gradient = [-29.87317583941218, 13.838683944306096]
				|| Gradient || = 125.16932530315574
				beta = 0.06918305370279063
				||X optimum - X|| = 0.26189193008957823
				alpha = 0.0009903520314283058
			Iteration 1:
				X = [1.1193661795347252, 1.2312612396552578]
				Current Gradient = [-29.87317583941218, 13.838683944306096]
				Next Gradient = [9.963518973220287, -4.343880845823767]
				|| Gradient || = 32.92287666718744
				beta = 0.10899463801137445
				||X optimum - X|| = 0.26024996788396115
				alpha = 0.0015474250491067279
			Iteration 2:
				X = [1.109983591503033, 1.235219536131635]
				Current Gradient = [9.963518973220287, -4.343880845823767]
				Next Gradient = [-1.1812595528274197, 0.631192545080643]
				|| Gradient || = 10.869269116754596
				beta = 0.015183365563890446
				||X optimum - X|| = 0.2596625128467479
				alpha = 0.0012379400392853823
			Iteration 3:
				X = [1.1113034607362458, 1.2344982578699923]
				Current Gradient = [-1.1812595528274197, 0.631192545080643]
				Next Gradient = [0.44358915912961344, -0.09942479486501482]
				|| Gradient || = 1.339320036477994
				beta = 0.11520746351289723
				||X optimum - X|| = 0.25957252034051376
				alpha = 0.0012379400392853823
			Iteration 4:
				X = [1.1108071132430553, 1.2345482394893053]
				Current Gradient = [0.44358915912961344, -0.09942479486501482]
				Next Gradient = [-0.06977121004645565, 0.13115933157614723]
				|| Gradient || = 0.4545950196947474
				beta = 0.10679934055147536
				||X optimum - X|| = 0.2594052678585995
				alpha = 0.0015474250491067279
			Iteration 5:
				X = [1.110914449440663, 1.2341622605222686]
				Current Gradient = [-0.06977121004645565, 0.13115933157614723]
				Next Gradient = [0.2078995668553657, 0.006269309242752652]
				|| Gradient || = 0.14856241789513377
				beta = 1.9601260396892766
				||X optimum - X|| = 0.2591022565467623
				alpha = 0.0030223145490365774
			Iteration 6:
				X = [1.1014114710465595, 1.21652908527868]
				Current Gradient = [0.2078995668553657, 0.006269309242752652]
				Next Gradient = [-1.30472595738073, 0.6843713450908895]
				|| Gradient || = 0.20799407236031978
				beta = 50.175612241790006
				||X optimum - X|| = 0.23910067175030913
				alpha = 0.06871947673600004
			Iteration 7:
				X = [1.068154880084665, 1.136489362867673]
				Current Gradient = [-1.30472595738073, 0.6843713450908895]
				Next Gradient = [2.0442415901828457, -0.893096996129085]
				|| Gradient || = 1.4733207260622432
				beta = 2.292627087717568
				||X optimum - X|| = 0.1525596075485854
				alpha = 0.005902958103587064
			Iteration 8:
				X = [0.9975052530887915, 0.9939059056338492]
				Current Gradient = [2.0442415901828457, -0.893096996129085]
				Next Gradient = [0.43823173874165194, -0.2221648611833247]
				|| Gradient || = 2.230817321863914
				beta = 0.048508400423640755
				||X optimum - X|| = 0.006584963803585849
				alpha = 0.004722366482869652
			Iteration 9:
				X = [0.9960643546666832, 0.9923678146309185]
				Current Gradient = [0.43823173874165194, -0.2221648611833247]
				Next Gradient = [-0.0969656583193397, 0.04472319867376754]
				|| Gradient || = 0.4913290978408844
				beta = 0.04723405600040108
				||X optimum - X|| = 0.00858717402279004
				alpha = 0.0012379400392853823
			Iteration 10:
				X = [0.9961293274093187, 0.9922077959873069]
				Current Gradient = [-0.0969656583193397, 0.04472319867376754]
				Next Gradient = [0.01849309078654213, -0.013168187527323795]
				|| Gradient || = 0.10678250508822226
				beta = 0.04520021190383894
				||X optimum - X|| = 0.008700606282304806
				alpha = 0.0015474250491067279
			Iteration 11:
				X = [0.9961036475191353, 0.9922209398939382]
				Current Gradient = [0.01849309078654213, -0.013168187527323795]
				Next Gradient = [-0.007180416789345573, -0.00030734139749654483]
				|| Gradient || = 0.022702325202367608
				beta = 0.10021980601039043
				||X optimum - X|| = 0.00870030682153581
				alpha = 0.0015474250491067279
			Iteration 12:
				X = [0.9961169873991201, 0.992223741249485]
				Current Gradient = [-0.007180416789345573, -0.00030734139749654483]
				Next Gradient = [0.002319195748482598, -0.00506226712292543]
				|| Gradient || = 0.00718699130396934
				beta = 0.600261572075916
				||X optimum - X|| = 0.008691834502195335
				alpha = 0.002417851639229262
			Iteration 13:
				X = [0.9961284312338486, 0.9922901234523287]
				Current Gradient = [0.002319195748482598, -0.00506226712292543]
				Next Gradient = [-0.015023616673731675, 0.003654387984169582]
				|| Gradient || = 0.005568232874407416
				beta = 7.710431662146551
				||X optimum - X|| = 0.008627354234721713
				alpha = 0.011529215046068483
			Iteration 14:
				X = [0.9971257739654319, 0.9940818990172025]
				Current Gradient = [-0.015023616673731675, 0.003654387984169582]
				Next Gradient = [0.06521104239221931, -0.035582017792858855]
				|| Gradient || = 0.015461681975065695
				beta = 23.084065582702863
				||X optimum - X|| = 0.006579140866433732
				alpha = 0.043980465111040035
			Iteration 15:
				X = [0.9992898698006302, 0.9986910837949765]
				Current Gradient = [0.06521104239221931, -0.035582017792858855]
				Next Gradient = [-0.04572473921991707, 0.022167981763858945]
				|| Gradient || = 0.07428701124753335
				beta = 0.4679066954881869
				||X optimum - X|| = 0.0014891428849610547
				alpha = 0.004722366482869652
			Iteration 16:
				X = [0.9997930731928953, 0.99953157606626]
				Current Gradient = [-0.04572473921991707, 0.022167981763858945]
				Next Gradient = [0.0214268817110184, -0.01092262764715069]
				|| Gradient || = 0.05081506855463451
				beta = 0.22400337217019833
				||X optimum - X|| = 0.0005120934340518414
				alpha = 0.0019342813113834097
			Iteration 17:
				X = [0.9998643468327953, 0.9997409766038395]
				Current Gradient = [0.0214268817110184, -0.01092262764715069]
				Next Gradient = [-0.00517645503222371, 0.0024529072934859467]
				|| Gradient || = 0.024050261008485445
				beta = 0.05672819307081807
				||X optimum - X|| = 0.0002923951120165201
				alpha = 0.0019342813113834097
			Iteration 18:
				X = [0.9998755915888219, 0.9997466840449504]
				Current Gradient = [-0.00517645503222371, 0.0024529072934859467]
				Next Gradient = [0.00155680297394846, -0.0009029220292593303]
				|| Gradient || = 0.00572821445924214
				beta = 0.09870962362626191
				||X optimum - X|| = 0.0002822169836394802
				alpha = 0.0015474250491067279
			Iteration 19:
				X = [0.9998739677509678, 0.9997491347743621]
				Current Gradient = [0.00155680297394846, -0.0009029220292593303]
				Next Gradient = [-0.0007253597595878368, 0.00023667765974414432]
				|| Gradient || = 0.0017996954438505857
				beta = 0.17974078609928318
				||X optimum - X|| = 0.0002807445266260012
				alpha = 0.0019342813113834097
			Iteration 20:
				X = [0.9998750789309024, 0.999749117469219]
				Current Gradient = [-0.0007253597595878368, 0.00023667765974414432]
				Next Gradient = [0.00017250463894785394, -0.00021119957188172567]
				|| Gradient || = 0.0007629961306922135
				beta = 0.12773587024424457
				||X optimum - X|| = 0.00028026294395718513
				alpha = 0.0019342813113834097
			Iteration 21:
				X = [0.9998748392621983, 0.9997496253553407]
				Current Gradient = [0.00017250463894785394, -0.00021119957188172567]
				Next Gradient = [-0.0002227908153152549, -1.3766853235571843e-05]
				|| Gradient || = 0.0002726960022104352
				beta = 0.6700267631412264
				||X optimum - X|| = 0.00027991547469783117
				alpha = 0.002417851639229262
			Iteration 22:
				X = [0.9998762815637271, 0.9997510504633075]
				Current Gradient = [-0.0002227908153152549, -1.3766853235571843e-05]
				Next Gradient = [0.0003636760714532081, -0.00030559407965026757]
				|| Gradient || = 0.00022321575579883646
				beta = 4.528786497181748
				||X optimum - X|| = 0.0002779966246076261
				alpha = 0.009223372036854787
			Iteration 23:
				X = [0.9998802535087028, 0.9997626412353143]
				Current Gradient = [0.0003636760714532081, -0.00030559407965026757]
				Next Gradient = [-0.0010873425180610446, 0.00042397573733030775]
				|| Gradient || = 0.00047502423776575126
				beta = 6.03625566226605
				||X optimum - X|| = 0.0002658541053869537
				alpha = 0.011529215046068483
			Iteration 24:
				X = [0.9999167653897721, 0.9998277179910208]
				Current Gradient = [-0.0010873425180610446, 0.00042397573733030775]
				Next Gradient = [0.002161224028365049, -0.0011639433047940203]
				|| Gradient || = 0.0011670771942884118
				beta = 4.423896684113392
				||X optimum - X|| = 0.00019133502282045104
				alpha = 0.011529215046068483
			Iteration 25:
				X = [0.9999615289592952, 0.9999264519715519]
				Current Gradient = [0.002161224028365049, -0.0011639433047940203]
				Next Gradient = [-0.0014339186513100937, 0.0006785145881122712]
				|| Gradient || = 0.002454720619043494
				beta = 0.41763185039598044
				||X optimum - X|| = 8.300200877992747e-05
				alpha = 0.0037778931862957215
			Iteration 26:
				X = [0.9999738742438381, 0.9999462515744176]
				Current Gradient = [-0.0014339186513100937, 0.0006785145881122712]
				Next Gradient = [0.0005467715628522664, -0.0002995191627472391]
				|| Gradient || = 0.0015863495027439959
				beta = 0.1544486938048426
				||X optimum - X|| = 5.976159626059419e-05
				alpha = 0.0019342813113834097
			Iteration 27:
				X = [0.9999747233468947, 0.999949888951537]
				Current Gradient = [0.0005467715628522664, -0.0002995191627472391]
				Next Gradient = [-0.00022719597651215252, 8.83237676799627e-05]
				|| Gradient || = 0.0006234347365977589
				beta = 0.15287767657682796
				||X optimum - X|| = 5.6125095726083624e-05
				alpha = 0.0019342813113834097
			Iteration 28:
				X = [0.9999752926167286, 0.9999502741822867]
				Current Gradient = [-0.00022719597651215252, 8.83237676799627e-05]
				Next Gradient = [7.524720341492392e-05, -6.233232505882754e-05]
				|| Gradient || = 0.00024376033245894333
				beta = 0.16067999044658038
				||X optimum - X|| = 5.552577541450202e-05
				alpha = 0.0019342813113834097
			Iteration 29:
				X = [0.9999752250179937, 0.9999505022661924]
				Current Gradient = [7.524720341492392e-05, -6.233232505882754e-05]
				Next Gradient = [-7.019561459720279e-05, 1.0323281030308206e-05]
				|| Gradient || = 9.771110668192371e-05
				beta = 0.5272600508771423
				||X optimum - X|| = 5.535183272030376e-05
				alpha = 0.002417851639229262
			Iteration 30:
				X = [0.9999754868939107, 0.9999506883977741]
				Current Gradient = [-7.019561459720279e-05, 1.0323281030308206e-05]
				Next Gradient = [6.536775945738027e-05, -5.7198187921027606e-05]
				|| Gradient || = 7.095064791747677e-05
				beta = 1.4987256676553613
				||X optimum - X|| = 5.50683800763082e-05
				alpha = 0.004722366482869652
			Iteration 31:
				X = [0.9999755706835528, 0.9999512374687587]
				Current Gradient = [6.536775945738027e-05, -5.7198187921027606e-05]
				Next Gradient = [-8.70592442756804e-05, 1.9100972315494113e-05]
				|| Gradient || = 8.68595226669311e-05
				beta = 1.0529628760340908
				||X optimum - X|| = 5.453967322176364e-05
				alpha = 0.004722366482869652
			Iteration 32:
				X = [0.9999759701659846, 0.999951627828416]
				Current Gradient = [-8.70592442756804e-05, 1.9100972315494113e-05]
				Next Gradient = [7.71701171382699e-05, -6.261619722905043e-05]
				|| Gradient || = 8.913001266268206e-05
				beta = 1.2431794150987978
				||X optimum - X|| = 5.401203483079949e-05
				alpha = 0.0037778931862957215
			Iteration 33:
				X = [0.9999763707282429, 0.9999530376807504]
				Current Gradient = [7.71701171382699e-05, -6.261619722905043e-05]
				Next Gradient = [-0.00016552171786585564, 5.9133184439654316e-05]
				|| Gradient || = 9.937814213679808e-05
				beta = 3.1282022320037037
				||X optimum - X|| = 5.2571873783185565e-05
				alpha = 0.00737869762948383
			Iteration 34:
				X = [0.9999788451027003, 0.9999570116580819]
				Current Gradient = [-0.00016552171786585564, 5.9133184439654316e-05]
				Next Gradient = [0.00022928279909822076, -0.0001357989696732146]
				|| Gradient || = 0.00017576738203443234
				beta = 2.2985552348456704
				||X optimum - X|| = 4.791166059140434e-05
				alpha = 0.00737869762948383
			Iteration 35:
				X = [0.9999814023365665, 0.9999634989706797]
				Current Gradient = [0.00022928279909822076, -0.0001357989696732146]
				Next Gradient = [-0.00031477043396386855, 0.00013879033471785854]
				|| Gradient || = 0.0002664806974747359
				beta = 1.6665246187378844
				||X optimum - X|| = 4.096581778294989e-05
				alpha = 0.004722366482869652
			Iteration 36:
				X = [0.9999885875297427, 0.9999761937798408]
				Current Gradient = [-0.00031477043396386855, 0.00013879033471785854]
				Next Gradient = [0.0003697349350070388, -0.00019628197783237307]
				|| Gradient || = 0.0003440104404068245
				beta = 1.4806981896473348
				||X optimum - X|| = 2.6400390066067365e-05
				alpha = 0.005902958103587064
			Iteration 37:
				X = [0.9999929172949639, 0.9999864111623609]
				Current Gradient = [0.0003697349350070388, -0.00019628197783237307]
				Next Gradient = [-0.0002447722841283382, 0.00011530445367723015]
				|| Gradient || = 0.0004186054669810792
				beta = 0.4177844191670228
				||X optimum - X|| = 1.5323877414400855e-05
				alpha = 0.0030223145490365774
			Iteration 38:
				X = [0.9999949562447907, 0.9999895473038758]
				Current Gradient = [-0.0002447722841283382, 0.00011530445367723015]
				Next Gradient = [0.00013599661082159837, -7.304222902281481e-05]
				|| Gradient || = 0.0002705708559974788
				beta = 0.32551160989583544
				||X optimum - X|| = 1.1605960661489151e-05
				alpha = 0.002417851639229262
			Iteration 39:
				X = [0.9999952911270029, 0.9999907447596224]
				Current Gradient = [0.00013599661082159837, -7.304222902281481e-05]
				Next Gradient = [-7.441041715276893e-05, 3.2496688607654623e-05]
				|| Gradient || = 0.00015437048090740217
				beta = 0.2766629066298806
				||X optimum - X|| = 1.0384264988467308e-05
				alpha = 0.002417851639229262
			Iteration 40:
				X = [0.9999955091772712, 0.9999909469351548]
				Current Gradient = [-7.441041715276893e-05, 3.2496688607654623e-05]
				Next Gradient = [1.9594448245290087e-05, -1.4287911032495693e-05]
				|| Gradient || = 8.119695161341932e-05
				beta = 0.08919941059007902
				||X optimum - X|| = 1.0105714812583467e-05
				alpha = 0.0019342813113834097
			Iteration 41:
				X = [0.9999954907260515, 0.9999909926059324]
				Current Gradient = [1.9594448245290087e-05, -1.4287911032495693e-05]
				Next Gradient = [-1.347152612103645e-05, 2.2266991584559357e-06]
				|| Gradient || = 2.4250501102242484e-05
				beta = 0.3170283774366363
				||X optimum - X|| = 1.0073068024768498e-05
				alpha = 0.0019342813113834097
			Iteration 42:
				X = [0.9999955223013031, 0.9999910084994792]
				Current Gradient = [-1.347152612103645e-05, 2.2266991584559357e-06]
				Next Gradient = [5.494208609461038e-06, -7.224635334631829e-06]
				|| Gradient || = 1.365431086404714e-05
				beta = 0.44186651632715007
				||X optimum - X|| = 1.0044743263826418e-05
				alpha = 0.0030223145490365774
			Iteration 43:
				X = [0.9999955189848277, 0.9999910445719125]
				Current Gradient = [5.494208609461038e-06, -7.224635334631829e-06]
				Next Gradient = [-1.1594489545410619e-05, 1.3164354939855075e-06]
				|| Gradient || = 9.076435641962463e-06
				beta = 1.652857573172877
				||X optimum - X|| = 1.0013949730506325e-05
				alpha = 0.0037778931862957215
			Iteration 44:
				X = [0.9999957017139851, 0.9999913051598045]
				Current Gradient = [-1.1594489545410619e-05, 1.3164354939855075e-06]
				Next Gradient = [3.0718315394239154e-05, -1.9657328187993205e-05]
				|| Gradient || = 1.1668984112957777e-05
				beta = 9.767734689893032
				||X optimum - X|| = 9.69925299655084e-06
				alpha = 0.018014398509482003
			Iteration 45:
				X = [0.999996489859876, 0.9999931608195395]
				Current Gradient = [3.0718315394239154e-05, -1.9657328187993205e-05]
				Next Gradient = [-7.945461254604531e-05, 3.621749329434161e-05]
				|| Gradient || = 3.646951401034051e-05
				beta = 5.732779220908866
				||X optimum - X|| = 7.68735800269998e-06
				alpha = 0.011529215046068483
			Iteration 46:
				X = [0.9999992722295147, 0.9999983937300299]
				Current Gradient = [-7.945461254604531e-05, 3.621749329434161e-05]
				Next Gradient = [5.883662682102293e-05, -3.0145905839141564e-05]
				|| Gradient || = 8.731977024344407e-05
				beta = 0.5732028882678326
				||X optimum - X|| = 1.7634492043413154e-06
				alpha = 0.005902958103587064
			Iteration 47:
				X = [0.9999995992678308, 0.9999992266845752]
				Current Gradient = [5.883662682102293e-05, -3.0145905839141564e-05]
				Next Gradient = [-1.2060561099541975e-05, 5.629750609985972e-06]
				|| Gradient || = 6.610994096608092e-05
				beta = 0.04053317497577721
				||X optimum - X|| = 8.709781958789193e-07
				alpha = 0.0015474250491067279
			Iteration 48:
				X = [0.9999996311865464, 0.9999992517352504]
				Current Gradient = [-1.2060561099541975e-05, 5.629750609985972e-06]
				Next Gradient = [3.517962869134804e-06, -2.127595699680361e-06]
				|| Gradient || = 1.3309816902062272e-05
				beta = 0.09541410801815908
				||X optimum - X|| = 8.342202940627581e-07
				alpha = 0.0015474250491067279
			Iteration 49:
				X = [0.9999996281886864, 0.9999992588383538]
				Current Gradient = [3.517962869134804e-06, -2.127595699680361e-06]
				Next Gradient = [-1.7275594154366476e-06, 4.921685725775551e-07]
				|| Gradient || = 4.111292523028439e-06
				beta = 0.1908976929298618
				||X optimum - X|| = 8.291949340715341e-07
				alpha = 0.0019342813113834097
			Iteration 50:
				X = [0.9999996309579877, 0.9999992592423275]
				Current Gradient = [-1.7275594154366476e-06, 4.921685725775551e-07]
				Next Gradient = [3.318292048389773e-07, -5.347568498982453e-07]
				|| Gradient || = 1.7962993730714375e-06
				beta = 0.12274973214664577
				||X optimum - X|| = 8.275952732156662e-07
				alpha = 0.0019342813113834097
	- Starting Point : [-1.2  1. ]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Fletcher-Reevers Method
			------------
			Iteration 0:
				X = [-0.9864801020462848, 1.087150978763799]
				Current Gradient = [-215.59999997755597, -87.9999999980896]
				Next Gradient = [41.01368406939088, 22.80159740397636]
				|| Gradient || = 232.86768773272496
				beta = 0.04060745582162723
				||X optimum - X|| = 1.9883909296024527
				alpha = 0.0009903520314283058
			Iteration 1:
				X = [-1.0363980481576693, 1.0573968712811805]
				Current Gradient = [41.01368406939088, 22.80159740397636]
				Next Gradient = [-11.00590228197973, -3.3448085883236445]
				|| Gradient || = 46.925847090029485
				beta = 0.06008879151098471
				||X optimum - X|| = 2.037206766966287
				alpha = 0.0015474250491067279
			Iteration 2:
				X = [-1.0223667483350565, 1.0607848235141013]
				Current Gradient = [-11.00590228197973, -3.3448085883236445]
				Next Gradient = [2.3148192851429883, 3.110211082457681]
				|| Gradient || = 11.502940038660126
				beta = 0.11360391924616806
				||X optimum - X|| = 2.0232800249943037
				alpha = 0.0015474250491067279
			Iteration 3:
				X = [-1.0254729962944606, 1.0538661768185924]
				Current Gradient = [2.3148192851429883, 3.110211082457681]
				Next Gradient = [-3.119278881413834, 0.4542621376835143]
				|| Gradient || = 3.87708670270765
				beta = 0.66101557832331
				||X optimum - X|| = 2.026189138190982
				alpha = 0.002417851639229262
			Iteration 4:
				X = [-0.09565523899017891, 0.09304761748680757]
				Current Gradient = [-3.119278881413834, 0.4542621376835143]
				Next Gradient = [1.0187910618464358, 16.779538548172823]
				|| Gradient || = 3.152182550197107
				beta = 28.440378589197145
				||X optimum - X|| = 1.4223301399017678
				alpha = 0.40960000000000013
			Iteration 5:
				X = [0.002672259800522117, -0.03615233463543149]
				Current Gradient = [1.0187910618464358, 16.779538548172823]
				Next Gradient = [-1.9560044751676386, -7.2318951216399086]
				|| Gradient || = 16.810438694969147
				beta = 0.19861315655686515
				||X optimum - X|| = 1.4381496034633714
				alpha = 0.0015474250491067279
			Iteration 6:
				X = [0.002672259800522159, -0.03615233463543152]
				Current Gradient = [-1.9560044751676386, -7.2318951216399086]
				Next Gradient = [-1.9560044751676386, -7.2318951216399086]
				|| Gradient || = 7.4917461620956525
				beta = 1.0
				||X optimum - X|| = 1.4381496034633714
				alpha = 2.8793048285076774e-18
			Iteration 7:
				X = [0.05263842299044597, -0.04255698110128516]
				Current Gradient = [-1.9560044751676386, -7.2318951216399086]
				Next Gradient = [-0.9403299128241116, -9.065556935250463]
				|| Gradient || = 7.4917461620956525
				beta = 1.4800298838090407
				||X optimum - X|| = 1.4086940819202212
				alpha = 0.0030223145490365774
			Iteration 8:
				X = [0.2401222791349506, 0.0011927661053348707]
				Current Gradient = [-0.9403299128241116, -9.065556935250463]
				Next Gradient = [3.9037369129468757, -11.29318856635253]
				|| Gradient || = 9.114194582694598
				beta = 1.7187645877894773
				||X optimum - X|| = 1.2550020084236415
				alpha = 0.00737869762948383
			Iteration 9:
				X = [0.3603137132388412, 0.06612441765957311]
				Current Gradient = [3.9037369129468757, -11.29318856635253]
				Next Gradient = [7.901644852315037, -12.740310857684012]
				|| Gradient || = 11.948860610146037
				beta = 1.5741627545886359
				||X optimum - X|| = 1.1319550118100767
				alpha = 0.0030223145490365774
			Iteration 10:
				X = [0.49256941146961497, 0.17869898912760207]
				Current Gradient = [7.901644852315037, -12.740310857684012]
				Next Gradient = [11.580263981292305, -12.785127197600943]
				|| Gradient || = 14.991714782590343
				beta = 1.323959908100712
				||X optimum - X|| = 0.9654124261870237
				alpha = 0.002417851639229262
			Iteration 11:
				X = [0.6764467637515345, 0.4036449391873055]
				Current Gradient = [11.580263981292305, -12.785127197600943]
				Next Gradient = [13.946633124983787, -10.787057000249956]
				|| Gradient || = 17.24998525608794
				beta = 1.0447207079592793
				||X optimum - X|| = 0.6784733268476867
				alpha = 0.0030223145490365774
			Iteration 12:
				X = [0.9107426472670512, 0.8217817696749435]
				Current Gradient = [13.946633124983787, -10.787057000249956]
				Next Gradient = [2.6157894104728365, -1.5340799752548013]
				|| Gradient || = 17.631482474526543
				beta = 0.029580789515779107
				||X optimum - X|| = 0.19932037687373788
				alpha = 0.004722366482869652
			Iteration 13:
				X = [0.9089659469662058, 0.8282086575977985]
				Current Gradient = [2.6157894104728365, -1.5340799752548013]
				Next Gradient = [-0.9054467862137581, 0.39791297073727555]
				|| Gradient || = 3.032450430002047
				beta = 0.10637174979263647
				||X optimum - X|| = 0.19442084285412944
				alpha = 0.0015474250491067279
			Iteration 14:
				X = [0.9108598849627094, 0.8283147494974734]
				Current Gradient = [-0.9054467862137581, 0.39791297073727555]
				Next Gradient = [0.3139413608348185, -0.27019610736919025]
				|| Gradient || = 0.9890240719748872
				beta = 0.17539421308236244
				||X optimum - X|| = 0.19344711253719118
				alpha = 0.002417851639229262
			Iteration 15:
				X = [0.9104330070933166, 0.8289866515038473]
				Current Gradient = [0.3139413608348185, -0.27019610736919025]
				Next Gradient = [-0.214965387061207, 0.019678219774152406]
				|| Gradient || = 0.4142041941848014
				beta = 0.27160154387452806
				||X optimum - X|| = 0.19304872851747154
				alpha = 0.002417851639229262
			Iteration 16:
				X = [0.9110639660388019, 0.8291974493262309]
				Current Gradient = [-0.214965387061207, 0.019678219774152406]
				Next Gradient = [0.12828219124114137, -0.16802017762870824]
				|| Gradient || = 0.21586419334353343
				beta = 0.9590051947340194
				||X optimum - X|| = 0.1925698041059731
				alpha = 0.0037778931862957215
			Iteration 17:
				X = [0.9112992326211676, 0.8308320557538249]
				Current Gradient = [0.12828219124114137, -0.16802017762870824]
				Next Gradient = [-0.31072985316304286, 0.07315287558085776]
				|| Gradient || = 0.21139323707255028
				beta = 2.280398220107766
				||X optimum - X|| = 0.19101209253361615
				alpha = 0.00737869762948383
			Iteration 18:
				X = [0.9141285157477892, 0.8340198363922486]
				Current Gradient = [-0.31072985316304286, 0.07315287558085776]
				Next Gradient = [0.417360539597695, -0.322221382210823]
				|| Gradient || = 0.3192246620367459
				beta = 2.7282087966049002
				||X optimum - X|| = 0.18687783849063963
				alpha = 0.00737869762948383
			Iteration 19:
				X = [0.9213774187008598, 0.8513237509680026]
				Current Gradient = [0.417360539597695, -0.322221382210823]
				Next Gradient = [-1.037124949442459, 0.4774806552421997]
				|| Gradient || = 0.5272726421569134
				beta = 4.68898868279822
				||X optimum - X|| = 0.16818483081528018
				alpha = 0.011529215046068483
			Iteration 20:
				X = [0.9507836654089655, 0.8997287957418858]
				Current Gradient = [-1.037124949442459, 0.4774806552421997]
				Next Gradient = [1.5220003557569854, -0.8521565333491875]
				|| Gradient || = 1.141760017204379
				beta = 2.3340124603884034
				||X optimum - X|| = 0.11169853174482247
				alpha = 0.00737869762948383
			Iteration 21:
				X = [0.9967069980592669, 0.9951414221742657]
				Current Gradient = [1.5220003557569854, -0.8521565333491875]
				Next Gradient = [-0.6909577976749887, 0.34331643879994755]
				|| Gradient || = 1.7443210255724417
				beta = 0.19564777831344723
				||X optimum - X|| = 0.005869381591819451
				alpha = 0.005902958103587064
			Iteration 22:
				X = [0.9994466110932071, 0.9986312269312492]
				Current Gradient = [-0.6909577976749887, 0.34331643879994755]
				Next Gradient = [0.10375575847197649, -0.05246029889094282]
				|| Gradient || = 0.7715496454008314
				beta = 0.022707195431364013
				||X optimum - X|| = 0.00147640746269416
				alpha = 0.0012379400392853823
			Iteration 23:
				X = [0.9993638179942684, 0.9988114599101293]
				Current Gradient = [0.10375575847197649, -0.05246029889094282]
				Next Gradient = [-0.03461881331525921, 0.016683838810096715]
				|| Gradient || = 0.11626409753583511
				beta = 0.1092532015720757
				||X optimum - X|| = 0.0013480931309247327
				alpha = 0.0015474250491067279
			Iteration 24:
				X = [0.9994194737539775, 0.9988038024599812]
				Current Gradient = [-0.03461881331525921, 0.016683838810096715]
				Next Gradient = [0.013023532080141568, -0.0070964117394420895]
				|| Gradient || = 0.03842932100360424
				beta = 0.14895013126031192
				||X optimum - X|| = 0.0013296237351476004
				alpha = 0.0019342813113834097
			Iteration 25:
				X = [0.9994025725119808, 0.998816388338382]
				Current Gradient = [0.013023532080141568, -0.0070964117394420895]
				Next Gradient = [-0.005546810970583624, 0.002177278963451547]
				|| Gradient || = 0.014831434435622471
				beta = 0.1614193844011721
				||X optimum - X|| = 0.0013258416832182141
				alpha = 0.0019342813113834097
			Iteration 26:
				X = [0.9994105734167003, 0.998814208473117]
				Current Gradient = [-0.005546810970583624, 0.002177278963451547]
				Next Gradient = [0.0017337430515308658, -0.0014571567961782484]
				|| Gradient || = 0.005958830055310815
				beta = 0.14445253584481765
				||X optimum - X|| = 0.001324207401553094
				alpha = 0.0019342813113834097
			Iteration 27:
				X = [0.9994083756208927, 0.9988167121372102]
				Current Gradient = [0.0017337430515308658, -0.0014571567961782484]
				Next Gradient = [-0.0010276908521475322, -7.782479620967928e-05]
				|| Gradient || = 0.002264767294310834
				beta = 0.20709101095371457
				||X optimum - X|| = 0.0013229473051409402
				alpha = 0.0019342813113834097
			Iteration 28:
				X = [0.9994113691745129, 0.9988180188195872]
				Current Gradient = [-0.0010276908521475322, -7.782479620967928e-05]
				Next Gradient = [0.0008479522185164678, -0.0010132031374857086]
				|| Gradient || = 0.0010306333909265693
				beta = 1.6433769905243423
				||X optimum - X|| = 0.0013204415017575182
				alpha = 0.0037778931862957215
			Iteration 29:
				X = [0.9994195520064234, 0.9988465105311167]
				Current Gradient = [0.0008479522185164678, -0.0010132031374857086]
				Next Gradient = [-0.003987093532476874, 0.0014139196793790138]
				|| Gradient || = 0.0013212129134616735
				beta = 10.252089351144097
				||X optimum - X|| = 0.001291300827875406
				alpha = 0.018014398509482003
			Iteration 30:
				X = [0.9995192103844589, 0.9990171528733905]
				Current Gradient = [-0.003987093532476874, 0.0014139196793790138]
				Next Gradient = [0.007633908232689306, -0.0042998108364626425]
				|| Gradient || = 0.0042303763067195535
				beta = 4.2894819579824
				||X optimum - X|| = 0.0010941421885187585
				alpha = 0.011529215046068483
			Iteration 31:
				X = [0.9996582572329252, 0.9993372719409331]
				Current Gradient = [0.007633908232689306, -0.0042998108364626425]
				Next Gradient = [-0.008936938397824504, 0.00412813739288578]
				|| Gradient || = 0.008761559686179346
				beta = 1.2624304954897658
				||X optimum - X|| = 0.0007456517948227937
				alpha = 0.004722366482869652
			Iteration 32:
				X = [0.9998324496170492, 0.9996449787372472]
				Current Gradient = [-0.008936938397824504, 0.00412813739288578]
				Next Gradient = [0.007642990670789718, -0.003989713996514307]
				|| Gradient || = 0.009844307302245893
				beta = 0.7670294901882484
				||X optimum - X|| = 0.0003925725765174308
				alpha = 0.0037778931862957215
			Iteration 33:
				X = [0.9998994808447044, 0.9998056781935205]
				Current Gradient = [0.007642990670789718, -0.003989713996514307]
				Next Gradient = [-0.00288332826646449, 0.0013412800022813312]
				|| Gradient || = 0.00862166597403082
				beta = 0.13604451649159788
				||X optimum - X|| = 0.00021878086080551044
				alpha = 0.002417851639229262
			Iteration 34:
				X = [0.9999123533974498, 0.9998205736045421]
				Current Gradient = [-0.00288332826646449, 0.0013412800022813312]
				Next Gradient = [0.0014809109352862046, -0.0008281744569032534]
				|| Gradient || = 0.003180033637670037
				beta = 0.2846909955560965
				||X optimum - X|| = 0.00019968915425130665
				alpha = 0.0019342813113834097
			Iteration 35:
				X = [0.9999133536493379, 0.9998278767442516]
				Current Gradient = [0.0014809109352862046, -0.0008281744569032534]
				Next Gradient = [-0.0006380272245953868, 0.00023238759714996277]
				|| Gradient || = 0.0016967528191570097
				beta = 0.16015544237111276
				||X optimum - X|| = 0.00019270185586161488
				alpha = 0.002417851639229262
			Iteration 36:
				X = [0.9999147159301015, 0.999828362951322]
				Current Gradient = [-0.0006380272245953868, 0.00023238759714996277]
				Next Gradient = [0.0002598684491055429, -0.0002152364507130577]
				|| Gradient || = 0.0006790307317301814
				beta = 0.24693689874648478
				||X optimum - X|| = 0.00019165763500922492
				alpha = 0.0019342813113834097
			Iteration 37:
				X = [0.9999145081034796, 0.9998290334392099]
				Current Gradient = [0.0002598684491055429, -0.0002152364507130577]
				Next Gradient = [-0.0001749524082752121, 1.9846772670322623e-06]
				|| Gradient || = 0.00033742901558116584
				beta = 0.2688629041635679
				||X optimum - X|| = 0.0001911502793067343
				alpha = 0.002417851639229262
			Iteration 38:
				X = [0.999914967018602, 0.9998292527775419]
				Current Gradient = [-0.0001749524082752121, 1.9846772670322623e-06]
				Next Gradient = [0.00010530712750824389, -0.0001376980540297078]
				|| Gradient || = 0.000174963665099788
				beta = 0.9816433522041446
				||X optimum - X|| = 0.00019074910721309096
				alpha = 0.0030223145490365774
			Iteration 39:
				X = [0.9999153705211522, 0.9998311798980482]
				Current Gradient = [0.00010530712750824389, -0.0001376980540297078]
				Next Gradient = [-0.00034192138215833587, 8.633871902112442e-05]
				|| Gradient || = 0.00017335035387216796
				beta = 4.138541677403729
				||X optimum - X|| = 0.00018884484507945343
				alpha = 0.009223372036854787
			Iteration 40:
				X = [0.9999201941013881, 0.9998383590324541]
				Current Gradient = [-0.00034192138215833587, 8.633871902112442e-05]
				Next Gradient = [0.0006545393449717865, -0.0004071078607232262]
				|| Gradient || = 0.0003526536629318848
				beta = 4.777553546687952
				||X optimum - X|| = 0.0001802686435363213
				alpha = 0.009223372036854787
			Iteration 41:
				X = [0.9999467688716572, 0.9998978177923007]
				Current Gradient = [0.0006545393449717865, -0.0004071078607232262]
				Next Gradient = [-0.0018172569576108968, 0.0008554430866582549]
				|| Gradient || = 0.0007708168163569974
				beta = 6.789779641929177
				||X optimum - X|| = 0.0001152161299252358
				alpha = 0.014411518807585602
			Iteration 42:
				X = [1.0000009347077898, 1.0000004166660135]
				Current Gradient = [-0.0018172569576108968, 0.0008554430866582549]
				Next Gradient = [0.0005829705345972444, -0.0002905500879923894]
				|| Gradient || = 0.0020085332271328285
				beta = 0.10516915269459214
				||X optimum - X|| = 1.0233714961627792e-06
				alpha = 0.0037778931862957215
			Iteration 43:
				X = [1.000002365921739, 1.0000052859514155]
				Current Gradient = [0.0005829705345972444, -0.0002905500879923894]
				Next Gradient = [-0.00021690921684925857, 0.00011082046799314272]
				|| Gradient || = 0.0006513631842842994
				beta = 0.1398407274127014
				||X optimum - X|| = 5.791275165419506e-06
				alpha = 0.0015474250491067279
			Iteration 44:
				X = [1.000003035662683, 1.000005922748971]
				Current Gradient = [-0.00021690921684925857, 0.00011082046799314272]
				Next Gradient = [6.550614987723877e-05, -2.9717122049575094e-05]
				|| Gradient || = 0.00024357911339106613
				beta = 0.08720874095908565
				||X optimum - X|| = 6.655389041895257e-06
				alpha = 0.0019342813113834097
			Iteration 45:
				X = [1.0000029810226374, 1.0000060131614406]
				Current Gradient = [6.550614987723877e-05, -2.9717122049575094e-05]
				Next Gradient = [-1.4480527391051017e-05, 1.0221455858652856e-05]
				|| Gradient || = 7.193165516411124e-05
				beta = 0.060717807402653534
				||X optimum - X|| = 6.711527879320224e-06
				alpha = 0.0015474250491067279
			Iteration 46:
				X = [1.0000030001125444, 1.0000060028341506]
				Current Gradient = [-1.4480527391051017e-05, 1.0221455858652856e-05]
				Next Gradient = [4.960597493947314e-06, 5.200122554354886e-07]
				|| Gradient || = 1.7724667370457692e-05
				beta = 0.07918779184111102
				||X optimum - X|| = 6.71078930671689e-06
				alpha = 0.0015474250491067279
			Iteration 47:
				X = [1.0000029904805674, 1.000006000299033]
				Current Gradient = [4.960597493947314e-06, 5.200122554354886e-07]
				Next Gradient = [-1.7502440796484254e-06, 3.865791020311636e-06]
				|| Gradient || = 4.987779089209893e-06
				beta = 0.7238418605136508
				||X optimum - X|| = 6.7042197539362205e-06
				alpha = 0.002417851639229262
			Iteration 48:
				X = [1.0000029700645043, 1.000005916987137]
				Current Gradient = [-1.7502440796484254e-06, 3.865791020311636e-06]
				Next Gradient = [1.520083371513134e-05, -4.630138627678042e-06]
				|| Gradient || = 4.243547401769709e-06
				beta = 14.021979805940031
				||X optimum - X|| = 6.620575499035598e-06
				alpha = 0.018014398509482003
			Iteration 49:
				X = [1.0000002992638246, 1.000000744312185]
				Current Gradient = [1.520083371513134e-05, -4.630138627678042e-06]
				Next Gradient = [-5.771486834673927e-05, 2.9156889246647973e-05]
				|| Gradient || = 1.5890359635533426e-05
				beta = 16.55870010863754
				||X optimum - X|| = 8.022215812700383e-07
				alpha = 0.08589934592000005
			Iteration 50:
				X = [0.9999995918867086, 0.9999991562108927]
				Current Gradient = [-5.771486834673927e-05, 2.9156889246647973e-05]
				Next Gradient = [1.0209245293784626e-05, -5.512538214643864e-06]
				|| Gradient || = 6.466165957368202e-05
				beta = 0.03219626273072064
				||X optimum - X|| = 9.373027878552841e-07
				alpha = 0.0015474250491067279
			Iteration 51:
				X = [0.9999995610283555, 0.9999991221303434]
				Current Gradient = [1.0209245293784626e-05, -5.512538214643864e-06]
				Next Gradient = [-9.069190980062058e-07, 1.4687917549299299e-08]
				|| Gradient || = 1.1602446597014463e-05
				beta = 0.006111556556894655
				||X optimum - X|| = 9.81504579050044e-07
				alpha = 0.0012379400392853823
	- Starting Point : [0.2 0.8]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Fletcher-Reevers Method
			------------
			Iteration 0:
				X = [0.49467566853534556, 0.08220029458736644]
				Current Gradient = [-62.400000000906175, 152.00000000348268]
				Next Gradient = [31.144006354288933, -32.50074449079321]
				|| Gradient || = 164.309951010801
				beta = 0.07505243117072923
				||X optimum - X|| = 1.0477160775829093
				alpha = 0.004722366482869652
			Iteration 1:
				X = [0.36971838211600966, 0.18180810805414738]
				Current Gradient = [31.144006354288933, -32.50074449079321]
				Next Gradient = [-7.9327120435235265, 9.023285195919328]
				|| Gradient || = 45.013859246367836
				beta = 0.07123887598365357
				||X optimum - X|| = 1.0328082541732488
				alpha = 0.004722366482869652
			Iteration 2:
				X = [0.39827773895812063, 0.14629279715012694]
				Current Gradient = [-7.9327120435235265, 9.023285195919328]
				Next Gradient = [0.7612372925625, -2.466472039913681]
				|| Gradient || = 12.014474440954965
				beta = 0.04615917909017738
				||X optimum - X|| = 1.044454722633349
				alpha = 0.004722366482869652
			Iteration 3:
				X = [0.3954320326972052, 0.1588030812698288]
				Current Gradient = [0.7612372925625, -2.466472039913681]
				Next Gradient = [-1.5945380371362727, 0.48731775736943206]
				|| Gradient || = 2.5812722714320238
				beta = 0.41723609628529257
				||X optimum - X|| = 1.0359124881812014
				alpha = 0.005902958103587064
			Iteration 4:
				X = [0.42680852751040876, 0.16774139686979878]
				Current Gradient = [-1.5945380371362727, 0.48731775736943206]
				Next Gradient = [1.3161524125837598, -2.8848244571499926]
				|| Gradient || = 1.6673422409697325
				beta = 3.616676361249664
				||X optimum - X|| = 1.0105458161899536
				alpha = 0.022517998136852502
			Iteration 5:
				X = [0.7466385046047186, 0.5388636292727931]
				Current Gradient = [1.3161524125837598, -2.8848244571499926]
				Next Gradient = [5.049888372118949, -3.721085457222828]
				|| Gradient || = 3.1708783202325503
				beta = 3.9134685572925987
				||X optimum - X|| = 0.5261547298622272
				alpha = 0.08589934592000005
			Iteration 6:
				X = [0.7916009683392439, 0.6362811288390322]
				Current Gradient = [5.049888372118949, -3.721085457222828]
				Next Gradient = [-3.472072484630301, 1.9298071527382166]
				|| Gradient || = 6.272786426367264
				beta = 0.40102427871966434
				||X optimum - X|| = 0.4191915715227938
				alpha = 0.004722366482869652
			Iteration 7:
				X = [0.8136345288615537, 0.6554513854033401]
				Current Gradient = [-3.472072484630301, 1.9298071527382166]
				Next Gradient = [1.7589137898781082, -1.3099522305215494]
				|| Gradient || = 3.972334702072122
				beta = 0.3048113023353625
				||X optimum - X|| = 0.3917216315869379
				alpha = 0.0030223145490365774
			Iteration 8:
				X = [0.8153846382868545, 0.6677043835962375]
				Current Gradient = [1.7589137898781082, -1.3099522305215494]
				Next Gradient = [-1.2995112897498662, 0.5704550484278426]
				|| Gradient || = 2.193114809231781
				beta = 0.41876344502720936
				||X optimum - X|| = 0.38013577635054563
				alpha = 0.0037778931862957215
			Iteration 9:
				X = [0.8210269349860284, 0.6706803730908639]
				Current Gradient = [-1.2995112897498662, 0.5704550484278426]
				Next Gradient = [0.7602448973721698, -0.6809709763543059]
				|| Gradient || = 1.4192070160706551
				beta = 0.5171881549196262
				||X optimum - X|| = 0.3748103182518697
				alpha = 0.0037778931862957215
			Iteration 10:
				X = [0.8210729399876848, 0.674792155218284]
				Current Gradient = [0.7602448973721698, -0.6809709763543059]
				Next Gradient = [-0.5652185336539606, 0.12627648765528576]
				|| Gradient || = 1.0206340062026926
				beta = 0.3219926530171469
				||X optimum - X|| = 0.37118059635737877
				alpha = 0.0037778931862957215
			Iteration 11:
				X = [0.8232230885072797, 0.6756390597718182]
				Current Gradient = [-0.5652185336539606, 0.12627648765528576]
				Next Gradient = [0.3238579111969342, -0.41143873593871283]
				|| Gradient || = 0.5791526069357618
				beta = 0.81738604029241
				||X optimum - X|| = 0.36940505679080143
				alpha = 0.0037778931862957215
			Iteration 12:
				X = [0.8245268013696656, 0.6811239707986735]
				Current Gradient = [0.3238579111969342, -0.41143873593871283]
				Next Gradient = [-0.7729473344205567, 0.2559049243639616]
				|| Gradient || = 0.5236084224644282
				beta = 2.418007498669443
				||X optimum - X|| = 0.36396808299185524
				alpha = 0.009223372036854787
			Iteration 13:
				X = [0.8327520560157593, 0.6898457705338725]
				Current Gradient = [-0.7729473344205567, 0.2559049243639616]
				Next Gradient = [0.8747321356347704, -0.7260432529406641]
				|| Gradient || = 0.8142081503531937
				beta = 1.9493544398742326
				||X optimum - X|| = 0.35237412053481304
				alpha = 0.00737869762948383
			Iteration 14:
				X = [0.8447264969255309, 0.7177946863674728]
				Current Gradient = [0.8747321356347704, -0.7260432529406641]
				Next Gradient = [-1.7404431729289849, 0.8463663519042014]
				|| Gradient || = 1.1367915878703656
				beta = 2.898315097319145
				||X optimum - X|| = 0.32210200216616197
				alpha = 0.009223372036854787
			Iteration 15:
				X = [0.885333263136471, 0.7763534167443831]
				Current Gradient = [-1.7404431729289849, 0.8463663519042014]
				Next Gradient = [2.413056998450819, -1.4923140143410785]
				|| Gradient || = 1.935323859159169
				beta = 2.1492168022024547
				||X optimum - X|| = 0.2513289771292626
				alpha = 0.00737869762948383
			Iteration 16:
				X = [0.9938762729323787, 0.9902076997471374]
				Current Gradient = [2.413056998450819, -1.4923140143410785]
				Next Gradient = [-0.9733869725257792, 0.4835307698501787]
				|| Gradient || = 2.8372249109246273
				beta = 0.14674620132861782
				||X optimum - X|| = 0.011549423251441211
				alpha = 0.011529215046068483
			Iteration 17:
				X = [0.9967915530767288, 0.9929787668451481]
				Current Gradient = [-0.9733869725257792, 0.4835307698501787]
				Next Gradient = [0.23864767503854337, -0.12292668799734409]
				|| Gradient || = 1.0868689910356302
				beta = 0.06100452642904952
				||X optimum - X|| = 0.007719575550134869
				alpha = 0.0012379400392853823
			Iteration 18:
				X = [0.9966445702922307, 0.9933802962263805]
				Current Gradient = [0.23864767503854337, -0.12292668799734409]
				Next Gradient = [-0.0385623172268146, 0.015979346679488745]
				|| Gradient || = 0.2684467981245047
				beta = 0.02417850084029212
				||X optimum - X|| = 0.0074215487988864666
				alpha = 0.0015474250491067279
			Iteration 19:
				X = [0.9967006887644806, 0.9933652777635418]
				Current Gradient = [-0.0385623172268146, 0.015979346679488745]
				Next Gradient = [0.012133458401421078, -0.009397044009910434]
				|| Gradient || = 0.04174196725364977
				beta = 0.13517352688432302
				||X optimum - X|| = 0.007409790400799325
				alpha = 0.0015474250491067279
			Iteration 20:
				X = [0.996686701407424, 0.9933809166669145]
				Current Gradient = [0.012133458401421078, -0.009397044009910434]
				Next Gradient = [-0.005245549620926314, -0.0006928190994214949]
				|| Gradient || = 0.015346831884894331
				beta = 0.11886534144637916
				||X optimum - X|| = 0.00740204105189211
				alpha = 0.0019342813113834097
			Iteration 21:
				X = [0.996699957277154, 0.9933859151522667]
				Current Gradient = [-0.005245549620926314, -0.0006928190994214949]
				Next Gradient = [0.0033229337502438732, -0.004977936802928325]
				|| Gradient || = 0.005291104717365118
				beta = 1.2795404107367692
				||X optimum - X|| = 0.007391643954197471
				alpha = 0.0030223145490365774
			Iteration 22:
				X = [0.9967643905498976, 0.9935855968107912]
				Current Gradient = [0.0033229337502438732, -0.004977936802928325]
				Next Gradient = [-0.024949851770851714, 0.009269308496740044]
				|| Gradient || = 0.005985126859345429
				beta = 19.77612236967404
				||X optimum - X|| = 0.007184270094263172
				alpha = 0.028147497671065627
			Iteration 23:
				X = [0.998740906730968, 0.9972736178854252]
				Current Gradient = [-0.024949851770851714, 0.009269308496740044]
				Next Gradient = [0.08128851732791878, -0.041956178475406815]
				|| Gradient || = 0.026616070021609307
				beta = 11.812485330319541
				||X optimum - X|| = 0.003003077637157378
				alpha = 0.028147497671065627
			Iteration 24:
				X = [1.0005499040099661, 1.0011172404924622]
				Current Gradient = [0.08128851732791878, -0.041956178475406815]
				Next Gradient = [-0.005755990782714089, 0.0034260156216727065]
				|| Gradient || = 0.09147755988017794
				beta = 0.0053618834877079274
				||X optimum - X|| = 0.0012452392292945204
				alpha = 0.002417851639229262
			Iteration 25:
				X = [1.0005619957933332, 1.0011235511275227]
				Current Gradient = [-0.005755990782714089, 0.0034260156216727065]
				Next Gradient = [0.0014266813675084956, -0.000151259683033074]
				|| Gradient || = 0.006698433617692644
				beta = 0.04587351228985569
				||X optimum - X|| = 0.0012562668537702212
				alpha = 0.0012379400392853823
			Iteration 26:
				X = [1.000560481476564, 1.0011241470542889]
				Current Gradient = [0.0014266813675084956, -0.000151259683033074]
				Next Gradient = [-2.766474089805542e-05, 0.0005739923349928352]
				|| Gradient || = 0.0014346773909514213
				beta = 0.16043952013159984
				||X optimum - X|| = 0.0012561234355101345
				alpha = 0.0015474250491067279
			Iteration 27:
				X = [1.0005568408212466, 1.0011097297458633]
				Current Gradient = [-2.766474089805542e-05, 0.0005739923349928352]
				Next Gradient = [0.0028194186696672142, -0.0008523936659808289]
				|| Gradient || = 0.0005746586278126203
				beta = 26.271477170504255
				||X optimum - X|| = 0.0012416005030042826
				alpha = 0.028147497671065627
			Iteration 28:
				X = [0.9998892498273826, 0.9997563848650522]
				Current Gradient = [0.0028194186696672142, -0.0008523936659808289]
				Next Gradient = [0.008628341950228834, -0.00442541106286345]
				|| Gradient || = 0.002945453546853571
				beta = 10.838616454321466
				||X optimum - X|| = 0.0002676078001673293
				alpha = 0.10737418240000006
			Iteration 29:
				X = [0.9998139665997673, 0.9996254755977674]
				Current Gradient = [0.008628341950228834, -0.00442541106286345]
				Next Gradient = [0.0006246322230108239, -0.0004984420386576879]
				|| Gradient || = 0.009697038098584172
				beta = 0.0067913705869484114
				||X optimum - X|| = 0.00041818291915123404
				alpha = 0.0009903520314283058
			Iteration 30:
				X = [0.9998128367176786, 0.9996250801775055]
				Current Gradient = [0.0006246322230108239, -0.0004984420386576879]
				Next Gradient = [-0.00012305802330317585, -0.00012565758920419186]
				|| Gradient || = 0.0007991307026542502
				beta = 0.048438190194525305
				||X optimum - X|| = 0.000419040532107113
				alpha = 0.0009903520314283058
			Iteration 31:
				X = [0.9998242108996862, 0.9996429173034065]
				Current Gradient = [-0.00012305802330317585, -0.00012565758920419186]
				Next Gradient = [0.0018621920837790548, -0.0011070795547725998]
				|| Gradient || = 0.0001758781021727674
				beta = 151.72690296531908
				||X optimum - X|| = 0.00039800736173546924
				alpha = 0.1677721600000001
			Iteration 32:
				X = [1.0000139069110452, 1.0000310896023743]
				Current Gradient = [0.0018621920837790548, -0.0011070795547725998]
				Next Gradient = [-0.001282438751845787, 0.0006551173762930424]
				|| Gradient || = 0.002166422049713508
				beta = 0.4418619292896622
				||X optimum - X|| = 3.405826699365417e-05
				alpha = 0.022517998136852502
			Iteration 33:
				X = [1.0000201025160753, 1.0000397079389491]
				Current Gradient = [-0.001282438751845787, 0.0006551173762930424]
				Next Gradient = [0.00023920835758384687, -9.949946252766035e-05]
				|| Gradient || = 0.0014400791398242179
				beta = 0.032365646370196566
				||X optimum - X|| = 4.4506533993864233e-05
				alpha = 0.0012379400392853823
			Iteration 34:
				X = [1.0000199830150227, 1.0000402105794521]
				Current Gradient = [0.00023920835758384687, -9.949946252766035e-05]
				Next Gradient = [-5.7695555818747834e-05, 4.883001718123587e-05]
				|| Gradient || = 0.0002590767866507048
				beta = 0.08511741999400468
				||X optimum - X|| = 4.490224481330983e-05
				alpha = 0.0015474250491067279
			Iteration 35:
				X = [1.0000200621229498, 1.0000401778021233]
				Current Gradient = [-5.7695555818747834e-05, 4.883001718123587e-05]
				Next Gradient = [1.8862725358995006e-05, 1.0630746992937058e-05]
				|| Gradient || = 7.558536722907442e-05
				beta = 0.08205899987213222
				||X optimum - X|| = 4.490817921839024e-05
				alpha = 0.0015474250491067279
			Iteration 36:
				X = [1.000019926837475, 1.0000400637190774]
				Current Gradient = [1.8862725358995006e-05, 1.0630746992937058e-05]
				Next Gradient = [-4.400641548805155e-05, 4.192940971858084e-05]
				|| Gradient || = 2.1652140531520518e-05
				beta = 7.880802681828345
				||X optimum - X|| = 4.4745730947948354e-05
				alpha = 0.009223372036854787
			Iteration 37:
				X = [1.0000011608185793, 1.000003519184038]
				Current Gradient = [-4.400641548805155e-05, 4.192940971858084e-05]
				Next Gradient = [-0.0004766967316630646, 0.00023950910635034696]
				|| Gradient || = 6.07835504347652e-05
				beta = 77.03169611566904
				||X optimum - X|| = 3.705692386987893e-06
				alpha = 0.2621440000000001
			Iteration 38:
				X = [0.9999949243902035, 0.9999899288111848]
				Current Gradient = [-0.0004766967316630646, 0.00023950910635034696]
				Next Gradient = [-4.2152663509207394e-05, 1.600100316735901e-05]
				|| Gradient || = 0.00053348325747205
				beta = 0.00714282436694754
				||X optimum - X|| = 1.1277883620526231e-05
				alpha = 0.0012379400392853823
			Iteration 39:
				X = [0.9999949304996094, 0.9999898353056417]
				Current Gradient = [-4.2152663509207394e-05, 1.600100316735901e-05]
				Next Gradient = [1.4905787097094597e-07, -5.143855408432903e-06]
				|| Gradient || = 4.508746104275886e-05
				beta = 0.013026581929019992
				||X optimum - X|| = 1.1358734331270254e-05
				alpha = 0.0009903520314283058
			Iteration 40:
				X = [0.9999949299927084, 0.999989864185359]
				Current Gradient = [1.4905787097094597e-07, -5.143855408432903e-06]
				Next Gradient = [-1.1809300955812465e-05, 8.348474134463237e-07]
				|| Gradient || = 5.146014643562805e-06
				beta = 5.29262826693942
				||X optimum - X|| = 1.133312456359605e-05
				alpha = 0.00737869762948383
			Iteration 41:
				X = [0.9999957165358139, 0.999991230337985]
				Current Gradient = [-1.1809300955812465e-05, 8.348474134463237e-07]
				Next Gradient = [7.253392057231856e-05, -4.0550398173800114e-05]
				|| Gradient || = 1.1838773554245018e-05
				beta = 49.26993400577672
				||X optimum - X|| = 9.75986871282027e-06
				alpha = 0.06871947673600004
			Iteration 42:
				X = [1.0000002488582802, 1.000000638578183]
				Current Gradient = [7.253392057231856e-05, -4.0550398173800114e-05]
				Next Gradient = [-5.5846521768279096e-05, 2.817231211573854e-05]
				|| Gradient || = 8.309936477281369e-05
				beta = 0.566578908997793
				||X optimum - X|| = 6.853557758045266e-07
				alpha = 0.009223372036854787
			Iteration 43:
				X = [1.000000662653088, 1.0000013191515538]
				Current Gradient = [-5.5846521768279096e-05, 2.817231211573854e-05]
				Next Gradient = [3.787732271796431e-06, -1.2310122697964804e-06]
				|| Gradient || = 6.255008524024135e-05
				beta = 0.004054250122128301
				||X optimum - X|| = 1.4762350547222536e-06
				alpha = 0.0012379400392853823
			Iteration 44:
				X = [1.0000006596417301, 1.0000013234346878]
				Current Gradient = [3.787732271796431e-06, -1.2310122697964804e-06]
				Next Gradient = [-3.4063466089248094e-07, 8.301584752273589e-07]
				|| Gradient || = 3.982751181180872e-06
				beta = 0.05076153598938675
				||X optimum - X|| = 1.4787178855686127e-06
				alpha = 0.0012379400392853823
Running: Quadratic
===================
	- Starting Point : [-0.2  1.2]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Fletcher-Reevers Method
			------------
			Iteration 0:
				X = [0.060221282671646836, 1.1528518930343448]
				Current Gradient = [-86.09999999986684, 15.600000000226544]
				Next Gradient = [24.347259079460226, 2.5975385103960136]
				|| Gradient || = 87.50182855223163
				beta = 0.07830350026142134
				||X optimum - X|| = 4.104987677056572
				alpha = 0.0030223145490365774
			Iteration 1:
				X = [-0.02291752681164823, 1.1348168301628394]
				Current Gradient = [24.347259079460226, 2.5975385103960136]
				Next Gradient = [-8.595845925246648, 1.2115057650974315]
				|| Gradient || = 24.485428952651592
				beta = 0.1256910083054319
				||X optimum - X|| = 4.179913236605418
				alpha = 0.004722366482869652
			Iteration 2:
				X = [0.007225407084379649, 1.1268288107067685]
				Current Gradient = [-8.595845925246648, 1.2115057650974315]
				Next Gradient = [3.0095937108010062, 1.0467296387775549]
				|| Gradient || = 8.680801425527697
				beta = 0.13473718105496768
				||X optimum - X|| = 4.148733797012207
				alpha = 0.004722366482869652
			Iteration 3:
				X = [-0.005463381071951528, 1.119304655473628]
				Current Gradient = [3.0095937108010062, 1.0467296387775549]
				Next Gradient = [-1.8175498546386948, 0.9535333620608322]
				|| Gradient || = 3.186423895339156
				beta = 0.4149108655793746
				||X optimum - X|| = 4.158915701102066
				alpha = 0.005902958103587064
			Iteration 4:
				X = [0.005208893471049034, 1.102213793662781]
				Current Gradient = [-1.8175498546386948, 0.9535333620608322]
				Next Gradient = [2.1054787566650304, 0.8370999044424177]
				|| Gradient || = 2.052489548489876
				beta = 1.2186390628394566
				||X optimum - X|| = 4.144059752433995
				alpha = 0.011529215046068483
			Iteration 5:
				X = [-0.008877189920291512, 1.0641154228707195]
				Current Gradient = [2.1054787566650304, 0.8370999044424177]
				Next Gradient = [-2.8918112690030227, 0.5203261285169347]
				|| Gradient || = 2.265783980167842
				beta = 1.6816686077787142
				||X optimum - X|| = 4.147702732483916
				alpha = 0.014411518807585602
			Iteration 6:
				X = [0.005512624676072109, 1.006861403706141]
				Current Gradient = [-2.8918112690030227, 0.5203261285169347]
				Next Gradient = [1.6930389870311453, 0.07509574166415095]
				|| Gradient || = 2.938249767387091
				beta = 0.3326672872825624
				||X optimum - X|| = 4.1194294845154635
				alpha = 0.011529215046068483
			Iteration 7:
				X = [-0.002030358991941316, 0.9966662885976896]
				Current Gradient = [1.6930389870311453, 0.07509574166415095]
				Next Gradient = [-0.6127358907277356, -0.02949782473751078]
				|| Gradient || = 1.6947036266036417
				beta = 0.1310281068357239
				||X optimum - X|| = 4.124268503034236
				alpha = 0.005902958103587064
			Iteration 8:
				X = [0.0005982524296760253, 0.9955045663896294]
				Current Gradient = [-0.6127358907277356, -0.02949782473751078]
				Next Gradient = [0.16917397246095367, -0.03466007491648507]
				|| Gradient || = 0.6134455097644422
				beta = 0.0792451073500551
				||X optimum - X|| = 4.121437089192454
				alpha = 0.005902958103587064
			Iteration 9:
				X = [-0.00019206984769072892, 0.9956171025586399]
				Current Gradient = [0.16917397246095367, -0.03466007491648507]
				Next Gradient = [-0.06597879753308944, -0.035436300485976346]
				|| Gradient || = 0.17268802434284744
				beta = 0.18808571803747703
				||X optimum - X|| = 4.122231193247124
				alpha = 0.005902958103587064
			Iteration 10:
				X = [0.0001842141281582405, 0.9959770173137468]
				Current Gradient = [-0.06597879753308944, -0.035436300485976346]
				Next Gradient = [0.0468666204070137, -0.031805293736913466]
				|| Gradient || = 0.07489281084353035
				beta = 0.571954906876951
				||X optimum - X|| = 4.1219530006935745
				alpha = 0.009223372036854787
			Iteration 11:
				X = [-0.0002397132346502591, 0.9969520311167112]
				Current Gradient = [0.0468666204070137, -0.031805293736913466]
				Next Gradient = [-0.07769204977939692, -0.024845991348980783]
				|| Gradient || = 0.05663971061072311
				beta = 2.0739588674267933
				||X optimum - X|| = 4.12260004313872
				alpha = 0.018014398509482003
			Iteration 12:
				X = [0.0002806543978527672, 0.9994217552287563]
				Current Gradient = [-0.07769204977939692, -0.024845991348980783]
				Next Gradient = [0.08308281300197647, -0.004041032971012379]
				|| Gradient || = 0.08156824066410846
				beta = 1.039935485906159
				||X optimum - X|| = 4.122693135367777
				alpha = 0.018014398509482003
			Iteration 13:
				X = [-3.245633853516658e-05, 1.0002872074320817]
				Current Gradient = [0.08308281300197647, -0.004041032971012379]
				Next Gradient = [-0.009184308689741938, 0.002233062894337386]
				|| Gradient || = 0.08318103007173089
				beta = 0.01291183905967712
				||X optimum - X|| = 4.123206779815193
				alpha = 0.005902958103587064
			Iteration 14:
				X = [7.681064640720846e-06, 1.0002856017543658]
				Current Gradient = [-0.009184308689741938, 0.002233062894337386]
				Next Gradient = [0.0028806798563748323, 0.0023001938686987525]
				|| Gradient || = 0.00945188319852376
				beta = 0.1521098935077572
				||X optimum - X|| = 4.123167451925639
				alpha = 0.004722366482869652
			Iteration 15:
				X = [-1.5202022147792695e-05, 1.0002517071074664]
				Current Gradient = [0.0028806798563748323, 0.0023001938686987525]
				Next Gradient = [-0.004067089603567102, 0.0019833221631663147]
				|| Gradient || = 0.0036863543330129104
				beta = 1.5066944476652442
				||X optimum - X|| = 4.123181428700377
				alpha = 0.014411518807585602
			Iteration 16:
				X = [2.2509100515094658e-05, 1.00012725154349]
				Current Gradient = [-0.004067089603567102, 0.0019833221631663147]
				Next Gradient = [0.007020206491819635, 0.0010631825660865838]
				|| Gradient || = 0.004524907142290361
				beta = 2.4622313361231543
				||X optimum - X|| = 4.1231146536304895
				alpha = 0.022517998136852502
			Iteration 17:
				X = [-4.208078881889808e-06, 0.9999919282507689]
				Current Gradient = [0.007020206491819635, 0.0010631825660865838]
				Next Gradient = [-0.0012806508226164523, -7.298483927916684e-05]
				|| Gradient || = 0.007100257485233686
				beta = 0.032637849248497074
				||X optimum - X|| = 4.123107750376583
				alpha = 0.009223372036854787
			Iteration 18:
				X = [1.3931641070596133e-06, 0.9999900115813791]
				Current Gradient = [-0.0012806508226164523, -7.298483927916684e-05]
				Next Gradient = [0.000398660627669113, -7.712043848880005e-05]
				|| Gradient || = 0.001282728855305283
				beta = 0.10020574197039453
				||X optimum - X|| = 4.123101851513204
				alpha = 0.004722366482869652
			Iteration 19:
				X = [-2.5851698854069855e-07, 0.9999902267434986]
				Current Gradient = [0.000398660627669113, -7.712043848880005e-05]
				Next Gradient = [-9.722935213338052e-05, -7.870306594193409e-05]
				|| Gradient || = 0.00040605154609511823
				beta = 0.09490491741318667
				||X optimum - X|| = 4.12310350606415
				alpha = 0.005902958103587064
			Iteration 20:
				X = [5.56303585895609e-07, 0.9999911740107721]
				Current Gradient = [-9.722935213338052e-05, -7.870306594193409e-05]
				Next Gradient = [0.00014951430315868878, -6.94952138122819e-05]
				|| Gradient || = 0.00012509084500848705
				beta = 1.737257086137418
				||X optimum - X|| = 4.123102945315708
				alpha = 0.011529215046068483
			Iteration 21:
				X = [-6.194995479146726e-07, 1.0000005080868835]
				Current Gradient = [0.00014951430315868878, -6.94952138122819e-05]
				Next Gradient = [-0.00018514362923702793, 2.825811105477933e-06]
				|| Gradient || = 0.00016487604917586748
				beta = 1.2612569125028863
				||X optimum - X|| = 4.123106349849684
				alpha = 0.043980465111040035
			Iteration 22:
				X = [9.558170077934844e-08, 1.0000017588229708]
				Current Gradient = [-0.00018514362923702793, 2.825811105477933e-06]
				Next Gradient = [3.224004789319629e-05, 1.4261749907710576e-05]
				|| Gradient || = 0.00018516519288317096
				beta = 0.036248404890109685
				||X optimum - X|| = 4.123105959467382
				alpha = 0.004722366482869652
			Iteration 23:
				X = [-6.232925790184705e-08, 1.0000017313079437]
				Current Gradient = [3.224004789319629e-05, 1.4261749907710576e-05]
				Next Gradient = [-1.526739085856296e-05, 1.3725806197358448e-05]
				|| Gradient || = 3.525362674372203e-05
				beta = 0.339141299890227
				||X optimum - X|| = 4.1231061059901135
				alpha = 0.005902958103587064
			Iteration 24:
				X = [1.1204360965917248e-07, 1.000001300464872]
				Current Gradient = [-1.526739085856296e-05, 1.3725806197358448e-05]
				Next Gradient = [3.627012187244312e-05, 1.0627809961245858e-05]
				|| Gradient || = 2.0530245478210325e-05
				beta = 3.3890928988864344
				||X optimum - X|| = 4.123105832328656
				alpha = 0.028147497671065627
			Iteration 25:
				X = [-1.0808942008769117e-07, 1.000000399696385]
				Current Gradient = [3.627012187244312e-05, 1.0627809961245858e-05]
				Next Gradient = [-3.168150388781822e-05, 2.9813957451162308e-06]
				|| Gradient || = 3.779513308898691e-05
				beta = 0.7088737817589021
				||X optimum - X|| = 4.123105827420429
				alpha = 0.014411518807585602
			Iteration 26:
				X = [4.578299250504332e-08, 1.0000000507696114]
				Current Gradient = [-3.168150388781822e-05, 2.9813957451162308e-06]
				Next Gradient = [1.3859329865223062e-05, 4.977235046143996e-07]
				|| Gradient || = 3.182147716846027e-05
				beta = 0.18993436270595665
				||X optimum - X|| = 4.123105593515073
				alpha = 0.00737869762948383
			Iteration 27:
				X = [-1.2647524134098136e-08, 0.9999999948130229]
				Current Gradient = [1.3859329865223062e-05, 4.977235046143996e-07]
				Next Gradient = [-3.8109549169690315e-06, -6.679081684910364e-08]
				|| Gradient || = 1.3868264238905659e-05
				beta = 0.07553648721664374
				||X optimum - X|| = 4.123105636629535
				alpha = 0.005902958103587064
			Iteration 28:
				X = [1.8182928549841966e-09, 0.9999999917470224]
				Current Gradient = [-3.8109549169690315e-06, -6.679081684910364e-08]
				Next Gradient = [5.298910387558986e-07, -6.23872343842442e-08]
				|| Gradient || = 3.811540160143378e-06
				beta = 0.019595253765840474
				||X optimum - X|| = 8.450906977604731e-09
				alpha = 0.004722366482869652
	- Starting Point : [3.8 0.1]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Fletcher-Reevers Method
			------------
			Iteration 0:
				X = [3.7970144293060404, -0.012568995892813503]
				Current Gradient = [11.500000001163357, 433.5999999991458]
				Next Gradient = [0.05332453489881317, -54.86988849992547]
				|| Gradient || = 433.7524754964356
				beta = 0.016002381974218736
				||X optimum - X|| = 0.20337433851817696
				alpha = 0.0002596148429267419
			Iteration 1:
				X = [3.7969374042017807, 0.002985585874167659]
				Current Gradient = [0.05332453489881317, -54.86988849992547]
				Next Gradient = [-0.08540667166719029, 12.530478397786844]
				|| Gradient || = 54.869914411271644
				beta = 0.052153914913952715
				||X optimum - X|| = 0.20308454282717583
				alpha = 0.00032451855365842736
			Iteration 2:
				X = [3.796961103090609, -0.0002695545181330399]
				Current Gradient = [-0.08540667166719029, 12.530478397786844]
				Next Gradient = [-0.1019757917587738, -1.5740774909856967]
				|| Gradient || = 12.530769456700096
				beta = 0.01584585471364815
				||X optimum - X|| = 0.2030390758396535
				alpha = 0.00032451855365842736
			Iteration 3:
				X = [3.796994571656208, 0.00018968235085900005]
				Current Gradient = [-0.1019757917587738, -1.5740774909856967]
				Next Gradient = [-0.10108236541458288, 0.415911285141235]
				|| Gradient || = 1.5773772566297053
				beta = 0.07362985491812367
				||X optimum - X|| = 0.20300551696060068
				alpha = 0.00032451855365842736
			Iteration 4:
				X = [3.7970386558920257, 6.323562002485747e-05]
				Current Gradient = [-0.10108236541458288, 0.415911285141235]
				Next Gradient = [-0.10134964581291761, -0.13190688929760191]
				|| Gradient || = 0.42801850626537274
				beta = 0.1510436793664633
				||X optimum - X|| = 0.20296135395897216
				alpha = 0.00040564819207303417
			Iteration 5:
				X = [3.7971552841775997, 0.00014724150795576653]
				Current Gradient = [-0.10134964581291761, -0.13190688929760191]
				Next Gradient = [-0.10110317814112507, 0.23238406896951974]
				|| Gradient || = 0.16634656038095183
				beta = 2.320978448824563
				||X optimum - X|| = 0.20284476926243866
				alpha = 0.0009903520314283058
			Iteration 6:
				X = [3.801472191032076, -0.0002621467002650397]
				Current Gradient = [-0.10110317814112507, 0.23238406896951974]
				Next Gradient = [-0.09970982572937714, -1.535652387994746]
				|| Gradient || = 0.2534249556398631
				beta = 36.87348391901278
				||X optimum - X|| = 0.19852798204408623
				alpha = 0.011529215046068483
			Iteration 7:
				X = [3.883560624440811, 0.0010738134173601348]
				Current Gradient = [-0.09970982572937714, -1.535652387994746]
				Next Gradient = [-0.05472864965556934, 4.63430183644635]
				|| Gradient || = 1.5388860601425136
				beta = 9.070187511872094
				||X optimum - X|| = 0.11644432685137185
				alpha = 0.005902958103587064
			Iteration 8:
				X = [3.963541563892062, -0.0005624274748965649]
				Current Gradient = [-0.05472864965556934, 4.63430183644635]
				Next Gradient = [-0.018977943219851932, -2.72807990528293]
				|| Gradient || = 4.634624983359833
				beta = 0.34650219717563735
				||X optimum - X|| = 0.036462774004470726
				alpha = 0.0006338253001141158
			Iteration 9:
				X = [3.9812859478617177, 0.00018135812537586405]
				Current Gradient = [-0.018977943219851932, -2.72807990528293]
				Next Gradient = [-0.008955025551944511, 0.8264153478794304]
				|| Gradient || = 2.728145914707895
				beta = 0.09177249731754714
				||X optimum - X|| = 0.018714930889639603
				alpha = 0.00040564819207303417
			Iteration 10:
				X = [3.982591611077863, -3.2221738434429464e-05]
				Current Gradient = [-0.008955025551944511, 0.8264153478794304]
				Next Gradient = [-0.00876739747287565, -0.18839559716614868]
				|| Gradient || = 0.8264638647232654
				beta = 0.05207548178114574
				||X optimum - X|| = 0.017408418742229384
				alpha = 0.00032451855365842736
			Iteration 11:
				X = [3.982662449302035, 1.779385396687229e-05]
				Current Gradient = [-0.00876739747287565, -0.18839559716614868]
				Next Gradient = [-0.008632809343599038, 0.050138948648994944]
				|| Gradient || = 0.1885994917544508
				beta = 0.07277077398096199
				||X optimum - X|| = 0.01733755982904583
				alpha = 0.00032451855365842736
			Iteration 12:
				X = [3.9826723948760385, 2.0046718076636066e-06]
				Current Gradient = [-0.008632809343599038, 0.050138948648994944]
				Next Gradient = [-0.008659788418016528, -0.02509993441689602]
				|| Gradient || = 0.050876709492551526
				beta = 0.27236434324290454
				||X optimum - X|| = 0.017327605239924097
				alpha = 0.00040564819207303417
			Iteration 13:
				X = [3.9826821161998622, 1.1194254289273196e-05]
				Current Gradient = [-0.008659788418016528, -0.02509993441689602]
				Next Gradient = [-0.008636403670143065, 0.018721948293064002]
				|| Gradient || = 0.026551810544241508
				beta = 0.6029782047891373
				||X optimum - X|| = 0.01731788741811204
				alpha = 0.0006338253001141158
			Iteration 14:
				X = [3.9826998282585113, 1.3109315579457077e-06]
				Current Gradient = [-0.008636403670143065, 0.018721948293064002]
				Next Gradient = [-0.008647461955513637, -0.02835169726312319]
				|| Gradient || = 0.020617924634691597
				beta = 2.066807298451854
				||X optimum - X|| = 0.017300171791157018
				alpha = 0.0009903520314283058
			Iteration 15:
				X = [3.98281011010324, 1.999071042735884e-05]
				Current Gradient = [-0.008647461955513637, -0.02835169726312319]
				Next Gradient = [-0.008554486035392082, 0.06091259660374399]
				|| Gradient || = 0.029641142622575174
				beta = 4.306322704877194
				||X optimum - X|| = 0.0171899015206962
				alpha = 0.002417851639229262
			Iteration 16:
				X = [3.983063853560507, -1.4229560001125867e-05]
				Current Gradient = [-0.008554486035392082, 0.06091259660374399]
				Next Gradient = [-0.00849629039325272, -0.10171085642726778]
				|| Gradient || = 0.06151035405799711
				beta = 2.753328963110408
				||X optimum - X|| = 0.01693615241725
				alpha = 0.0012379400392853823
			Iteration 17:
				X = [3.984795194156594, 6.314417023594492e-05]
				Current Gradient = [-0.00849629039325272, -0.10171085642726778]
				Next Gradient = [-0.007471348146109974, 0.2708877105885455]
				|| Gradient || = 0.1020651030745316
				beta = 7.049434753737663
				||X optimum - X|| = 0.015204936958827157
				alpha = 0.0030223145490365774
			Iteration 18:
				X = [3.991055701462995, -7.676843438866507e-05]
				Current Gradient = [-0.007471348146109974, 0.2708877105885455]
				Next Gradient = [-0.004618629880583552, -0.38534513655970304]
				|| Gradient || = 0.2709907245479519
				beta = 2.0223359256751423
				||X optimum - X|| = 0.00894462798061426
				alpha = 0.0015474250491067279
			Iteration 19:
				X = [3.996244512551791, 5.157662497079485e-05]
				Current Gradient = [-0.004618629880583552, -0.38534513655970304]
				Next Gradient = [-0.0017714012935634567, 0.24000478730663857]
				|| Gradient || = 0.3853728143138667
				beta = 0.38788351031510065
				||X optimum - X|| = 0.0037558415996814453
				alpha = 0.0006338253001141158
			Iteration 20:
				X = [3.997533329843593, -1.3919806509209934e-05]
				Current Gradient = [-0.0017714012935634567, 0.24000478730663857]
				Next Gradient = [-0.0012609423215655519, -0.07177739004648097]
				|| Gradient || = 0.24001132430084973
				beta = 0.08946349639595551
				||X optimum - X|| = 0.002466709431919709
				alpha = 0.00040564819207303417
			Iteration 21:
				X = [3.997625980723684, 4.685656484723384e-06]
				Current Gradient = [-0.0012609423215655519, -0.07177739004648097]
				Next Gradient = [-0.0011776119945379952, 0.01775390853508379]
				|| Gradient || = 0.07178846493290535
				beta = 0.06143065813408808
				||X optimum - X|| = 0.002374023900405717
				alpha = 0.00032451855365842736
			Iteration 22:
				X = [3.9976320544851656, 6.712960174072849e-08]
				Current Gradient = [-0.0011776119945379952, 0.01775390853508379]
				Next Gradient = [-0.0011838384929746715, -0.004413513293887832]
				|| Gradient || = 0.017792921016005235
				beta = 0.0659550287689233
				||X optimum - X|| = 0.002367945515785974
				alpha = 0.00032451855365842736
			Iteration 23:
				X = [3.9976330354510017, 1.476694448300171e-06]
				Current Gradient = [-0.0011838384929746715, -0.004413513293887832]
				Next Gradient = [-0.00118052627056431, 0.0023576316110770026]
				|| Gradient || = 0.004569526580814817
				beta = 0.33294436084288365
				||X optimum - X|| = 0.002366965009636033
				alpha = 0.00040564819207303417
			Iteration 24:
				X = [3.9976350019680686, 2.8757742265737343e-07]
				Current Gradient = [-0.00118052627056431, 0.0023576316110770026]
				Next Gradient = [-0.0011819237621033382, -0.0033489556214099008]
				|| Gradient || = 0.0026366776611944855
				beta = 1.8142005454861567
				||X optimum - X|| = 0.0023649980494156756
				alpha = 0.0009903520314283058
			Iteration 25:
				X = [3.9976442562198935, 2.5519294661310064e-06]
				Current Gradient = [-0.0011819237621033382, -0.0033489556214099008]
				Next Gradient = [-0.001172760221074603, 0.007543765500951034]
				|| Gradient || = 0.0035514007847041824
				beta = 4.6211303804607
				||X optimum - X|| = 0.002355745162332816
				alpha = 0.0019342813113834097
			Iteration 26:
				X = [3.997700548160437, -2.6079437911117653e-06]
				Current Gradient = [-0.001172760221074603, 0.007543765500951034]
				Next Gradient = [-0.001154933650572001, -0.017123509144746557]
				|| Gradient || = 0.007634380424728254
				beta = 5.053696168196408
				||X optimum - X|| = 0.002299453318473795
				alpha = 0.002417851639229262
			Iteration 27:
				X = [3.997884404046802, 7.200486894632749e-06]
				Current Gradient = [-0.001154933650572001, -0.017123509144746557]
				Next Gradient = [-0.0010433348194480872, 0.030352198780898506]
				|| Gradient || = 0.017162413500654346
				beta = 3.1313848657642764
				||X optimum - X|| = 0.002115608206686714
				alpha = 0.0015474250491067279
			Iteration 28:
				X = [3.9984617420692796, -9.053294388157988e-06]
				Current Gradient = [-0.0010433348194480872, 0.030352198780898506]
				Next Gradient = [-0.0007871372375031015, -0.04657133858192806]
				|| Gradient || = 0.03037012542583006
				beta = 2.3521678929173118
				||X optimum - X|| = 0.001538284571710779
				alpha = 0.0015474250491067279
			Iteration 29:
				X = [3.9991576596350837, 8.269730722997388e-06]
				Current Gradient = [-0.0007871372375031015, -0.04657133858192806]
				Next Gradient = [-0.0004045486722151515, 0.03805946811940908]
				|| Gradient || = 0.04657799010630713
				beta = 0.66774863102943
				||X optimum - X|| = 0.0008423809582448374
				alpha = 0.0007922816251426447
			Iteration 30:
				X = [3.9994552714868306, -3.6255594852891135e-06]
				Current Gradient = [-0.0004045486722151515, 0.03805946811940908]
				Next Gradient = [-0.0002795996041245852, -0.018516407484877154]
				|| Gradient || = 0.038061618110118586
				beta = 0.23672164917781421
				||X optimum - X|| = 0.0005447405783869753
				alpha = 0.0005070602400912927
			Iteration 31:
				X = [3.999511745840593, 1.6328895621954733e-06]
				Current Gradient = [-0.0002795996041245852, -0.018516407484877154]
				Next Gradient = [-0.00024085810140933518, 0.006872511376738184]
				|| Gradient || = 0.018518518355544574
				beta = 0.1378959664514969
				||X optimum - X|| = 0.00048825688987117795
				alpha = 0.00040564819207303417
			Iteration 32:
				X = [3.999519631129838, -4.2981333934088957e-07]
				Current Gradient = [-0.00024085810140933518, 0.006872511376738184]
				Next Gradient = [-0.0002410438401326388, -0.0030267847801816183]
				|| Gradient || = 0.00687673070931313
				beta = 0.19495961708088025
				||X optimum - X|| = 0.0004803690624511841
				alpha = 0.00040564819207303417
			Iteration 33:
				X = [3.999521266221808, 3.9585266669881004e-07]
				Current Gradient = [-0.0002410438401326388, -0.0030267847801816183]
				Next Gradient = [-0.0002385749957794564, 0.0009453372730436657]
				|| Gradient || = 0.003036367605940522
				beta = 0.10310512250041731
				||X optimum - X|| = 0.0004787339418523604
				alpha = 0.00040564819207303417
			Iteration 34:
				X = [3.9995215315856814, 9.750870568654836e-08]
				Current Gradient = [-0.0002385749957794564, 0.0009453372730436657]
				Next Gradient = [-0.0002390391783732295, -0.00048822693663306524]
				|| Gradient || = 0.0009749772245631186
				beta = 0.310868193662172
				||X optimum - X|| = 0.0004784684242544599
				alpha = 0.00040564819207303417
			Iteration 35:
				X = [3.999521969718002, 3.5459543888151776e-07]
				Current Gradient = [-0.0002390391783732295, -0.00048822693663306524]
				Next Gradient = [-0.00023830579928702997, 0.0007484275127696307]
				|| Gradient || = 0.0005436039647127821
				beta = 2.0877238328164203
				||X optimum - X|| = 0.0004780304135146753
				alpha = 0.0009903520314283058
			Iteration 36:
				X = [3.999524779058628, -1.446247946540879e-07]
				Current Gradient = [-0.00023830579928702997, 0.0007484275127696307]
				Next Gradient = [-0.0002378996952120748, -0.0016456329562593137]
				|| Gradient || = 0.0007854510779446203
				beta = 4.48136559040519
				||X optimum - X|| = 0.00047522096337904374
				alpha = 0.002417851639229262
			Iteration 37:
				X = [3.999531519481581, 7.471296830474273e-07]
				Current Gradient = [-0.0002378996952120748, -0.0016456329562593137]
				Next Gradient = [-0.00023274533011113393, 0.0026543984907888294]
				|| Gradient || = 0.0016627399350796763
				beta = 2.5680873978098306
				||X optimum - X|| = 0.00046848111417736795
				alpha = 0.0012379400392853823
			Iteration 38:
				X = [3.9995590165440893, -8.089370917032508e-07]
				Current Gradient = [-0.00023274533011113393, 0.0026543984907888294]
				Next Gradient = [-0.00022210881700142219, -0.004770480349001824]
				|| Gradient || = 0.0026645828447602366
				beta = 3.212226691335183
				||X optimum - X|| = 0.0004409841978644656
				alpha = 0.0019342813113834097
			Iteration 39:
				X = [3.999604459830646, 1.3563169284142805e-06]
				Current Gradient = [-0.00022210881700142219, -0.004770480349001824]
				Next Gradient = [-0.00019505524355086784, 0.0057288039699593335]
				|| Gradient || = 0.004775648132641509
				beta = 1.4406764534725445
				||X optimum - X|| = 0.00039554249476898406
				alpha = 0.0009903520314283058
			Iteration 40:
				X = [3.999670122076914, -1.197785238319394e-06]
				Current Gradient = [-0.00019505524355086784, 0.0057288039699593335]
				Next Gradient = [-0.0001673328105576678, -0.006417759016157583]
				|| Gradient || = 0.005732123644362402
				beta = 1.254385006460473
				||X optimum - X|| = 0.00032988009765523926
				alpha = 0.0009903520314283058
			Iteration 41:
				X = [3.9997361472413924, 1.3238253344406546e-06]
				Current Gradient = [-0.0001673328105576678, -0.006417759016157583]
				Next Gradient = [-0.00012927662577545695, 0.005836408410490088]
				|| Gradient || = 0.006419940113346937
				beta = 0.8268798682533233
				||X optimum - X|| = 0.0002638560795933503
				alpha = 0.0007922816251426447
			Iteration 42:
				X = [3.9997799050836327, -7.073827633747621e-07]
				Current Gradient = [-0.00012927662577545695, 0.005836408410490088]
				Next Gradient = [-0.00011146162329056143, -0.003840912510092955]
				|| Gradient || = 0.005837839975539867
				beta = 0.43324148728909717
				||X optimum - X|| = 0.00022009605312479192
				alpha = 0.0006338253001141158
			Iteration 43:
				X = [3.9997951277715122, 5.361883623296538e-07]
				Current Gradient = [-0.00011146162329056143, -0.003840912510092955]
				Next Gradient = [-0.00010136339255340787, 0.0021679855556165925]
				|| Gradient || = 0.0038425294538435395
				beta = 0.3190264480381871
				||X optimum - X|| = 0.0002048729301384087
				alpha = 0.0005070602400912927
			Iteration 44:
				X = [3.999800035608902, -1.6637883489942055e-07]
				Current Gradient = [-0.00010136339255340787, 0.0021679855556165925]
				Next Gradient = [-0.00010031492001620947, -0.0011997983747553942]
				|| Gradient || = 0.002170353866702875
				beta = 0.3077378085493043
				||X optimum - X|| = 0.00019996446031503225
				alpha = 0.0005070602400912927
			Iteration 45:
				X = [3.9998015968017326, 2.2578472743129022e-07]
				Current Gradient = [-0.00010031492001620947, -0.0011997983747553942]
				Next Gradient = [-9.87499685210854e-05, 0.0006886590642427806]
				|| Gradient || = 0.0012039847271637393
				beta = 0.3338919703634164
				||X optimum - X|| = 0.0001984033267399031
				alpha = 0.0005070602400912927
			Iteration 46:
				X = [3.999802310979149, -4.7029479974524516e-08]
				Current Gradient = [-9.87499685210854e-05, 0.0006886590642427806]
				Next Gradient = [-9.893856674531034e-05, -0.0006214734686739553]
				|| Gradient || = 0.0006957031429041107
				beta = 0.8182144001430796
				||X optimum - X|| = 0.00019768902644511278
				alpha = 0.0006338253001141158
			Iteration 47:
				X = [3.999803322010419, 2.1966598054449404e-07]
				Current Gradient = [-9.893856674531034e-05, -0.0006214734686739553]
				Next Gradient = [-9.789960494212015e-05, 0.0006626943695439676]
				|| Gradient || = 0.0006292996998690321
				beta = 1.1331505963642863
				||X optimum - X|| = 0.00019667811225116598
				alpha = 0.0009903520314283058
			Iteration 48:
				X = [3.9998043160950267, -6.36096954228619e-08]
				Current Gradient = [-9.789960494212015e-05, 0.0006626943695439676]
				Next Gradient = [-9.796916703593151e-05, -0.0006971733525368342]
				|| Gradient || = 0.0006698866770380644
				beta = 1.1045140354367653
				||X optimum - X|| = 0.00019568391531185993
				alpha = 0.0007922816251426447
			Iteration 49:
				X = [3.9998057855944924, 2.35734900514947e-07]
				Current Gradient = [-9.796916703593151e-05, -0.0006971733525368342]
				Next Gradient = [-9.663566628443387e-05, 0.0007448747138443226]
				|| Gradient || = 0.0007040231822725464
				beta = 1.1382595339774984
				||X optimum - X|| = 0.0001942145485735118
				alpha = 0.0009903520314283058
			Iteration 50:
				X = [3.9998072002945766, -8.183017608061301e-08]
				Current Gradient = [-9.663566628443387e-05, 0.0007448747138443226]
				Next Gradient = [-9.656350504233482e-05, -0.0007790010339648088]
				|| Gradient || = 0.0007511170290460055
				beta = 1.0921525502307456
				||X optimum - X|| = 0.0001927997227890395
				alpha = 0.0007922816251426447
			Iteration 51:
				X = [3.999809227261821, 2.561181950561074e-07]
				Current Gradient = [-9.656350504233482e-05, -0.0007790010339648088]
				Next Gradient = [-9.487405400055456e-05, 0.0008497535433914136]
				|| Gradient || = 0.0007849631337994812
				beta = 1.1864998069660533
				||X optimum - X|| = 0.00019077291010228495
				alpha = 0.0009903520314283058
			Iteration 52:
				X = [3.999811226425786, -9.634538157819386e-08]
				Current Gradient = [-9.487405400055456e-05, 0.0008497535433914136]
				Next Gradient = [-9.457946674499778e-05, -0.000840732094187993]
				|| Gradient || = 0.0008550334324625928
				beta = 0.979063309821791
				||X optimum - X|| = 0.00018877359880024912
				alpha = 0.0007922816251426447
			Iteration 53:
				X = [3.9998137667278635, 3.049201608738519e-07]
				Current Gradient = [-9.457946674499778e-05, -0.000840732094187993]
				Next Gradient = [-9.25066841930197e-05, 0.0010934533053003344]
				|| Gradient || = 0.000846035300520904
				beta = 1.682367210119103
				||X optimum - X|| = 0.0001862335217595855
				alpha = 0.0009903520314283058
			Iteration 54:
				X = [3.9998192233967407, -2.048644778814042e-07]
				Current Gradient = [-9.25066841930197e-05, 0.0010934533053003344]
				Next Gradient = [-9.079798023693786e-05, -0.001346452734880574]
				|| Gradient || = 0.0010973593839269855
				beta = 1.5123591128460745
				||X optimum - X|| = 0.00018077671934027813
				alpha = 0.0012379400392853823
			Iteration 55:
				X = [3.9998245768977694, 3.684797189208439e-07]
				Current Gradient = [-9.079798023693786e-05, -0.001346452734880574]
				Next Gradient = [-8.69744287639298e-05, 0.0014206491518681823]
				|| Gradient || = 0.0013495107411512087
				beta = 1.1123608917406176
				||X optimum - X|| = 0.0001754234892296869
				alpha = 0.0007922816251426447
			Iteration 56:
				X = [3.999832106814545, -2.4125597704213914e-07]
				Current Gradient = [-8.69744287639298e-05, 0.0014206491518681823]
				Next Gradient = [-8.442903485115736e-05, -0.0014956478979972047]
				|| Gradient || = 0.0014233090191390616
				beta = 1.107750720689908
				||X optimum - X|| = 0.0001678933587928193
				alpha = 0.0009903520314283058
			Iteration 57:
				X = [3.9998388467227053, 4.0337024491758103e-07]
				Current Gradient = [-8.442903485115736e-05, -0.0014956478979972047]
				Next Gradient = [-7.976970292756253e-05, 0.0016169415754769935]
				|| Gradient || = 0.0014980290039613234
				beta = 1.1678953236048961
				||X optimum - X|| = 0.00016115378211627824
				alpha = 0.0007922816251426447
			Iteration 58:
				X = [3.99984876510682, -2.5690119143213367e-07]
				Current Gradient = [-7.976970292756253e-05, 0.0016169415754769935]
				Next Gradient = [-7.613116978853487e-05, -0.001537557470718631]
				|| Gradient || = 0.0016189080468053687
				beta = 0.9042360062497106
				||X optimum - X|| = 0.00015123511137738515
				alpha = 0.0009903520314283058
			Iteration 59:
				X = [3.999854553239108, 3.3553526163560274e-07]
				Current Gradient = [-7.613116978853487e-05, -0.001537557470718631]
				Next Gradient = [-7.205217483697744e-05, 0.001322242892256132]
				|| Gradient || = 0.001539441109875933
				beta = 0.7399187187365683
				||X optimum - X|| = 0.0001454471479195158
				alpha = 0.0006338253001141158
			Iteration 60:
				X = [3.999859963759005, -1.641099592660007e-07]
				Current Gradient = [-7.205217483697744e-05, 0.001322242892256132]
				Next Gradient = [-7.034630810860828e-05, -0.0010690580118945833]
				|| Gradient || = 0.0013242045846547275
				beta = 0.6545891051859468
				||X optimum - X|| = 0.00014003633715619257
				alpha = 0.0007922816251426447
			Iteration 61:
				X = [3.999862841680177, 2.5183620151415127e-07]
				Current Gradient = [-7.034630810860828e-05, -0.0010690580118945833]
				Next Gradient = [-6.807541141478125e-05, 0.0009364289192297187]
				|| Gradient || = 0.001071369980847191
				beta = 0.7679975171211646
				||X optimum - X|| = 0.00013715855102093896
				alpha = 0.0006338253001141158
			Iteration 62:
				X = [3.9998663625930404, -1.7642430165940512e-07]
				Current Gradient = [-6.807541141478125e-05, 0.0009364289192297187]
				Next Gradient = [-6.71715147430191e-05, -0.001115466272708842]
				|| Gradient || = 0.0009389000918143691
				beta = 1.4165964022045354
				||X optimum - X|| = 0.0001336375234147174
				alpha = 0.0009903520314283058
			Iteration 63:
				X = [3.9998714168289817, 3.2160769950559296e-07]
				Current Gradient = [-6.71715147430191e-05, -0.001115466272708842]
				Next Gradient = [-6.364824600526374e-05, 0.0012890242307777538]
				|| Gradient || = 0.0011174869207036958
				beta = 1.3338126365380063
				||X optimum - X|| = 0.00012858357321456808
				alpha = 0.0009903520314283058
			Iteration 64:
				X = [3.9998768603793304, -1.682374116599048e-07]
				Current Gradient = [-6.364824600526374e-05, 0.0012890242307777538]
				Next Gradient = [-6.190625120322632e-05, -0.0010551149973139263]
				|| Gradient || = 0.001290594656254134
				beta = 0.6706753472782092
				||X optimum - X|| = 0.00012313973559526265
				alpha = 0.0007922816251426447
			Iteration 65:
				X = [3.999879820301095, 2.376995361327365e-07]
				Current Gradient = [-6.190625120322632e-05, -0.0010551149973139263]
				Next Gradient = [-5.961438258924989e-05, 0.0009024314129715202]
				|| Gradient || = 0.0010569295347821462
				beta = 0.7321961322593655
				||X optimum - X|| = 0.00012017993397386656
				alpha = 0.0006338253001141158
			Iteration 66:
				X = [3.9998825765865598, -1.0574846142243283e-07]
				Current Gradient = [-5.961438258924989e-05, 0.0009024314129715202]
				Next Gradient = [-5.892319023232565e-05, -0.0007432556282150659]
				|| Gradient || = 0.000904398324705034
				beta = 0.6796383178193396
				||X optimum - X|| = 0.0001174234610573744
				alpha = 0.0007922816251426447
			Iteration 67:
				X = [3.9998841125553417, 1.786094247390342e-07]
				Current Gradient = [-5.892319023232565e-05, -0.0007432556282150659]
				Next Gradient = [-5.7586465207322765e-05, 0.0006269295489389779]
				|| Gradient || = 0.0007455876013055254
				beta = 0.7129991709451177
				||X optimum - X|| = 0.00011588758229747979
				alpha = 0.0006338253001141158
			Iteration 68:
				X = [3.9998855271106253, -6.466166578824426e-08]
				Current Gradient = [-5.7586465207322765e-05, 0.0006269295489389779]
				Next Gradient = [-5.736576300976254e-05, -0.0005398213033016851]
				|| Gradient || = 0.0006295687891786761
				beta = 0.7435165119510991
				||X optimum - X|| = 0.00011447290763725382
				alpha = 0.0007922816251426447
			Iteration 69:
				X = [3.9998864048666656, 1.327898756350337e-07]
				Current Gradient = [-5.736576300976254e-05, -0.0005398213033016851]
				Next Gradient = [-5.6531965764630226e-05, 0.0004112272536113676]
				|| Gradient || = 0.000542860820343504
				beta = 0.5846792075951995
				||X optimum - X|| = 0.00011359521094841959
				alpha = 0.0006338253001141158
			Iteration 70:
				X = [3.999887091163036, -4.871065768686102e-08]
				Current Gradient = [-5.6531965764630226e-05, 0.0004112272536113676]
				Next Gradient = [-5.6551836958180924e-05, -0.00046000531659371347]
				|| Gradient || = 0.0004150948292450309
				beta = 1.2466533222046836
				||X optimum - X|| = 0.00011290884747129427
				alpha = 0.0007922816251426447
			Iteration 71:
				X = [3.9998884980046476, 1.672042125591736e-07]
				Current Gradient = [-5.6551836958180924e-05, -0.00046000531659371347]
				Next Gradient = [-5.541655571099447e-05, 0.0005808691192611161]
				|| Gradient || = 0.0004634684472084667
				beta = 1.585079937844321
				||X optimum - X|| = 0.00011150212071888419
				alpha = 0.0012379400392853823
			Iteration 72:
				X = [3.9998899690822713, -7.397262661428064e-08]
				Current Gradient = [-5.541655571099447e-05, 0.0005808691192611161]
				Next Gradient = [-5.5163397559038296e-05, -0.0005757026902193209]
				|| Gradient || = 0.0005835065795327885
				beta = 0.9823680049776053
				||X optimum - X|| = 0.00011003094259415994
				alpha = 0.0007922816251426447
			Iteration 73:
				X = [3.9998914579268083, 1.4522162604604444e-07]
				Current Gradient = [-5.5163397559038296e-05, -0.0005757026902193209]
				Next Gradient = [-5.398056804476373e-05, 0.0004811036017779398]
				|| Gradient || = 0.0005783395092469647
				beta = 0.7007204265099702
				||X optimum - X|| = 0.00010854217033975901
				alpha = 0.0007922816251426447
			Iteration 74:
				X = [3.999892326752081, -3.6838896566698575e-08]
				Current Gradient = [-5.398056804476373e-05, 0.0004811036017779398]
				Next Gradient = [-5.3910300131778524e-05, -0.00039245839090022125]
				|| Gradient || = 0.00048412248178548973
				beta = 0.6695688193197415
				||X optimum - X|| = 0.00010767325422100553
				alpha = 0.0006338253001141158
			Iteration 75:
				X = [3.9998930966371113, 1.2172111371340923e-07]
				Current Gradient = [-5.3910300131778524e-05, -0.00039245839090022125]
				Next Gradient = [-5.3208221445516935e-05, 0.00037139715962823894]
				|| Gradient || = 0.00039614379844734324
				beta = 0.8970053309978215
				||X optimum - X|| = 0.00010690343218500052
				alpha = 0.0007922816251426447
			Iteration 76:
				X = [3.999893829383984, -3.0300856985888046e-08]
				Current Gradient = [-5.3208221445516935e-05, 0.00037139715962823894]
				Next Gradient = [-5.314590862762873e-05, -0.00035802003157168566]
				|| Gradient || = 0.00037518923893059455
				beta = 0.9306361801703593
				||X optimum - X|| = 0.00010617062034004194
				alpha = 0.0007922816251426447
			Iteration 77:
				X = [3.999894734418081, 1.4741857593120168e-07]
				Current Gradient = [-5.314590862762873e-05, -0.00035802003157168566]
				Next Gradient = [-5.233792773708648e-05, 0.0004982201062895625]
				|| Gradient || = 0.0003619431317354248
				beta = 1.9157031326846918
				||X optimum - X|| = 0.00010526568514484083
				alpha = 0.0009903520314283058
			Iteration 78:
				X = [3.9998982219368844, -1.5132286935020245e-07]
				Current Gradient = [-5.233792773708648e-05, 0.0004982201062895625]
				Next Gradient = [-5.119164982602429e-05, -0.0009310795193066122]
				|| Gradient || = 0.0005009616083004719
				beta = 3.4647787696474235
				||X optimum - X|| = 0.00010177817560841838
				alpha = 0.0019342813113834097
			Iteration 79:
				X = [3.999904459376967, 2.408162391972955e-07]
				Current Gradient = [-5.119164982602429e-05, -0.0009310795193066122]
				Next Gradient = [-4.728860945545642e-05, 0.0009667080140880092]
				|| Gradient || = 0.0009324857405259032
				beta = 1.0773187438935397
				||X optimum - X|| = 9.55409265288333e-05
				alpha = 0.0009903520314283058
			Iteration 80:
				X = [3.999909872611755, -1.8712170776123285e-07]
				Current Gradient = [-4.728860945545642e-05, 0.0009667080140880092]
				Next Gradient = [-4.5437895527942064e-05, -0.0010798954723590113]
				|| Gradient || = 0.0009678639352131132
				beta = 1.247105009759482
				||X optimum - X|| = 9.012758249501735e-05
				alpha = 0.0007922816251426447
			Iteration 81:
				X = [3.999920477098994, 3.1584357709285033e-07]
				Current Gradient = [-4.5437895527942064e-05, -0.0010798954723590113]
				Next Gradient = [-3.9129643648106484e-05, 0.0013594698369309328]
				|| Gradient || = 0.0010808509765788715
				beta = 1.5833143988907106
				||X optimum - X|| = 7.952352822639202e-05
				alpha = 0.0012379400392853823
			Iteration 82:
				X = [3.9999312538525884, -2.5157400094614726e-07]
				Current Gradient = [-3.9129643648106484e-05, 0.0013594698369309328]
				Next Gradient = [-3.48761457665314e-05, -0.0013470185843490515]
				|| Gradient || = 0.001360032854947646
				beta = 0.9816109909981944
				||X optimum - X|| = 6.874660772295751e-05
				alpha = 0.0007922816251426447
			Iteration 83:
				X = [3.9999418600640935, 2.5866074107060825e-07]
				Current Gradient = [-3.48761457665314e-05, -0.0013470185843490515]
				Next Gradient = [-2.8552566189872656e-05, 0.0011273248790678817]
				|| Gradient || = 0.0013474700041653065
				beta = 0.7003876483148171
				||X optimum - X|| = 5.814051128597484e-05
				alpha = 0.0007922816251426447
			Iteration 84:
				X = [3.999947820929059, -1.6997659989099495e-07]
				Current Gradient = [-2.8552566189872656e-05, 0.0011273248790678817]
				Next Gradient = [-2.6429454003958513e-05, -0.00092158434816916]
				|| Gradient || = 0.0011276864067645052
				beta = 0.6684216768940042
				||X optimum - X|| = 5.217934779489433e-05
				alpha = 0.0006338253001141158
			Iteration 85:
				X = [3.9999518220520716, 1.2763638594285282e-07]
				Current Gradient = [-2.6429454003958513e-05, -0.00092158434816916]
				Next Gradient = [-2.383368164672104e-05, 0.00051730508962595]
				|| Gradient || = 0.000921963245921074
				beta = 0.31549115377958137
				||X optimum - X|| = 4.817811699975981e-05
				alpha = 0.0006338253001141158
			Iteration 86:
				X = [3.9999528439923164, -5.95530455789236e-08]
				Current Gradient = [-2.383368164672104e-05, 0.00051730508962595]
				Next Gradient = [-2.3697105680480555e-05, -0.00038063631866626683]
				|| Gradient || = 0.0005178538405126966
				beta = 0.5423580180559073
				||X optimum - X|| = 4.7156045288149675e-05
				alpha = 0.0005070602400912927
			Iteration 87:
				X = [3.9999537287944196, 8.338735137298326e-08]
				Current Gradient = [-2.3697105680480555e-05, -0.00038063631866626683]
				Next Gradient = [-2.296881974666621e-05, 0.0003083747140513718]
				|| Gradient || = 0.0003813732553620399
				beta = 0.6574455143834464
				||X optimum - X|| = 4.627128071835291e-05
				alpha = 0.0007922816251426447
			Iteration 88:
				X = [3.999954112734866, -1.2832870579847956e-08]
				Current Gradient = [-2.296881974666621e-05, 0.0003083747140513718]
				Next Gradient = [-2.2969298113622533e-05, -0.00015347355874467404]
				|| Gradient || = 0.00030922892967317946
				beta = 0.25184150274144346
				||X optimum - X|| = 4.58872669283071e-05
				alpha = 0.0005070602400912927
			Iteration 89:
				X = [3.999954221073823, 4.075522367417533e-08]
				Current Gradient = [-2.2969298113622533e-05, -0.00015347355874467404]
				Next Gradient = [-2.2807950651226698e-05, 0.00010438878534684092]
				|| Gradient || = 0.00015518286596653437
				beta = 0.4741031879466344
				||X optimum - X|| = 4.5778944318368104e-05
				alpha = 0.0005070602400912927
			Iteration 90:
				X = [3.9999543194001506, -2.2527704492471838e-09]
				Current Gradient = [-2.2807950651226698e-05, 0.00010438878534684092]
				Next Gradient = [-2.2844805462652766e-05, -0.00010219227303902127]
				|| Gradient || = 0.00010685139736614408
				beta = 0.9604040852959297
				||X optimum - X|| = 4.568059990498875e-05
				alpha = 0.0007922816251426447
			Iteration 91:
				X = [3.999954431932677, 3.740723645461114e-08]
				Current Gradient = [-2.2844805462652766e-05, -0.00010219227303902127]
				Next Gradient = [-2.2709217512708646e-05, 8.87137672724762e-05]
				|| Gradient || = 0.00010471459213265515
				beta = 0.7647724172989993
				||X optimum - X|| = 4.556808267699777e-05
				alpha = 0.0007922816251426447
			Iteration 92:
				X = [3.999954535986545, -2.5481719025939434e-09]
				Current Gradient = [-2.2709217512708646e-05, 8.87137672724762e-05]
				Next Gradient = [-2.2737103066599576e-05, -0.00010317935938120696]
				|| Gradient || = 9.157423799144922e-05
				beta = 1.3311671391530882
				||X optimum - X|| = 4.546401352625351e-05
				alpha = 0.0007922816251426447
			Iteration 93:
				X = [3.9999548417038864, 5.323265601765128e-08]
				Current Gradient = [-2.2737103066599576e-05, -0.00010317935938120696]
				Next Gradient = [-2.247267934741051e-05, 0.00016562024858999142]
				|| Gradient || = 0.0001056548913121273
				beta = 2.502481234762025
				||X optimum - X|| = 4.51583274889731e-05
				alpha = 0.0015474250491067279
			Iteration 94:
				X = [3.999955353592972, -2.1451789535969608e-08]
				Current Gradient = [-2.247267934741051e-05, 0.00016562024858999142]
				Next Gradient = [-2.2366106543969802e-05, -0.00019243071956606998]
				|| Gradient || = 0.00016713793124261797
				beta = 1.3434654107393662
				||X optimum - X|| = 4.4646412181435175e-05
				alpha = 0.0009903520314283058
			Iteration 95:
				X = [3.9999560634485722, 6.878639517396129e-08]
				Current Gradient = [-2.2366106543969802e-05, -0.00019243071956606998]
				Next Gradient = [-2.183069724884069e-05, 0.00024284463181442205]
				|| Gradient || = 0.0001937261586741751
				beta = 1.584076004855294
				||X optimum - X|| = 4.393660527319186e-05
				alpha = 0.0009903520314283058
			Iteration 96:
				X = [3.9999574960551953, -5.316051897375176e-08]
				Current Gradient = [-2.183069724884069e-05, 0.00024284463181442205]
				Next Gradient = [-2.1358290052071433e-05, -0.0003405982419902384]
				|| Gradient || = 0.00024382390068131702
				beta = 1.9590101562524016
				||X optimum - X|| = 4.2503978049090314e-05
				alpha = 0.0012379400392853823
			Iteration 97:
				X = [3.9999603289864023, 1.2958443875716657e-07]
				Current Gradient = [-2.1358290052071433e-05, -0.0003405982419902384]
				Next Gradient = [-1.9576317773762775e-05, 0.0005436876166173381]
				|| Gradient || = 0.0003412672545099946
				beta = 2.5413959381553948
				||X optimum - X|| = 3.9671225239403206e-05
				alpha = 0.0012379400392853823
			Iteration 98:
				X = [3.999969358779115, -1.3119728146596873e-07]
				Current Gradient = [-1.9576317773762775e-05, 0.0005436876166173381]
				Next Gradient = [-1.5582984352546113e-05, -0.0006920693229896086]
				|| Gradient || = 0.0005440399403358369
				beta = 1.6190406678856586
				||X optimum - X|| = 3.064150175908302e-05
				alpha = 0.0015474250491067279
			Iteration 99:
				X = [3.99997535684483, 1.3451400506408715e-07]
				Current Gradient = [-1.5582984352546113e-05, -0.0006920693229896086]
				Next Gradient = [-1.2052527863812091e-05, 0.0005974490703926815]
				|| Gradient || = 0.000692244737953729
				beta = 0.7451765142287573
				||X optimum - X|| = 2.4643522287631798e-05
				alpha = 0.0006338253001141158
			Iteration 100:
				X = [3.9999809534159536, -9.133165250695694e-08]
				Current Gradient = [-1.2052527863812091e-05, 0.0005974490703926815]
				Next Gradient = [-9.70594531976035e-06, -0.0004772115784208329]
				|| Gradient || = 0.0005975706277428529
				beta = 0.6380035228407267
				||X optimum - X|| = 1.9046803020636396e-05
				alpha = 0.0007922816251426447
			Iteration 101:
				X = [3.9999832435419918, 5.84255569263471e-08]
				Current Gradient = [-9.70594531976035e-06, -0.0004772115784208329]
				Next Gradient = [-8.26137379514559e-06, 0.00024739481207658426]
				|| Gradient || = 0.0004773102722060912
				beta = 0.2689451005516538
				||X optimum - X|| = 1.6756559865554667e-05
				alpha = 0.0005070602400912927
			Iteration 102:
				X = [3.9999838636491836, -2.6742048133170908e-08]
				Current Gradient = [-8.26137379514559e-06, 0.00024739481207658426]
				Next Gradient = [-8.121658647452756e-06, -0.00016084743341438965]
				|| Gradient || = 0.0002475327116552307
				beta = 0.42332012176356304
				||X optimum - X|| = 1.6136372975612715e-05
				alpha = 0.0005070602400912927
			Iteration 103:
				X = [3.9999841969267114, 3.014067344315711e-08]
				Current Gradient = [-8.121658647452756e-06, -0.00016084743341438965]
				Next Gradient = [-7.84125420846189e-06, 0.00011330906818398895]
				|| Gradient || = 0.0001610523460716492
				beta = 0.49735911551204753
				||X optimum - X|| = 1.5803102031757183e-05
				alpha = 0.0006338253001141158
			Iteration 104:
				X = [3.999984333509593, -4.680937801840527e-09]
				Current Gradient = [-7.84125420846189e-06, 0.00011330906818398895]
				Next Gradient = [-7.84260705389226e-06, -5.383875376386009e-05]
				|| Gradient || = 0.00011358006075137299
				beta = 0.22945885108403521
				||X optimum - X|| = 1.5666491106485386e-05
				alpha = 0.0005070602400912927
			Iteration 105:
				X = [3.9999843688264183, 1.4628426698706275e-08]
				Current Gradient = [-7.84260705389226e-06, -5.383875376386009e-05]
				Next Gradient = [-7.786329681776172e-06, 3.907057962131863e-05]
				|| Gradient || = 5.44069654754547e-05
				beta = 0.5361736186304911
				||X optimum - X|| = 1.563118042672225e-05
				alpha = 0.0005070602400912927
			Iteration 106:
				X = [3.999984404582806, -1.4964462251007814e-10]
				Current Gradient = [-7.786329681776172e-06, 3.907057962131863e-05]
				Next Gradient = [-7.798007887369145e-06, -3.191032013313092e-05]
				|| Gradient || = 3.9838889566089905e-05
				beta = 0.6798892440663129
				||X optimum - X|| = 1.5595417194809917e-05
				alpha = 0.0007922816251426447
			Iteration 107:
				X = [3.9999844289736872, 1.2037962221137263e-08]
				Current Gradient = [-7.798007887369145e-06, -3.191032013313092e-05]
				Next Gradient = [-7.7614370592139e-06, 2.6736019871292047e-05]
				|| Gradient || = 3.2849314422227624e-05
				beta = 0.7182567461017357
				||X optimum - X|| = 1.557103096605158e-05
				alpha = 0.0006338253001141158
			Iteration 108:
				X = [3.999984464033547, -7.622486921334548e-10]
				Current Gradient = [-7.7614370592139e-06, 2.6736019871292047e-05]
				Next Gradient = [-7.769507724242547e-06, -3.4736796197156085e-05]
				|| Gradient || = 2.783980358735065e-05
				beta = 1.6347366444281741
				||X optimum - X|| = 1.553596647157243e-05
				alpha = 0.0009903520314283058
			Iteration 109:
				X = [3.999984545293779, 1.6083604861405935e-08]
				Current Gradient = [-7.769507724242547e-06, -3.4736796197156085e-05]
				Next Gradient = [-7.695185591371495e-06, 4.641996317169518e-05]
				|| Gradient || = 3.559508758691039e-05
				beta = 1.7474435144576634
				||X optimum - X|| = 1.5454714590041804e-05
				alpha = 0.0012379400392853823
			Iteration 110:
				X = [3.999984666512854, -6.338757934400743e-09]
				Current Gradient = [-7.695185591371495e-06, 4.641996317169518e-05]
				Next Gradient = [-7.679421041892957e-06, -6.114348917181323e-05]
				|| Gradient || = 4.705346812029044e-05
				beta = 1.7151988578682997
				||X optimum - X|| = 1.5333488456417888e-05
				alpha = 0.0009903520314283058
			Iteration 111:
				X = [3.9999850032630864, 2.8184316521604845e-08]
				Current Gradient = [-7.679421041892957e-06, -6.114348917181323e-05]
				Next Gradient = [-7.441998871537697e-06, 0.00010551570559519436]
				|| Gradient || = 6.162385719542642e-05
				beta = 2.9463984556952867
				||X optimum - X|| = 1.4996763397891812e-05
				alpha = 0.0015474250491067279
			Iteration 112:
				X = [3.999986006979387, -3.337459612754154e-08]
				Current Gradient = [-7.441998871537697e-06, 0.00010551570559519436]
				Next Gradient = [-7.0632581629741974e-06, -0.00018844997858093507]
				|| Gradient || = 0.00010577782127863902
				beta = 3.17842979638813
				||X optimum - X|| = 1.3993060413520584e-05
				alpha = 0.0015474250491067279
			Iteration 113:
				X = [3.9999892081510464, 6.25769390349227e-08]
				Current Gradient = [-7.0632581629741974e-06, -0.00018844997858093507]
				Next Gradient = [-5.270765900343572e-06, 0.00027928460420526913]
				|| Gradient || = 0.00018858230045004675
				beta = 2.1940513430890207
				||X optimum - X|| = 1.079203037941763e-05
				alpha = 0.0015474250491067279
			Iteration 114:
				X = [3.9999928083768865, -5.0907552629683285e-08]
				Current Gradient = [-5.270765900343572e-06, 0.00027928460420526913]
				Next Gradient = [-3.697623552597007e-06, -0.00025914588061253505]
				|| Gradient || = 0.0002793343357327739
				beta = 0.8608517836667091
				||X optimum - X|| = 7.191803291600142e-06
				alpha = 0.0007922816251426447
			Iteration 115:
				X = [3.9999952901292026, 3.5191001268504896e-08]
				Current Gradient = [-3.697623552597007e-06, -0.00025914588061253505]
				Next Gradient = [-2.284551910469984e-06, 0.00015977819471663291]
				|| Gradient || = 0.0002591722590447963
				beta = 0.3801428003728522
				||X optimum - X|| = 4.7100022648074904e-06
				alpha = 0.0006338253001141158
			Iteration 116:
				X = [3.999996046023828, -1.964237219633614e-08]
				Current Gradient = [-2.284551910469984e-06, 0.00015977819471663291]
				Next Gradient = [-2.016272367546909e-06, -0.00010234829146661315]
				|| Gradient || = 0.00015979452645299805
				beta = 0.4103986380488196
				||X optimum - X|| = 3.954024960724825e-06
				alpha = 0.0005070602400912927
			Iteration 117:
				X = [3.9999963572643247, 9.750835258065283e-09]
				Current Gradient = [-2.016272367546909e-06, -0.00010234829146661315]
				Next Gradient = [-1.8018660533189113e-06, 3.959645932258178e-05]
				|| Gradient || = 0.00010236814993148471
				beta = 0.14992753233665093
				||X optimum - X|| = 3.642748725765895e-06
				alpha = 0.0005070602400912927
			Iteration 118:
				X = [3.999996395326064, -2.78591602975533e-09]
				Current Gradient = [-1.8018660533189113e-06, 3.959645932258178e-05]
				Next Gradient = [-1.8079087909391558e-06, -2.0604008041521467e-05]
				|| Gradient || = 3.963743574146764e-05
				beta = 0.2722847159141394
				||X optimum - X|| = 3.6046750123508093e-06
				alpha = 0.00040564819207303417
			Iteration 119:
				X = [3.9999964091973204, 3.3946000310084003e-09]
				Current Gradient = [-1.8079087909391558e-06, -2.0604008041521467e-05]
				Next Gradient = [-1.7886121261524114e-06, 9.139602335265605e-06]
				|| Gradient || = 2.0683173875675764e-05
				beta = 0.2027413398580756
				||X optimum - X|| = 3.5908042842013565e-06
				alpha = 0.0005070602400912927
			Iteration 120:
				X = [3.999996412172689, 6.895737531803015e-10]
				Current Gradient = [-1.7886121261524114e-06, 9.139602335265605e-06]
				Next Gradient = [-1.7925345076183132e-06, -3.860189954509661e-06]
				|| Gradient || = 9.312972897233834e-06
				beta = 0.208854383079971
				||X optimum - X|| = 3.5878273770699356e-06
				alpha = 0.00040564819207303417
			Iteration 121:
				X = [3.99999641427981, 2.253515130734105e-09]
				Current Gradient = [-1.7925345076183132e-06, -3.860189954509661e-06]
				Next Gradient = [-1.7883530589026545e-06, 3.6634409751536975e-06]
				|| Gradient || = 4.256083463220585e-06
				beta = 0.9174550258745854
				||X optimum - X|| = 3.585720898234884e-06
				alpha = 0.0006338253001141158
			Iteration 122:
				X = [3.9999964236386107, -4.5380816796335025e-10]
				Current Gradient = [-1.7883530589026545e-06, 3.6634409751536975e-06]
				Next Gradient = [-1.789088311057899e-06, -9.334628554653829e-06]
				|| Gradient || = 4.076641564047734e-06
				beta = 5.435711668739492
				||X optimum - X|| = 3.57636141804908e-06
				alpha = 0.0019342813113834097
			Iteration 123:
				X = [3.9999965894477625, 9.737746752058558e-09]
				Current Gradient = [-1.789088311057899e-06, -9.334628554653829e-06]
				Next Gradient = [-1.6858005117645936e-06, 3.9997902202714165e-05]
				|| Gradient || = 9.504531931564154e-06
				beta = 17.74123103328045
				||X optimum - X|| = 3.4105661390053898e-06
				alpha = 0.005902958103587064
			Iteration 124:
				X = [3.9999981006719176, -1.857340102881556e-08]
				Current Gradient = [-1.6858005117645936e-06, 3.9997902202714165e-05]
				Next Gradient = [-9.868104294346806e-07, -9.30994836469634e-05]
				|| Gradient || = 4.003341234498194e-05
				beta = 5.408765031274812
				||X optimum - X|| = 1.899418894212572e-06
				alpha = 0.0030223145490365774
			Iteration 125:
				X = [3.9999998154793053, 8.322065403549516e-09]
				Current Gradient = [-9.868104294346806e-07, -9.30994836469634e-05]
				Next Gradient = [-7.561613342976871e-08, 3.96434453855791e-05]
				|| Gradient || = 9.310471336164914e-05
				beta = 0.18130134612477108
				||X optimum - X|| = 1.847082660681817e-07
				alpha = 0.0006338253001141158
			Iteration 126:
				X = [3.9999999746830506, -2.046361809368681e-09]
				Current Gradient = [-7.561613342976871e-08, 3.96434453855791e-05]
				Next Gradient = [-1.675119329828907e-08, -9.889541353898903e-06]
				|| Gradient || = 3.964351750083521e-05
				beta = 0.062231344541339585
				||X optimum - X|| = 2.539951820175365e-08
				alpha = 0.00032451855365842736
			Iteration 127:
				X = [3.99999998459595, 5.177366809048831e-10]
				Current Gradient = [-1.675119329828907e-08, -9.889541353898903e-06]
				Next Gradient = [-6.666551434344903e-09, 2.458469843069588e-06]
				|| Gradient || = 9.889555540718372e-06
				beta = 0.06179871097189401
				||X optimum - X|| = 1.5412748254863634e-08
				alpha = 0.00032451855365842736
			Iteration 128:
				X = [3.9999999852107178, -1.2162441527703464e-10]
				Current Gradient = [-6.666551434344903e-09, 2.458469843069588e-06]
				Next Gradient = [-7.637890078091342e-09, -6.1434874896067e-07]
				|| Gradient || = 2.4584788817865876e-06
				beta = 0.062454554489373496
				||X optimum - X|| = 1.4789782343576279e-08
				alpha = 0.00032451855365842736
	- Starting Point : [1.9 0.6]
	------------------------------
		- Conjugate Gradient [Non-Linear]:
			- Fletcher-Reevers Method
			------------
			Iteration 0:
				X = [1.6457890130010624, -0.20515620154852698]
				Current Gradient = [205.34999994481495, 650.3999999978305]
				Next Gradient = [19.19349932855141, -173.05681957680008]
				|| Gradient || = 682.0474928291383
				beta = 0.06517150533433862
				||X optimum - X|| = 2.363133182522799
				alpha = 0.0012379400392853823
			Iteration 1:
				X = [1.5827769598634693, 0.04759493023477229]
				Current Gradient = [19.19349932855141, -173.05681957680008]
				Next Gradient = [-0.037793004725728, 31.31651503363031]
				|| Gradient || = 174.11792905531652
				beta = 0.03234897320310628
				||X optimum - X|| = 2.417691564933572
				alpha = 0.0019342813113834097
			Iteration 2:
				X = [1.5808116869477906, -0.004803779943323677]
				Current Gradient = [-0.037793004725728, 31.31651503363031]
				Next Gradient = [-1.208257930040979, -8.478151099278186]
				|| Gradient || = 31.316537838062484
				beta = 0.07478028269352921
				||X optimum - X|| = 2.419193082478151
				alpha = 0.0019342813113834097
			Iteration 3:
				X = [1.5835493707842965, 0.010797143639831551]
				Current Gradient = [-1.208257930040979, -8.478151099278186]
				Next Gradient = [-1.13124877409998, 3.376043778868798]
				|| Gradient || = 8.563815346427013
				beta = 0.17286037330280893
				||X optimum - X|| = 2.416474750902179
				alpha = 0.002417851639229262
			Iteration 4:
				X = [1.587559906725293, 0.003964654251837968]
				Current Gradient = [-1.13124877409998, 3.376043778868798]
				Next Gradient = [-1.190804527539946, -1.7954722630886266]
				|| Gradient || = 3.560533019892025
				beta = 0.3661427232561432
				||X optimum - X|| = 2.4124433510701584
				alpha = 0.0030223145490365774
			Iteration 5:
				X = [1.597457200474894, 0.009677184861185066]
				Current Gradient = [-1.190804527539946, -1.7954722630886266]
				Next Gradient = [-1.137037472731528, 2.680805768928707]
				|| Gradient || = 2.1544688603760855
				beta = 1.8268108433217896
				||X optimum - X|| = 2.4025622887777063
				alpha = 0.005902958103587064
			Iteration 6:
				X = [1.6579854429188752, -0.0034794832976961544]
				Current Gradient = [-1.137037472731528, 2.680805768928707]
				Next Gradient = [-1.1719443738789082, -7.581306890158679]
				|| Gradient || = 2.911970773396796
				beta = 6.940168134573399
				||X optimum - X|| = 2.342017141778411
				alpha = 0.014411518807585602
			Iteration 7:
				X = [2.2041925402151907, 0.018956338852524093]
				Current Gradient = [-1.1719443738789082, -7.581306890158679]
				Next Gradient = [-0.6223728480359014, 24.189647047312413]
				|| Gradient || = 7.671353712235793
				beta = 9.949527233390517
				||X optimum - X|| = 1.795907507473996
				alpha = 0.018014398509482003
			Iteration 8:
				X = [2.935103908971511, -0.009569776053826862]
				Current Gradient = [-0.6223728480359014, 24.189647047312413]
				Next Gradient = [-0.47094801250424645, -26.93896277261576]
				|| Gradient || = 24.197652205028536
				beta = 1.2397896008053095
				||X optimum - X|| = 1.0649390899490336
				alpha = 0.002417851639229262
			Iteration 9:
				X = [3.3996491871889765, 0.005671457705729665]
				Current Gradient = [-0.47094801250424645, -26.93896277261576]
				Next Gradient = [-0.25602713508987573, 18.50922674408173]
				|| Gradient || = 26.943079024025067
				beta = 0.4720252050844816
				||X optimum - X|| = 0.6003776010773257
				alpha = 0.0012379400392853823
			Iteration 10:
				X = [3.512081328738185, -0.0023767042867774164]
				Current Gradient = [-0.25602713508987573, 18.50922674408173]
				Next Gradient = [-0.24276111158794134, -9.78964216694772]
				|| Gradient || = 18.51099739500097
				beta = 0.27986009286677616
				||X optimum - X|| = 0.4879244598184866
				alpha = 0.0006338253001141158
			Iteration 11:
				X = [3.543700466447765, 0.0015758592350681357]
				Current Gradient = [-0.24276111158794134, -9.78964216694772]
				Next Gradient = [-0.22235799255684863, 5.036811481354264]
				|| Gradient || = 9.792651669194624
				beta = 0.26506742611263284
				||X optimum - X|| = 0.45630225470877944
				alpha = 0.0006338253001141158
			Iteration 12:
				X = [3.55222260601771, -0.0005689034744371714]
				Current Gradient = [-0.22235799255684863, 5.036811481354264]
				Next Gradient = [-0.22468159967606316, -3.0536819447257724]
				|| Gradient || = 5.041717264539539
				beta = 0.3688377724803977
				||X optimum - X|| = 0.4477777553795347
				alpha = 0.0006338253001141158
			Iteration 13:
				X = [3.5555083018758, 0.0005755279003587385]
				Current Gradient = [-0.22468159967606316, -3.0536819447257724]
				Next Gradient = [-0.22074148346706846, 1.2983056613159738]
				|| Gradient || = 3.0619365180841305
				beta = 0.1849856191713401
				||X optimum - X|| = 0.44449207072083863
				alpha = 0.0006338253001141158
			Iteration 14:
				X = [3.556106476291579, 8.657139719255968e-05]
				Current Gradient = [-0.22074148346706846, 1.2983056613159738]
				Next Gradient = [-0.22176562360434748, -0.5586626814560458]
				|| Gradient || = 1.3169375052478194
				beta = 0.20831396074406297
				||X optimum - X|| = 0.4438935321503181
				alpha = 0.0005070602400912927
			Iteration 15:
				X = [3.5564768772480093, 0.00037003884654105074]
				Current Gradient = [-0.22176562360434748, -0.5586626814560458]
				Next Gradient = [-0.22087538853465816, 0.5200480541096841]
				|| Gradient || = 0.6010690338590772
				beta = 0.8836149136269806
				||X optimum - X|| = 0.4435232771167995
				alpha = 0.0007922816251426447
			Iteration 16:
				X = [3.5577031646525645, -2.4366553093136615e-05]
				Current Gradient = [-0.22087538853465816, 0.5200480541096841]
				Next Gradient = [-0.2211965171167174, -0.9773126826047307]
				|| Gradient || = 0.5650096599560093
				beta = 3.1452224794672476
				||X optimum - X|| = 0.44229683601862374
				alpha = 0.0019342813113834097
			Iteration 17:
				X = [3.563059168402936, 0.0007880146073913723]
				Current Gradient = [-0.2211965171167174, -0.9773126826047307]
				Next Gradient = [-0.21623062394088288, 2.1336684343647994]
				|| Gradient || = 1.002031925022662
				beta = 4.5806626322188375
				||X optimum - X|| = 0.43694154218128
				alpha = 0.002417851639229262
			Iteration 18:
				X = [3.5943802431603085, -0.0010090475134220006]
				Current Gradient = [-0.21623062394088288, 2.1336684343647994]
				Next Gradient = [-0.20373005901047625, -4.730249686620003]
				|| Gradient || = 2.144597088157726
				beta = 4.87395565898719
				||X optimum - X|| = 0.4056210119256334
				alpha = 0.0030223145490365774
			Iteration 19:
				X = [3.672856155291216, 0.0018261531804186337]
				Current Gradient = [-0.20373005901047625, -4.730249686620003]
				Next Gradient = [-0.1562451047570912, 6.750693517788148]
				|| Gradient || = 4.734634942074526
				beta = 2.034025397116135
				||X optimum - X|| = 0.3271489415637524
				alpha = 0.0015474250491067279
			Iteration 20:
				X = [3.800747176031233, -0.0019173044444410932]
				Current Gradient = [-0.1562451047570912, 6.750693517788148]
				Next Gradient = [-0.09926949266943208, -8.7228735036627]
				|| Gradient || = 6.752501425684224
				beta = 1.6689603646820006
				||X optimum - X|| = 0.19926204835808828
				alpha = 0.0012379400392853823
			Iteration 21:
				X = [3.9374306539790522, 0.000995151213189703]
				Current Gradient = [-0.09926949266943208, -8.7228735036627]
				Next Gradient = [-0.028124568677212122, 4.511278817657775]
				|| Gradient || = 8.723438346952172
				beta = 0.2674489059187489
				||X optimum - X|| = 0.06257725934735561
				alpha = 0.0007922816251426447
			Iteration 22:
				X = [3.9561586561362576, -0.0004360271465953926]
				Current Gradient = [-0.028124568677212122, 4.511278817657775]
				Next Gradient = [-0.022567083151671125, -2.1384741915482226]
				|| Gradient || = 4.511366485003298
				beta = 0.22471919515373454
				||X optimum - X|| = 0.043843512079342714
				alpha = 0.00040564819207303417
			Iteration 23:
				X = [3.960376352004343, 0.00010982779386863864]
				Current Gradient = [-0.022567083151671125, -2.1384741915482226]
				Next Gradient = [-0.019577837223519034, 0.4384122000986642]
				|| Gradient || = 2.1385932622076127
				beta = 0.04210891705244
				||X optimum - X|| = 0.03962380020427154
				alpha = 0.00040564819207303417
			Iteration 24:
				X = [3.960524787460132, -1.4056810885057345e-05]
				Current Gradient = [-0.019577837223519034, 0.4384122000986642]
				Next Gradient = [-0.019765485121742622, -0.1452103937702831]
				|| Gradient || = 0.4388491186110573
				beta = 0.11151614664033985
				||X optimum - X|| = 0.039475215042627354
				alpha = 0.00032451855365842736
			Iteration 25:
				X = [3.960553496481005, 2.7578605630329252e-05]
				Current Gradient = [-0.019765485121742622, -0.1452103937702831]
				Next Gradient = [-0.019667190856247595, 0.05110689179455919]
				|| Gradient || = 0.1465494212237582
				beta = 0.1396261155959939
				||X optimum - X|| = 0.03944651315963882
				alpha = 0.00040564819207303417
			Iteration 26:
				X = [3.9605684795928564, 8.931072155741254e-06]
				Current Gradient = [-0.019667190856247595, 0.05110689179455919]
				Next Gradient = [-0.01969780328870416, -0.0367634777719407]
				|| Gradient || = 0.05476050387895322
				beta = 0.5801011557176795
				||X optimum - X|| = 0.039431521418568566
				alpha = 0.0005070602400912927
			Iteration 27:
				X = [3.960625485493021, 3.280754354776561e-05]
				Current Gradient = [-0.01969780328870416, -0.0367634777719407]
				Next Gradient = [-0.019620363281308173, 0.07590462470342214]
				|| Gradient || = 0.04170799386554648
				beta = 3.5333545160696365
				||X optimum - X|| = 0.03937452817488991
				alpha = 0.0015474250491067279
			Iteration 28:
				X = [3.960987646581153, -1.8899768308959446e-05]
				Current Gradient = [-0.019620363281308173, 0.07590462470342214]
				Next Gradient = [-0.019543551787836032, -0.1671338436399746]
				|| Gradient || = 0.07839943052508654
				beta = 4.606818035540902
				||X optimum - X|| = 0.03901235799689984
				alpha = 0.002417851639229262
			Iteration 29:
				X = [3.9620856713115873, 8.727537472124911e-05]
				Current Gradient = [-0.019543551787836032, -0.1671338436399746]
				Next Gradient = [-0.018773559846074154, 0.3358874123093425]
				|| Gradient || = 0.1682726124666617
				beta = 3.9968254990408405
				||X optimum - X|| = 0.037914429138311286
				alpha = 0.0015474250491067279
			Iteration 30:
				X = [3.9755673116861736, -0.00020385339865420878]
				Current Gradient = [-0.018773559846074154, 0.3358874123093425]
				Next Gradient = [-0.012574488105198409, -1.0170753771018795]
				|| Gradient || = 0.33641165303413667
				beta = 9.141776449301108
				||X optimum - X|| = 0.02443353872137091
				alpha = 0.004722366482869652
			Iteration 31:
				X = [3.9962545457566327, 0.0001554421755901077]
				Current Gradient = [-0.012574488105198409, -1.0170753771018795]
				Next Gradient = [-0.0015328751963767945, 0.7384784421986726]
				|| Gradient || = 1.0171531057112484
				beta = 0.5271143699273001
				||X optimum - X|| = 0.0037486784016650377
				alpha = 0.0007922816251426447
			Iteration 32:
				X = [4.00183829120121, -4.715266093213881e-05]
				Current Gradient = [-0.0015328751963767945, 0.7384784421986726]
				Next Gradient = [0.0008275095531385657, -0.22324149193440196]
				|| Gradient || = 0.738480033107562
				beta = 0.0913857088708253
				||X optimum - X|| = 0.001838895840954358
				alpha = 0.00040564819207303417
			Iteration 33:
				X = [4.002246242287493, 1.0481926947639221e-05]
				Current Gradient = [0.0008275095531385657, -0.22324149193440196]
				Next Gradient = [0.0011442169167917911, 0.054946113079817484]
				|| Gradient || = 0.2232430256316156
				beta = 0.06060471926742816
				||X optimum - X|| = 0.0022462667439360354
				alpha = 0.00032451855365842736
			Iteration 34:
				X = [4.002270594728933, -3.856178179627682e-06]
				Current Gradient = [0.0011442169167917911, 0.054946113079817484]
				Next Gradient = [0.00112760286252618, -0.01402033515676416]
				|| Gradient || = 0.05495802557345708
				beta = 0.06550201844014468
				||X optimum - X|| = 0.0022705980034273803
				alpha = 0.00032451855365842736
			Iteration 35:
				X = [4.002271823934951, -2.4549411919114566e-07]
				Current Gradient = [0.00112760286252618, -0.01402033515676416]
				Next Gradient = [0.0011354210517575596, 0.0033619732382513716]
				|| Gradient || = 0.014065606496826732
				beta = 0.063647205627381
				||X optimum - X|| = 0.0022718239482149368
				alpha = 0.00032451855365842736
			Iteration 36:
				X = [4.002271461147864, -1.3220100465230996e-06]
				Current Gradient = [0.0011354210517575596, 0.0033619732382513716]
				Next Gradient = [0.00113308865244104, -0.001820511001313748]
				|| Gradient || = 0.0035485271620057605
				beta = 0.36516310043976474
				||X optimum - X|| = 0.0022714615325748625
				alpha = 0.00040564819207303417
			Iteration 37:
				X = [4.00226965416599, -2.6798446475226795e-07]
				Current Gradient = [0.00113308865244104, -0.001820511001313748]
				Next Gradient = [0.0011342912004515767, 0.0032493788545020835]
				|| Gradient || = 0.002144329778787544
				beta = 2.576053184823046
				||X optimum - X|| = 0.002269654181810739
				alpha = 0.0012379400392853823
			Iteration 38:
				X = [4.002260186875511, -2.31065669911115e-06]
				Current Gradient = [0.0011342912004515767, 0.0032493788545020835]
				Next Gradient = [0.001125478535096301, -0.0066018012381010025]
				|| Gradient || = 0.003441668122801377
				beta = 3.7864230158511063
				||X optimum - X|| = 0.002260188056637663
				alpha = 0.0019342813113834097
			Iteration 39:
				X = [4.002229767548581, 1.7175989763369696e-06]
				Current Gradient = [0.001125478535096301, -0.0066018012381010025]
				Next Gradient = [0.0011183225145485344, 0.012726945168919776]
				|| Gradient || = 0.006697050210380272
				beta = 3.639331687111542
				||X optimum - X|| = 0.002229768210117579
				alpha = 0.0015474250491067279
			Iteration 40:
				X = [4.002010164930086, -8.11411045637605e-06]
				Current Gradient = [0.0011183225145485344, 0.012726945168919776]
				Next Gradient = [0.0009889332905185944, -0.035031468730797155]
				|| Gradient || = 0.012775984446579316
				beta = 7.5244351791754776
				||X optimum - X|| = 0.0020101813064834877
				alpha = 0.0030223145490365774
			Iteration 41:
				X = [4.001162613167903, 8.21769487726668e-06]
				Current Gradient = [0.0009889332905185944, -0.035031468730797155]
				Next Gradient = [0.0005978230339540399, 0.04185883623844713]
				|| Gradient || = 0.03504542467270036
				beta = 1.4269219566575644
				||X optimum - X|| = 0.0011626422100932659
				alpha = 0.0015474250491067279
			Iteration 42:
				X = [4.0007660170486945, -5.370932611303928e-06]
				Current Gradient = [0.0005978230339540399, 0.04185883623844713]
				Next Gradient = [0.0003723012821063265, -0.024301284985627468]
				|| Gradient || = 0.04186310504032232
				beta = 0.3370524771650491
				||X optimum - X|| = 0.000766035877624376
				alpha = 0.0005070602400912927
			Iteration 43:
				X = [4.000632154565104, 2.37120223173946e-06]
				Current Gradient = [0.0003723012821063265, -0.024301284985627468]
				Next Gradient = [0.00032082643524664663, 0.012668647263879996]
				|| Gradient || = 0.024304136688994758
				beta = 0.2718807917027117
				||X optimum - X|| = 0.0006321590122604842
				alpha = 0.0005070602400912927
			Iteration 44:
				X = [4.000595597248757, -1.9476273409196434e-06]
				Current Gradient = [0.00032082643524664663, 0.012668647263879996]
				Next Gradient = [0.0002939079223180456, -0.008175781968427836]
				|| Gradient || = 0.012672708988143268
				beta = 0.41675474732270307
				||X optimum - X|| = 0.0005956004331587781
				alpha = 0.0005070602400912927
			Iteration 45:
				X = [4.000576366668558, 9.84524209782504e-07]
				Current Gradient = [0.0002939079223180456, -0.008175781968427836]
				Next Gradient = [0.0002901535460522406, 0.005887687708555239]
				|| Gradient || = 0.00818106305207771
				beta = 0.5191866618981972
				||X optimum - X|| = 0.0005763675094181921
				alpha = 0.0006338253001141158
			Iteration 46:
				X = [4.00056823213464, -7.830209526691318e-07]
				Current Gradient = [0.0002901535460522406, 0.005887687708555239]
				Next Gradient = [0.00028255076130462894, -0.002629368397370818]
				|| Gradient || = 0.005894832960632483
				beta = 0.2012547671946522
				||X optimum - X|| = 0.000568232674139019
				alpha = 0.0005070602400912927
			Iteration 47:
				X = [4.00056680782745, -1.0039281218783305e-09]
				Current Gradient = [0.00028255076130462894, -0.002629368397370818]
				Next Gradient = [0.0002834019059098852, 0.0011287874027438225]
				|| Gradient || = 0.002644506211338179
				beta = 0.1936790550120191
				||X optimum - X|| = 0.000566807827451222
				alpha = 0.00040564819207303417
			Iteration 48:
				X = [4.000566319302524, -3.840417416721589e-07]
				Current Gradient = [0.0002834019059098852, 0.0011287874027438225]
				Next Gradient = [0.00028239174482874523, -0.0007143561024325976]
				|| Gradient || = 0.0011638202785939503
				beta = 0.4356289988313447
				||X optimum - X|| = 0.0005663194327403732
				alpha = 0.0005070602400912927
			Iteration 49:
				X = [4.00056576304432, -7.87929954554449e-08]
				Current Gradient = [0.00028239174482874523, -0.0007143561024325976]
				Next Gradient = [0.0002827239436597041, 0.0007525823712351841]
				|| Gradient || = 0.0007681469511949618
				beta = 1.095353512591966
				||X optimum - X|| = 0.0005657630498067929
				alpha = 0.0007922816251426447
			Iteration 50:
				X = [4.000564461018753, -4.880147106947348e-07]
				Current Gradient = [0.0002827239436597041, 0.0007525823712351841]
				Next Gradient = [0.00028125476582475126, -0.0012181138548035921]
				|| Gradient || = 0.0008039359761899377
				beta = 2.4181866625536075
				||X optimum - X|| = 0.0005644612297135529
				alpha = 0.0012379400392853823
			Iteration 51:
				X = [4.000558997397818, 3.219500071969311e-07]
				Current Gradient = [0.00028125476582475126, -0.0012181138548035921]
				Next Gradient = [0.0002801427233620991, 0.0026663623865716512]
				|| Gradient || = 0.0012501622320977394
				beta = 4.599105852452063
				||X optimum - X|| = 0.0005589974905306319
				alpha = 0.0019342813113834097
			Iteration 52:
				X = [4.000526910340509, -1.4685268170355264e-06]
				Current Gradient = [0.0002801427233620991, 0.0026663623865716512]
				Next Gradient = [0.0002605207048827174, -0.00600871345440608]
				|| Gradient || = 0.0026810386647672215
				beta = 5.032368924642844
				||X optimum - X|| = 0.0005269123869353009
				alpha = 0.002417851639229262
			Iteration 53:
				X = [4.000423163901787, 2.062889339658256e-06]
				Current Gradient = [0.0002605207048827174, -0.00600871345440608]
				Next Gradient = [0.00021571283675787605, 0.010766794916219307]
				|| Gradient || = 0.006014358520643181
				beta = 3.2060371226097253
				||X optimum - X|| = 0.00042316892996522887
				alpha = 0.0015474250491067279
			Iteration 54:
				X = [4.000156804915125, -2.208276146908703e-06]
				Current Gradient = [0.00021571283675787605, 0.010766794916219307]
				Next Gradient = [7.399175728895778e-05, -0.010304612944896352]
				|| Gradient || = 0.010768955603765298
				beta = 0.9156691563782114
				||X optimum - X|| = 0.00015682046387822658
				alpha = 0.0012379400392853823
			Iteration 55:
				X = [4.000076854827025, 6.902233407498217e-07]
				Current Gradient = [7.399175728895778e-05, -0.010304612944896352]
				Next Gradient = [3.980843190043539e-05, 0.003472430790392692]
				|| Gradient || = 0.010304878588526512
				beta = 0.11356343293111182
				||X optimum - X|| = 7.685792636626876e-05
				alpha = 0.00040564819207303417
			Iteration 56:
				X = [4.000067759272339, -3.8919837930414006e-07]
				Current Gradient = [3.980843190043539e-05, 0.003472430790392692]
				Next Gradient = [3.310142118896433e-05, -0.0017358105558811726]
				|| Gradient || = 0.003472658967609343
				beta = 0.2499414491052356
				||X optimum - X|| = 6.776039007609577e-05
				alpha = 0.00040564819207303417
			Iteration 57:
				X = [4.0000649007927755, 1.5372185178152625e-07]
				Current Gradient = [3.310142118896433e-05, -0.0017358105558811726]
				Next Gradient = [3.2757868452685896e-05, 0.0008689201931229753]
				|| Gradient || = 0.0017361261446085174
				beta = 0.2508499563963078
				||X optimum - X|| = 6.490097482551487e-05
				alpha = 0.0005070602400912927
			Iteration 58:
				X = [4.0000643138650265, -8.980084057895025e-08]
				Current Gradient = [3.2757868452685896e-05, 0.0008689201931229753]
				Next Gradient = [3.197734051381024e-05, -0.0003031485726129167]
				|| Gradient || = 0.0008695374517307649
				beta = 0.12289667394635047
				||X optimum - X|| = 6.43139277204784e-05
				alpha = 0.00040564819207303417
			Iteration 59:
				X = [4.000064228762008, 3.242700909437446e-09]
				Current Gradient = [3.197734051381024e-05, -0.0003031485726129167]
				Next Gradient = [3.2120866422913006e-05, 0.00014404892985453463]
				|| Gradient || = 0.0003048304567847265
				beta = 0.2344109714124802
				||X optimum - X|| = 6.422876208947988e-05
				alpha = 0.00040564819207303417
			Iteration 60:
				X = [4.000064187538442, -4.25357503675587e-08]
				Current Gradient = [3.2120866422913006e-05, 0.00014404892985453463]
				Next Gradient = [3.200869989556677e-05, -7.614336356891645e-05]
				|| Gradient || = 0.0001475867346748862
				beta = 0.31321354636753074
				||X optimum - X|| = 6.418755253550719e-05
				alpha = 0.0005070602400912927
			Iteration 61:
				X = [4.000064151110794, -1.2197198941393473e-08]
				Current Gradient = [3.200869989556677e-05, -7.614336356891645e-05]
				Next Gradient = [3.205116118203376e-05, 6.965621115366055e-05]
				|| Gradient || = 8.259763122870201e-05
				beta = 0.8617629678497934
				||X optimum - X|| = 6.41511119537047e-05
				alpha = 0.0006338253001141158
			Iteration 62:
				X = [4.000064024873405, -5.615527712011757e-08]
				Current Gradient = [3.205116118203376e-05, 6.965621115366055e-05]
				Next Gradient = [3.1900129936794325e-05, -0.00014195345446623347]
				|| Gradient || = 7.667636327708854e-05
				beta = 3.600518544002409
				||X optimum - X|| = 6.402489803121339e-05
				alpha = 0.0015474250491067279
			Iteration 63:
				X = [4.000063237556026, 3.976730976594059e-08]
				Current Gradient = [3.1900129936794325e-05, -0.00014195345446623347]
				Next Gradient = [3.169831453468717e-05, 0.0003176823729487081]
				|| Gradient || = 0.00014549364771316092
				beta = 4.815048179564101
				||X optimum - X|| = 6.323756853028217e-05
				alpha = 0.002417851639229262
			Iteration 64:
				X = [4.0000607622837485, -1.562243502810879e-07]
				Current Gradient = [3.169831453468717e-05, 0.0003176823729487081]
				Next Gradient = [3.0068722465473304e-05, -0.0006296248909395597]
				|| Gradient || = 0.0003192598835222835
				beta = 3.898202885884506
				||X optimum - X|| = 6.07624845803961e-05
				alpha = 0.0015474250491067279
			Iteration 65:
				X = [4.000041825481738, 2.544828235008358e-07]
				Current Gradient = [3.0068722465473304e-05, -0.0006296248909395597]
				Next Gradient = [2.1421784233372117e-05, 0.0013072299242735913]
				|| Gradient || = 0.0006303424714878081
				beta = 4.30197052748999
				||X optimum - X|| = 4.182625591765175e-05
				alpha = 0.0030223145490365774
			Iteration 66:
				X = [4.000024727336993, -2.0353724151665598e-07]
				Current Gradient = [2.1421784233372117e-05, 0.0013072299242735913]
				Next Gradient = [1.195664372840921e-05, -0.000929164462308565]
				|| Gradient || = 0.0013074054335806013
				beta = 0.5051687995763405
				||X optimum - X|| = 2.472817466330921e-05
				alpha = 0.0006338253001141158
			Iteration 67:
				X = [4.00001781131485, 8.250315668441079e-08]
				Current Gradient = [1.195664372840921e-05, -0.000929164462308565]
				Next Gradient = [9.070671907771263e-06, 0.0004323013338218265]
				|| Gradient || = 0.000929241389169904
				beta = 0.21652458711198128
				||X optimum - X|| = 1.7811505928621377e-05
				alpha = 0.0005070602400912927
			Iteration 68:
				X = [4.000016609644277, -4.3311274516908207e-08]
				Current Gradient = [9.070671907771263e-06, 0.0004323013338218265]
				Next Gradient = [8.218201841491685e-06, -0.00017502304584940623]
				|| Gradient || = 0.00043239648508398945
				beta = 0.16420358322869966
				||X optimum - X|| = 1.6609700745954376e-05
				alpha = 0.00040564819207303417
			Iteration 69:
				X = [4.000016408991964, 7.027327177881911e-09]
				Current Gradient = [8.218201841491685e-06, -0.00017502304584940623]
				Next Gradient = [8.218550696894143e-06, 6.66056497448883e-05]
				|| Gradient || = 0.000175215882327804
				beta = 0.1467025516889378
				||X optimum - X|| = 1.640899346907591e-05
				alpha = 0.00040564819207303417
			Iteration 70:
				X = [4.000016376221918, -1.2606332905902975e-08]
				Current Gradient = [8.218550696894143e-06, 6.66056497448883e-05]
				Next Gradient = [8.162898485152184e-06, -2.7859300241922753e-05]
				|| Gradient || = 6.711078269172664e-05
				beta = 0.18712261355675702
				||X optimum - X|| = 1.637622677022461e-05
				alpha = 0.00040564819207303417
			Iteration 71:
				X = [4.0000163644178155, -3.0723666721617216e-09]
				Current Gradient = [8.162898485152184e-06, -2.7859300241922753e-05]
				Next Gradient = [8.176064187051147e-06, 1.795677600577223e-05]
				|| Gradient || = 2.9030561855542806e-05
				beta = 0.46191986353674724
				||X optimum - X|| = 1.6364418103908823e-05
				alpha = 0.0005070602400912927
			Iteration 72:
				X = [4.000016345671123, -1.2254473646963896e-08]
				Current Gradient = [8.176064187051147e-06, 1.795677600577223e-05]
				Next Gradient = [8.148326795678526e-06, -2.62286477899922e-05]
				|| Gradient || = 1.9730530406257648e-05
				beta = 1.9377065242547333
				||X optimum - X|| = 1.6345675716932054e-05
				alpha = 0.0009903520314283058
			Iteration 73:
				X = [4.000016237284162, 7.724447322170016e-09]
				Current Gradient = [8.148326795678526e-06, -2.62286477899922e-05]
				Next Gradient = [8.134091048180141e-06, 6.961401206383053e-05]
				|| Gradient || = 2.746519969817506e-05
				beta = 6.512040170994869
				||X optimum - X|| = 1.6237285999016693e-05
				alpha = 0.002417851639229262
			Iteration 74:
				X = [4.000015103710295, -5.198307964302761e-08]
				Current Gradient = [8.134091048180141e-06, 6.961401206383053e-05]
				Next Gradient = [7.447892231952112e-06, -0.00021972911066940089]
				|| Gradient || = 7.008761739996036e-05
				beta = 9.839913666112801
				||X optimum - X|| = 1.5103799750813679e-05
				alpha = 0.0037778931862957215
			Iteration 75:
				X = [4.000009378318257, 7.222617448771232e-08]
				Current Gradient = [7.447892231952112e-06, -0.00021972911066940089]
				Next Gradient = [4.833617738373848e-06, 0.0003660217091176714]
				|| Gradient || = 0.00021985530053711372
				beta = 2.772142427104
				||X optimum - X|| = 9.378596374275856e-06
				alpha = 0.0019342813113834097
			Iteration 76:
				X = [4.000004174447986, -4.6938985605462505e-08]
				Current Gradient = [4.833617738373848e-06, 0.0003660217091176714]
				Next Gradient = [1.9933486662257095e-06, -0.0002173342170854832]
				|| Gradient || = 0.00036605362367535986
				beta = 0.35253588055774193
				||X optimum - X|| = 4.174711877420494e-06
				alpha = 0.0006338253001141158
			Iteration 77:
				X = [4.000002999526756, 1.433585005791101e-08]
				Current Gradient = [1.9933486662257095e-06, -0.0002173342170854832]
				Next Gradient = [1.528435324891298e-06, 7.492592379147239e-05]
				|| Gradient || = 0.00021734335820324733
				beta = 0.11889186836723238
				||X optimum - X|| = 2.9995610138393533e-06
				alpha = 0.00040564819207303417
			Iteration 78:
				X = [4.000002859218169, -8.772635771588101e-09]
				Current Gradient = [1.528435324891298e-06, 7.492592379147239e-05]
				Next Gradient = [1.4120639055372692e-06, -3.6460456651194526e-05]
				|| Gradient || = 7.49415116644167e-05
				beta = 0.23705560193539446
				||X optimum - X|| = 2.8592316269357116e-06
				alpha = 0.00040564819207303417
			Iteration 79:
				X = [4.0000028169259965, 2.867517109145459e-09]
				Current Gradient = [1.4120639055372692e-06, -3.6460456651194526e-05]
				Next Gradient = [1.4141980425215477e-06, 1.9420893639336982e-05]
				|| Gradient || = 3.648779006307393e-05
				beta = 0.28480005473195125
				||X optimum - X|| = 2.816927455970804e-06
				alpha = 0.0005070602400912927
			Iteration 80:
				X = [4.000002806716479, -2.3584403420773188e-09]
				Current Gradient = [1.4141980425215477e-06, 1.9420893639336982e-05]
				Next Gradient = [1.3986413655998838e-06, -5.725964094387834e-06]
				|| Gradient || = 1.9472315369619284e-05
				beta = 0.09162846432267505
				||X optimum - X|| = 2.8067174696673047e-06
				alpha = 0.00040564819207303417
			Iteration 81:
				X = [4.00000280521364, -5.145598151849696e-10]
				Current Gradient = [1.3986413655998838e-06, -5.725964094387834e-06]
				Next Gradient = [1.4015777010796731e-06, 3.136420224367807e-06]
				|| Gradient || = 5.894307633622951e-06
				beta = 0.3396827731984837
				||X optimum - X|| = 2.8052136872375174e-06
				alpha = 0.00040564819207303417
			Iteration 82:
				X = [4.000002802579275, -2.0915831129745852e-09]
				Current Gradient = [1.4015777010796731e-06, 3.136420224367807e-06]
				Next Gradient = [1.3971064768462962e-06, -4.451187125656815e-06]
				|| Gradient || = 3.43533868432025e-06
				beta = 1.8442467197508492
				||X optimum - X|| = 2.8025800557992724e-06
				alpha = 0.0009903520314283058
			Iteration 83:
				X = [4.000002790387779, 8.377570593742113e-10]
				Current Gradient = [1.3971064768462962e-06, -4.451187125656815e-06]
				Next Gradient = [1.3968694042959058e-06, 9.608717109481473e-06]
				|| Gradient || = 4.6652945603958225e-06
				beta = 4.3316703021165806
				||X optimum - X|| = 2.7903879043770255e-06
				alpha = 0.0019342813113834097
			Iteration 84:
				X = [4.000002734876297, -5.05926904250547e-09]
				Current Gradient = [1.3968694042959058e-06, 9.608717109481473e-06]
				Next Gradient = [1.3573196413895412e-06, -1.885524617022967e-05]
				|| Gradient || = 9.709721346295165e-06
				beta = 3.790492103459512
				||X optimum - X|| = 2.7348809765703305e-06
				alpha = 0.0019342813113834097
			Iteration 85:
				X = [4.000002564443281, 6.2357064899259694e-09]
				Current Gradient = [1.3573196413895412e-06, -1.885524617022967e-05]
				Next Gradient = [1.2946931000527911e-06, 3.5110201744214915e-05]
				|| Gradient || = 1.8904037260565863e-05
				beta = 3.4542014504462406
				||X optimum - X|| = 2.564450862207449e-06
				alpha = 0.0015474250491067279
			Iteration 86:
				X = [4.000001826051516, -1.2908399499210789e-08]
				Current Gradient = [1.2946931000527911e-06, 3.5110201744214915e-05]
				Next Gradient = [8.872091592644938e-07, -5.841153833137595e-05]
				|| Gradient || = 3.513406462029118e-05
				beta = 2.764653311488857
				||X optimum - X|| = 1.8260971405324337e-06
				alpha = 0.0019342813113834097
			Iteration 87:
				X = [4.000001156564134, 6.771252240904345e-09]
				Current Gradient = [8.872091592644938e-07, -5.841153833137595e-05]
				Next Gradient = [5.918246266744877e-07, 3.486932783745418e-05]
				|| Gradient || = 5.8418275824694494e-05
				beta = 0.3563811878664863
				||X optimum - X|| = 1.156583955651577e-06
				alpha = 0.0006338253001141158
			Iteration 88:
				X = [4.0000009653898765, -5.2988313730243705e-09]
				Current Gradient = [5.918246266744877e-07, 3.486932783745418e-05]
				Next Gradient = [4.7209730925370985e-07, -2.354601376608612e-05]
				|| Gradient || = 3.487434988963372e-05
				beta = 0.4560338691603618
				||X optimum - X|| = 9.654044184855687e-07
				alpha = 0.0005070602400912927
			Iteration 89:
				X = [4.000000856113229, 2.7447692043200235e-09]
				Current Gradient = [4.7209730925370985e-07, -2.354601376608612e-05]
				Next Gradient = [4.335461622864821e-07, 1.4909082432299094e-05]
				|| Gradient || = 2.3550746063386647e-05
				beta = 0.4011063893732797
				||X optimum - X|| = 8.561176291635671e-07
				alpha = 0.0006338253001141158
			Iteration 90:
				X = [4.000000820828146, -2.2339620452308793e-09]
				Current Gradient = [4.335461622864821e-07, 1.4909082432299094e-05]
				Next Gradient = [4.059461547623773e-07, -9.099237622266667e-06]
				|| Gradient || = 1.4915384716725305e-05
				beta = 0.3729105133516578
				||X optimum - X|| = 8.208311858623795e-07
				alpha = 0.0005070602400912927
			Iteration 91:
				X = [4.0000008074641284, 5.232783420534125e-10]
				Current Gradient = [4.059461547623773e-07, -9.099237622266667e-06]
				Next Gradient = [4.0477862122903435e-07, 4.130851540235868e-06]
				|| Gradient || = 9.108288400519578e-06
				beta = 0.20766139865314748
				||X optimum - X|| = 8.074642980050935e-07
				alpha = 0.0005070602400912927
			Iteration 92:
				X = [4.000000805079778, -6.943362007682541e-10]
				Current Gradient = [4.0477862122903435e-07, 4.130851540235868e-06]
				Next Gradient = [4.0115121730169083e-07, -1.7282102390089178e-06]
				|| Gradient || = 4.150636117473215e-06
				beta = 0.18270681982997136
				||X optimum - X|| = 8.05080077367611e-07
				alpha = 0.00040564819207303417
			Iteration 93:
				X = [4.000000804331824, -9.611260317025086e-11]
				Current Gradient = [4.0115121730169083e-07, -1.7282102390089178e-06]
				Next Gradient = [4.0197368687011483e-07, 1.146554067305882e-06]
				|| Gradient || = 1.774156962999015e-06
				beta = 0.46897751654058006
				||X optimum - X|| = 8.043318299980815e-07
				alpha = 0.0005070602400912927
			Iteration 94:
				X = [4.000000803465264, -5.661416086519474e-10]
				Current Gradient = [4.0197368687011483e-07, 1.146554067305882e-06]
				Next Gradient = [4.0060034933383556e-07, -1.115079418143885e-06]
				|| Gradient || = 1.21497698504606e-06
				beta = 0.9510311340340855
				||X optimum - X|| = 8.03465463557395e-07
				alpha = 0.0007922816251426447
			Iteration 95:
				X = [4.000000802038372, -2.0585714329471542e-11]
				Current Gradient = [4.0060034933383556e-07, -1.115079418143885e-06]
				Next Gradient = [4.009780144042424e-07, 1.5051005899191747e-06]
				|| Gradient || = 1.1848555813492615e-06
				beta = 1.728143718651604
				||X optimum - X|| = 8.020383719808465e-07
				alpha = 0.0009903520314283058
			Iteration 96:
				X = [4.000000797564958, -8.764926436789265e-10]
				Current Gradient = [4.009780144042424e-07, 1.5051005899191747e-06]
				Next Gradient = [3.970294947034921e-07, -2.619048392984778e-06]
				|| Gradient || = 1.5575978793676552e-06
				beta = 2.892302314112526
				||X optimum - X|| = 7.975654396925396e-07
				alpha = 0.0015474250491067279
			Iteration 97:
				X = [4.000000784012119, 7.00746852026065e-10]
				Current Gradient = [3.970294947034921e-07, -2.619048392984778e-06]
				Next Gradient = [3.934075538687443e-07, 4.937216422006901e-06]
				|| Gradient || = 2.6489709142345554e-06
				beta = 3.495897324782255
				||X optimum - X|| = 7.840124323882474e-07
				alpha = 0.0015474250491067279
			Iteration 98:
				X = [4.000000709030712, -2.621292258440465e-09]
				Current Gradient = [3.934075538687443e-07, 4.937216422006901e-06]
				Next Gradient = [3.4927277988791925e-07, -1.1185116213795415e-05]
				|| Gradient || = 4.952865382904689e-06
				beta = 5.104946873375075
				||X optimum - X|| = 7.09035557817469e-07
				alpha = 0.002417851639229262
			Iteration 99:
				X = [4.000000512616972, 2.5422883635316113e-09]
				Current Gradient = [3.4927277988791925e-07, -1.1185116213795415e-05]
				Next Gradient = [2.6139307054282875e-07, 1.3248559523209917e-05]
				|| Gradient || = 1.1190568179984415e-05
				beta = 1.4021745243500292
				||X optimum - X|| = 5.126232760943256e-07
				alpha = 0.0012379400392853823
			Iteration 100:
				X = [4.000000371443247, -2.1479803566375987e-09]
				Current Gradient = [2.6139307054282875e-07, 1.3248559523209917e-05]
				Next Gradient = [1.8142566812592088e-07, -9.584604975825876e-06]
				|| Gradient || = 1.3251137905001367e-05
				beta = 0.5233565573049883
				||X optimum - X|| = 3.7144945744084883e-07
				alpha = 0.0006338253001141158
			Iteration 101:
				X = [4.00000029744406, 1.4723018784174538e-09]
				Current Gradient = [1.8142566812592088e-07, -9.584604975825876e-06]
				Next Gradient = [1.5166663609684155e-07, 7.673716602233483e-06]
				|| Gradient || = 9.586321912792261e-06
				beta = 0.6410281649461315
				||X optimum - X|| = 2.974477034153041e-07
				alpha = 0.0006338253001141158
			Iteration 102:
				X = [4.000000249912366, -1.0707909722594366e-09]
				Current Gradient = [1.5166663609684155e-07, 7.673716602233483e-06]
				Next Gradient = [1.2281460254867522e-07, -4.648538903569709e-06]
				|| Gradient || = 7.675215258212548e-06
				beta = 0.367075036607743
				||X optimum - X|| = 2.499146603370598e-07
				alpha = 0.0006338253001141158
			Iteration 103:
				X = [4.0000002358919335, 5.394935592510474e-10]
				Current Gradient = [1.2281460254867522e-07, -4.648538903569709e-06]
				Next Gradient = [1.1902495425883326e-07, 3.0656692049491667e-06]
				|| Gradient || = 4.6501610041589165e-06
				beta = 0.43528004814312327
				||X optimum - X|| = 2.3589255046215575e-07
				alpha = 0.0005070602400912927
			Iteration 104:
				X = [4.000000228187974, -5.274492341264483e-10]
				Current Gradient = [1.1902495425883326e-07, 3.0656692049491667e-06]
				Next Gradient = [1.1303908910568315e-07, -2.0796002580974467e-06]
				|| Gradient || = 3.0679789135373752e-06
				beta = 0.4608252378423402
				||X optimum - X|| = 2.281885838840408e-07
				alpha = 0.0006338253001141158
			Iteration 105:
				X = [4.000000225290513, 1.336940388204729e-10]
				Current Gradient = [1.1303908910568315e-07, -2.0796002580974467e-06]
				Next Gradient = [1.1291264469076883e-07, 1.0933820377977017e-06]
				|| Gradient || = 2.0826701777153313e-06
				beta = 0.2785543166188782
				||X optimum - X|| = 2.252905530249484e-07
				alpha = 0.0005070602400912927
			Iteration 106:
				X = [4.000000224426159, -2.365522071938385e-10]
				Current Gradient = [1.1291264469076883e-07, 1.0933820377977017e-06]
				Next Gradient = [1.117399754911852e-07, -6.884908208396727e-07]
				|| Gradient || = 1.0991967730619112e-06
				beta = 0.402658438139086
				||X optimum - X|| = 2.2442628410087405e-07
				alpha = 0.0005070602400912927
