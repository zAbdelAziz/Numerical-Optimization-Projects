###################
# Exact Solutions #
###################
Running: Rosenbrock
===================
	- Starting Point : [1.2 1.2]
	------------------------------
		- Quasi Newton:
			- BFGS Method:
			---------------
			Iteration 0:
				X = [1.2, 1.2]
				Gradient = [115.6, -48.0]
				Hessian = [[0.15372342113220117, 0.3597772164432242], [0.3597772164432242, 0.84713108084427]]
				Gradient Difference = [-145.47317585488906, 61.8386839513994]
				|| Gradient || = 125.16932531574977
				||X optimum - X|| = 0.28284271247461895
				Rho = 0.05103584565976653
				alpha = [-0.11448469  0.0475369 ]
			Iteration 1:
				X = [1.0855153051668878, 1.2475368975085586]
				Gradient = [-29.873175854889084, 13.8386839513994]
				Hessian = [[0.05631567479098716, 0.12220565476346931], [0.12220565476346901, 0.26839713686823846]]
				Gradient Difference = [43.73307412018384, -21.773259356001475]
				|| Gradient || = 32.92287668421226
				||X optimum - X|| = 0.26189193008939504
				Rho = 0.4509821578204907
				alpha = [-0.19795784 -0.49945151]
			Iteration 2:
				X = [0.8875574689943044, 0.7480853837445653]
				Gradient = [13.85989826529476, -7.934575404602073]
				Hessian = [[0.03568631401245325, 0.07444478314546667], [0.07444478314546665, 0.1578239712327856]]
				Gradient Difference = [-14.768148330430641, 8.380042596358471]
				|| Gradient || = 15.970418490936199
				||X optimum - X|| = 0.2758700720667063
				Rho = 2.2722350487179046
				alpha = [0.09682968 0.22316   ]
			Iteration 3:
				X = [0.9843871441277491, 0.9712453854827678]
				Gradient = [-0.9082500651358819, 0.44546719175639904]
				Hessian = [[0.03337573294718183, 0.0686369605283245], [0.06863696052832453, 0.14587785902858316]]
				Gradient Difference = [0.4767037743939095, -0.24274019716628015]
				|| Gradient || = 1.0116121785302241
				||X optimum - X|| = 0.032719858259508065
				Rho = 3385.51944831742
				alpha = [-0.00075061 -0.00269092]
			Iteration 4:
				X = [0.9836365326652942, 0.9685544633667529]
				Gradient = [-0.4315462907419724, 0.2027269945901189]
				Hessian = [[0.039193418490077396, 0.07463883396906465], [0.07463883396906466, 0.14697079302062352]]
				Gradient Difference = [0.3608981859927446, -0.1829640668440824]
				|| Gradient || = 0.4767918155638759
				||X optimum - X|| = 0.03544834040356292
				Rho = 5959.34738077504
				alpha = [4.88609028e-04 4.66457857e-05]
			Iteration 5:
				X = [0.9841251416937373, 0.9686011091524488]
				Gradient = [-0.07064810474922786, 0.019762927746036496]
				Hessian = [[0.2842150950421033, 0.5442090028562453], [0.5442090028562451, 1.0450692285721621]]
				Gradient Difference = [0.07340520177833845, -0.03595862516996284]
				|| Gradient || = 0.07336026184354123
				||X optimum - X|| = 0.035183824020426656
				Rho = 101965.03670743662
				alpha = [0.00129386 0.00236852]
			Iteration 6:
				X = [0.9854190005459256, 0.9709696281498112]
				Gradient = [0.002757097029110589, -0.016195697423926347]
				Hessian = [[0.40963998564302295, 0.7994725520331357], [0.7994725520331375, 1.5629405170703967]]
				Gradient Difference = [0.20133678273528097, -0.09311809498437906]
				|| Gradient || = 0.01642870046824474
				||X optimum - X|| = 0.03248642847159334
				Rho = 5542.693102316117
				alpha = [0.00803024 0.01542519]
			Iteration 7:
				X = [0.993449236297393, 0.9863948161378319]
				Gradient = [0.20409387976439156, -0.10931379240830541]
				Hessian = [[0.45114498968933153, 0.8996744574332891], [0.8996744574332898, 1.7986642592016306]]
				Gradient Difference = [-0.04826076318391542, 0.02841134802749057]
				|| Gradient || = 0.23152498130432494
				||X optimum - X|| = 0.015100116986659192
				Rho = 28193.370965038004
				alpha = [0.00378836 0.0076835 ]
			Iteration 8:
				X = [0.9972375989099671, 0.9940783164578123]
				Gradient = [0.15583311658047613, -0.08090244438081484]
				Hessian = [[0.46407288857475926, 0.9277743974080753], [0.9277743974080788, 1.8597289746231902]]
				Gradient Difference = [-0.13849183656508768, 0.07194943060042647]
				|| Gradient || = 0.17558236167102637
				||X optimum - X|| = 0.006534309126145742
				Rho = 25797.584361450376
				alpha = [0.00248253 0.00531726]
			Iteration 9:
				X = [0.9997201318903483, 0.9993955770379533]
				Gradient = [0.017341280015388445, -0.008953013780388375]
				Hessian = [[0.47924467187722475, 0.9594386277841942], [0.9594386277841958, 1.9257105232308245]]
				Gradient Difference = [-0.017054792727955393, 0.008788657614378081]
				|| Gradient || = 0.01951605616726737
				||X optimum - X|| = 0.0006660730259132995
				Rho = 1920397.6834889695
				alpha = [0.00025876 0.00056138]
			Iteration 10:
				X = [0.9999788909471092, 0.9999569605589805]
				Gradient = [0.0002864872874330511, -0.00016435616601029324]
				Hessian = [[0.4976652196580388, 0.9958692333724811], [0.9958692333724792, 1.9976843981816406]]
				Gradient Difference = [-0.00029983953434506276, 0.00017031538916967293]
				|| Gradient || = 0.00033028459722843676
				||X optimum - X|| = 4.793730903183073e-05
				Rho = 1023769938.5099008
				alpha = [2.03921483e-05 4.16354285e-05]
			Iteration 11:
				X = [0.9999992830954312, 0.9999985959874921]
				Gradient = [-1.3352246912011667e-05, 5.95922315937969e-06]
				Hessian = [[0.49891172314973914, 0.9975489349569729], [0.9975489349569735, 1.9994798850809339]]
				Gradient Difference = [1.2716078125787135e-05, -5.647701439848163e-06]
				|| Gradient || = 1.4621724873030963e-05
				||X optimum - X|| = 1.576452753239506e-06
				Rho = 855687671970.846
				alpha = [7.10341893e-07 1.39244477e-06]
			Iteration 12:
				X = [0.9999999934373244, 0.9999999884322573]
				Gradient = [-6.361687862245309e-07, 3.1152171953152674e-07]
				Hessian = [[0.4966324493412312, 0.9931198012750364], [0.9931198012750406, 1.9909431569215474]]
				Gradient Difference = [6.291591009473504e-07, -3.0794564676028813e-07]
				|| Gradient || = 7.083477297953824e-07
				||X optimum - X|| = 1.329967598999978e-08
				Rho = 1778821171324910.2
				alpha = [6.63390581e-09 1.17280832e-08]
	- Starting Point : [-1.2  1. ]
	------------------------------
		- Quasi Newton:
			- BFGS Method:
			---------------
			Iteration 0:
				X = [-1.2, 1.0]
				Gradient = [-215.6, -87.99999999999999]
				Hessian = [[0.15791110530403546, -0.3637910601681758], [-0.3637910601681758, 0.8433174010615416]]
				Gradient Difference = [256.6136840849849, 110.80159741525932]
				|| Gradient || = 232.86768775422664
				||X optimum - X|| = 2.2
				Rho = 0.015516241978769408
				alpha = [0.2135199  0.08715098]
			Iteration 1:
				X = [-0.9864801020240572, 1.087150978765691]
				Gradient = [41.0136840849849, 22.801597415259334]
				Hessian = [[0.0224441822074563, -0.044690583098420264], [-0.04469058309841967, 0.09168262292575588]]
				Gradient Difference = [-71.63046369127115, -42.80053884721289]
				|| Gradient || = 46.9258471091413
				||X optimum - X|| = 1.9883909295803295
				Rho = 0.11007496818618459
				alpha = [ 0.30509386 -0.72285847]
			Iteration 2:
				X = [-0.6813862427069972, 0.36429250459059115]
				Gradient = [-30.616779606286247, -19.998941431953554]
				Hessian = [[0.01146847584542501, -0.02136282900145525], [-0.02136282900145526, 0.042278026197970456]]
				Gradient Difference = [21.654036236487226, 16.5762609308127]
				|| Gradient || = 36.56972589258243
				||X optimum - X|| = 1.797549364241232
				Rho = 0.6030275228487283
				alpha = [-0.10577704  0.23822012]
			Iteration 3:
				X = [-0.7871632789213407, 0.6025126251764923]
				Gradient = [-8.962743369799021, -3.422680501140851]
				Hessian = [[0.10993203633098991, -0.17093061733264792], [-0.17093061733264792, 0.2691527175896036]]
				Gradient Difference = [-0.020581040692647434, -0.18682073337279448]
				|| Gradient || = 9.594035153456865
				||X optimum - X|| = 1.8308328155975797
				Rho = 123.06049128430918
				alpha = [ 0.02967087 -0.04676538]
			Iteration 4:
				X = [-0.7574924113485446, 0.5557472470780644]
				Gradient = [-8.983324410491669, -3.6095012345136457]
				Hessian = [[0.050012137846266486, -0.0704862335291847], [-0.07048623352918466, 0.10220379710104538]]
				Gradient Difference = [-6.728135380433947, -7.465654125573639]
				|| Gradient || = 9.68135406986497
				||X optimum - X|| = 1.812771382283613
				Rho = 1.137226479795742
				alpha = [ 0.18973741 -0.28877728]
			Iteration 5:
				X = [-0.567755005299845, 0.26696996924259064]
				Gradient = [-15.711459790925616, -11.075155360087285]
				Hessian = [[0.05478332328928932, -0.06191939005702543], [-0.06191939005702543, 0.07498488772522525]]
				Gradient Difference = [6.935178983670953, 6.053264514388944]
				|| Gradient || = 19.222617798102906
				||X optimum - X|| = 1.7306613714516557
				Rho = 5.444131290107097
				alpha = [0.00511771 0.02448131]
			Iteration 6:
				X = [-0.5626372995531139, 0.29145127661992876]
				Gradient = [-8.776280807254663, -5.021890845698341]
				Hessian = [[0.07735067976383023, -0.07343869490375775], [-0.07343869490375775, 0.07583756133313514]]
				Gradient Difference = [1.325316027963419, -0.9167825635542632]
				|| Gradient || = 10.111502977989739
				||X optimum - X|| = 1.7157728938755785
				Rho = 2.645053086474287
				alpha = [ 0.16984141 -0.16685603]
			Iteration 7:
				X = [-0.3927958889102976, 0.12459524329856783]
				Gradient = [-7.450964779291244, -5.938673409252604]
				Hessian = [[0.0681148849517889, -0.04047656648383606], [-0.04047656648383606, 0.03472022166696001]]
				Gradient Difference = [1.3065524822234877, -1.2652529198517506]
				|| Gradient || = 9.528101490013768
				||X optimum - X|| = 1.6450574081839575
				Rho = 3.271340427628552
				alpha = [ 0.14020877 -0.09681462]
			Iteration 8:
				X = [-0.25258712297092345, 0.027780623045206634]
				Gradient = [-6.144412297067756, -7.2039263291043545]
				Hessian = [[0.18630534695401194, -0.0732295987567219], [-0.07322959875672189, 0.033974129961551865]]
				Gradient Difference = [4.567081334967428, 9.885837847846592]
				|| Gradient || = 9.468387245540837
				||X optimum - X|| = 1.5856181815175245
				Rho = 1.684249982242507
				alpha = [0.12693573 0.00141721]
			Iteration 9:
				X = [-0.12565138926444572, 0.029197829217796456]
				Gradient = [-1.577330962100328, 2.681911518742238]
				Hessian = [[0.06181415690446827, -0.013931031846122032], [-0.013931031846122032, 0.006103432341754694]]
				Gradient Difference = [0.2035447426380741, -10.628546003938226]
				|| Gradient || = 3.1113698523902045
				||X optimum - X|| = 1.4864548109338593
				Rho = 1.3292257984824758
				alpha = [ 0.16064856 -0.0677062 ]
			Iteration 10:
				X = [0.034997170252900306, -0.03850837050026945]
				Gradient = [-1.3737862194622539, -7.946634485195989]
				Hessian = [[0.03931043273150751, -0.0005294146531276038], [-0.0005294146531276038, 0.0047633523507241635]]
				Gradient Difference = [-0.5737812305994174, 6.100686243873876]
				|| Gradient || = 8.064507934033577
				||X optimum - X|| = 1.4176494972379579
				Rho = 5.156431035232345
				alpha = [-0.02578538  0.02936349]
			Iteration 11:
				X = [0.009211789093179473, -0.009144884148313343]
				Gradient = [-1.9475674500616713, -1.8459482413221127]
				Hessian = [[0.17986415376154824, 0.016823446148287884], [0.016823446148287884, 0.006845131557749901]]
				Gradient Difference = [0.40793623538254775, 0.13132514008273066]
				|| Gradient || = 2.683382917546417
				||X optimum - X|| = 1.4142258221637203
				Rho = 31.3950623279906
				alpha = [0.07558245 0.00776183]
			Iteration 12:
				X = [0.08479423628103136, -0.0013830529997135342]
				Gradient = [-1.5396312146791236, -1.714623101239382]
				Hessian = [[0.0722278638841279, 0.019895892759668583], [0.019895892759668583, 0.009232474952237252]]
				Gradient Difference = [3.9187765732865794, -6.357616165586122]
				|| Gradient || = 2.3044297898868753
				||X optimum - X|| = 1.3566022293876152
				Rho = 2.03672636829637
				alpha = [0.15655441 0.01927103]
			Iteration 13:
				X = [0.24134864777104678, 0.017887973446785284]
				Gradient = [2.379145358607456, -8.072239266825504]
				Hessian = [[0.06293879775020986, 0.029211540507817966], [0.029211540507817962, 0.018545155303750255]]
				Gradient Difference = [-3.194319431890169, 6.497789607624188]
				|| Gradient || = 8.41554391695884
				||X optimum - X|| = 1.2410060060045163
				Rho = 4.7041830079573
				alpha = [-0.01123618  0.02719153]
			Iteration 14:
				X = [0.23011246743213876, 0.04507949937170054]
				Gradient = [-0.8151740732827131, -1.5744496592013157]
				Hessian = [[0.18540574502181714, 0.10353878972210984], [0.10353878972210984, 0.0631835206605135]]
				Gradient Difference = [0.6627295776925275, -0.2470155875096247]
				|| Gradient || = 1.7729637613644191
				||X optimum - X|| = 1.2266213659168146
				Rho = 19.45984922831459
				alpha = [0.09729818 0.0530109 ]
			Iteration 15:
				X = [0.3274106435589736, 0.09809040328214655]
				Gradient = [-0.15244449559018558, -1.8214652467109405]
				Hessian = [[0.09756838170147758, 0.07171570243256589], [0.07171570243256585, 0.05676404330480447]]
				Gradient Difference = [3.788080754822829, -3.6054368471676588]
				|| Gradient || = 1.8278334084952856
				||X optimum - X|| = 1.1250854914403239
				Rho = 5.586355554284694
				alpha = [0.11103047 0.0670057 ]
			Iteration 16:
				X = [0.43844111649066436, 0.16509610216018733]
				Gradient = [3.635636259232643, -5.426902093878599]
				Hessian = [[0.15553946480598507, 0.1362846671457947], [0.1362846671457947, 0.12479434853005265]]
				Gradient Difference = [-2.5656760203311593, 3.181097577402414]
				|| Gradient || = 6.532160235786554
				||X optimum - X|| = 1.006187307749588
				Rho = 16.105531857871824
				alpha = [0.03447095 0.0473207 ]
			Iteration 17:
				X = [0.47291206591738816, 0.21241679950787115]
				Gradient = [1.069960238901484, -2.245804516476185]
				Hessian = [[0.1009097513668544, 0.10957407503166683], [0.10957407503166675, 0.12399823620801156]]
				Gradient Difference = [5.106022638274384, -3.427816266878742]
				|| Gradient || = 2.48766011324999
				||X optimum - X|| = 0.947686123119306
				Rho = 3.9652165445778316
				alpha = [0.13964768 0.13444454]
			Iteration 18:
				X = [0.6125597439974467, 0.34686133604944286]
				Gradient = [6.175982877175868, -5.673620783354927]
				Hessian = [[0.09943394157116434, 0.12160076087425059], [0.12160076087425059, 0.15370905643432958]]
				Gradient Difference = [-7.0276567307659255, 5.733948180677995]
				|| Gradient || = 8.386461547785602
				||X optimum - X|| = 0.7594077075711326
				Rho = 6.08240130372426
				alpha = [-0.00153515  0.02679136]
			Iteration 19:
				X = [0.611024596832237, 0.3736526949206131]
				Gradient = [-0.8516738535900574, 0.0603273973230678]
				Hessian = [[0.29283711372616794, 0.37518800438500133], [0.3751880043850019, 0.4845662751626697]]
				Gradient Difference = [1.8570558441740366, -1.2432845325674569]
				|| Gradient || = 0.853807793216198
				||X optimum - X|| = 0.7373010313635362
				Rho = 37.86262290097164
				alpha = [0.07734943 0.09429132]
			Iteration 20:
				X = [0.6883740276117508, 0.4679440162142015]
				Gradient = [1.0053819905839791, -1.182957135244389]
				Hessian = [[0.12487881804202414, 0.17495226376966075], [0.17495226376965956, 0.24825556779278027]]
				Gradient Difference = [3.643647912215438, -2.16351783749138]
				|| Gradient || = 1.552475613597913
				||X optimum - X|| = 0.6165989916868141
				Rho = 16.229019925859387
				alpha = [0.0765021 0.1003591]
			Iteration 21:
				X = [0.7648761288753456, 0.5683031176596555]
				Gradient = [4.649029902799417, -3.346474972735769]
				Hessian = [[0.1416622004159648, 0.21752433806332125], [0.21752433806332122, 0.3390096181170537]]
				Gradient Difference = [-3.0027876561039073, 1.9781212686432292]
				|| Gradient || = 5.728208601322932
				||X optimum - X|| = 0.4915744429839862
				Rho = 50.69305126323949
				alpha = [0.00490801 0.01742274]
			Iteration 22:
				X = [0.7697841417003646, 0.5857258562929043]
				Gradient = [1.6462422466955098, -1.3683537040925398]
				Hessian = [[0.23867284062832245, 0.3808720644064826], [0.38087206440648247, 0.6138840400372537]]
				Gradient Difference = [-0.5040065986978157, 0.4850253891135692]
				|| Gradient || = 2.1406787228140645
				||X optimum - X|| = 0.47394346451542635
				Rho = 53.10285355253347
				alpha = [0.06443993 0.10578731]
			Iteration 23:
				X = [0.8342240763349805, 0.6915131679620565]
				Gradient = [1.142235647997694, -0.8833283149789706]
				Hessian = [[0.23517533360513404, 0.4114460752550699], [0.41144607525506954, 0.7264923349518336]]
				Gradient Difference = [1.4357942162592021, -0.6655767260074441]
				|| Gradient || = 1.443942930866833
				||X optimum - X|| = 0.35020819865873604
				Rho = 49.34792591640649
				alpha = [0.06381445 0.10721551]
			Iteration 24:
				X = [0.8980385284351785, 0.7987286733490888]
				Gradient = [2.578029864256896, -1.5489050409864147]
				Hessian = [[0.37176434006803755, 0.6732134130828564], [0.6732134130828571, 1.2244137204108003]]
				Gradient Difference = [-2.7794031583342966, 1.5809026186117014]
				|| Gradient || = 3.007547972517406
				||X optimum - X|| = 0.22562421992215662
				Rho = 62.98648969581469
				alpha = [0.03100187 0.06454737]
			Iteration 25:
				X = [0.9290403951212179, 0.8632760436551152]
				Gradient = [-0.20137329407740062, 0.031997577625286766]
				Hessian = [[0.31669108548654923, 0.5946715070593325], [0.5946715070593317, 1.1204192679416614]]
				Gradient Difference = [1.6256900962717238, -0.794024577566832]
				|| Gradient || = 0.203899604073842
				||X optimum - X|| = 0.1540412469540247
				Rho = 123.15013938284665
				alpha = [0.04265777 0.07711114]
			Iteration 26:
				X = [0.971698164190425, 0.9403871872913344]
				Gradient = [1.424316802194323, -0.7620269999415452]
				Hessian = [[0.34939463659784664, 0.6795861040056895], [0.6795861040056896, 1.326823001865246]]
				Gradient Difference = [-1.055350346023289, 0.545657215116635]
				|| Gradient || = 1.6153524388358642
				||X optimum - X|| = 0.06599000946530152
				Rho = 665.9184173034987
				alpha = [0.00208731 0.00678911]
			Iteration 27:
				X = [0.9737854745019148, 0.9471763014267948]
				Gradient = [0.3689664561710343, -0.2163697848249102]
				Hessian = [[0.44171686850154596, 0.8667376026658944], [0.8667376026658914, 1.7061617641855316]]
				Gradient Difference = [-0.23670333106260572, 0.14154555197161134]
				|| Gradient || = 0.4277290375513331
				||X optimum - X|| = 0.058970708644568666
				Rho = 1172.2852207123399
				alpha = [0.018127   0.03633993]
			Iteration 28:
				X = [0.9919124727249511, 0.9835162323830603]
				Gradient = [0.13226312510842858, -0.07482423285329887]
				Hessian = [[0.4899284448309344, 0.9707095511832722], [0.970709551183273, 1.9295580855849306]]
				Gradient Difference = [-0.07692154000344249, 0.04544734640508086]
				|| Gradient || = 0.15196117953455257
				||X optimum - X|| = 0.01836090118360017
				Rho = 10274.470842664745
				alpha = [0.00643012 0.01302482]
			Iteration 29:
				X = [0.9983425954884108, 0.9965410535342955]
				Gradient = [0.05534158510498609, -0.02937688644821801]
				Hessian = [[0.571897313316779, 1.1357487279193785], [1.135748727919397, 2.2610503013079266]]
				Gradient Difference = [-0.061283519491438246, 0.03209414792730847]
				|| Gradient || = 0.06265534693323399
				||X optimum - X|| = 0.003835531301872841
				Rho = 109415.06157803758
				alpha = [0.00140301 0.0029638 ]
			Iteration 30:
				X = [0.9997456030227577, 0.9995048570707329]
				Gradient = [-0.0059419343864521605, 0.0027172614790904603]
				Hessian = [[0.4990320528998484, 0.9977470503940318], [0.9977470503940229, 1.9998248427264955]]
				Gradient Difference = [0.008366513777625411, -0.0038718315441998996]
				|| Gradient || = 0.006533765698175248
				||X optimum - X|| = 0.0005566725630325457
				Rho = 3709836.0759416274
				alpha = [0.00031205 0.00060468]
			Iteration 31:
				X = [1.000057653065973, 1.0001095366054966]
				Gradient = [0.0024245793911732497, -0.0011545700651094393]
				Hessian = [[0.49694621291245544, 0.9936430213631808], [0.9936430213631751, 1.9917592765846632]]
				Gradient Difference = [-0.0024249589482065966, 0.0011544389554973833]
				|| Gradient || = 0.002685445448961654
				||X optimum - X|| = 0.00012378264805623938
				Rho = 74685465.14106835
				alpha = [-5.79739541e-05 -1.10179037e-04]
			Iteration 32:
				X = [0.9999996791119133, 0.9999993575683815]
				Gradient = [-3.7955703334679935e-07, -1.311096120559796e-07]
				Hessian = [[0.49999931214509796, 1.000002656161944], [1.000002656161944, 2.0049861933179076]]
				Gradient Difference = [4.4102180160247837e-07, 9.838472259104947e-08]
				|| Gradient || = 4.01563534121928e-07
				||X optimum - X|| = 7.181138827191322e-07
				Rho = 4915521888118.977
				alpha = [3.18895581e-07 6.38282983e-07]
	- Starting Point : [0.2 0.8]
	------------------------------
		- Quasi Newton:
			- BFGS Method:
			---------------
			Iteration 0:
				X = [0.2, 0.8]
				Gradient = [-62.4, 152.0]
				Hessian = [[0.801123002660532, 0.4045814546033023], [0.4045814546033023, 0.20901796343078857]]
				Gradient Difference = [93.54400635036379, -184.50074448656886]
				|| Gradient || = 164.3099510072351
				||X optimum - X|| = 0.8246211251235323
				Rho = 0.006250010834151434
				alpha = [ 0.29467567 -0.71779971]
			Iteration 1:
				X = [0.49467566853106626, 0.08220029460381295]
				Gradient = [31.14400635036378, -32.50074448656888]
				Hessian = [[0.017707117054115203, 0.012133154235245174], [0.01213315423524515, 0.0124844778237906]]
				Gradient Difference = [-23.439018020027337, 12.305370523709975]
				|| Gradient || = 45.01385924060207
				||X optimum - X|| = 1.0477160775705663
				Rho = 0.2164751972535752
				alpha = [-0.26573448 -0.1307631 ]
			Iteration 2:
				X = [0.2289411913029395, -0.048562800739085366]
				Gradient = [7.704988330336445, -20.195373962858902]
				Hessian = [[0.01963764884856768, 0.014193777458913292], [0.01419377745891329, 0.01438517134569446]]
				Gradient Difference = [-8.50951324101235, 19.424518283542884]
				|| Gradient || = 21.61527179265484
				||X optimum - X|| = 1.3015435580736916
				Rho = 0.46351561403462366
				alpha = [0.10860046 0.15864289]
			Iteration 3:
				X = [0.337541648166902, 0.11008008585064857]
				Gradient = [-0.8045249106759047, -0.7708556793160182]
				Hessian = [[0.22569395515884244, 0.17160360596900448], [0.17160360596900448, 0.13338549370776479]]
				Gradient Difference = [-0.45042570936896653, 0.7482283998555994]
				|| Gradient || = 1.1142166801084215
				||X optimum - X|| = 1.1094181004080534
				Rho = 208.4768498886716
				alpha = [0.02674033 0.02250814]
			Iteration 4:
				X = [0.3642819798178317, 0.13258822442269708]
				Gradient = [-1.2549506200448712, -0.02262727946041876]
				Hessian = [[0.09969879673386772, 0.08304740498568502], [0.0830474049856849, 0.07156307519149874]]
				Gradient Difference = [6.488703425459086, -5.5770628987506505]
				|| Gradient || = 1.2551545930787915
				||X optimum - X|| = 1.0754257713085107
				Rho = 2.421932246788134
				alpha = [0.18375532 0.13975821]
			Iteration 5:
				X = [0.5480373025158445, 0.2723464340577879]
				Gradient = [5.233752805414214, -5.59969017821107]
				Hessian = [[0.04577957068196929, 0.04165317192103723], [0.04165317192103723, 0.04134486189355543]]
				Gradient Difference = [-4.735616975494527, 4.114625822850954]
				|| Gradient || = 7.664769958722485
				||X optimum - X|| = 0.856592080249153
				Rho = 9.672875043232109
				alpha = [-0.0454073  -0.02713483]
			Iteration 6:
				X = [0.5026300072534091, 0.2452116024147615]
				Gradient = [0.4981358299196872, -1.4850643553601162]
				Hessian = [[0.2001172539906417, 0.20888028670384565], [0.20888028670384565, 0.22225771100754144]]
				Gradient Difference = [0.222900859686729, -0.026585139113416423]
				|| Gradient || = 1.566382917619741
				||X optimum - X|| = 0.9039261224314938
				Rho = 131.15987873782615
				alpha = [0.0390532  0.04065084]
			Iteration 7:
				X = [0.5416832037259987, 0.2858624457264941]
				Gradient = [0.7210366896064162, -1.5116494944735326]
				Hessian = [[0.1001204778475161, 0.11811151362054265], [0.11811151362054287, 0.1428710080482741]]
				Gradient Difference = [5.8830813667917194, -3.825599942356206]
				|| Gradient || = 1.674806884957387
				||X optimum - X|| = 0.848555674172655
				Rho = 4.172363231010469
				alpha = [0.13716952 0.14829232]
			Iteration 8:
				X = [0.6788527216866516, 0.43415477055722573]
				Gradient = [6.604118056398136, -5.3372494368297385]
				Hessian = [[0.07038134034416636, 0.09050861938682207], [0.09050861938682206, 0.12112245303538255]]
				Gradient Difference = [-6.457849643098955, 4.681269811419186]
				|| Gradient || = 8.491207620461488
				||X optimum - X|| = 0.6506276954228256
				Rho = 8.53515933763936
				alpha = [-0.03081685 -0.01748417]
			Iteration 9:
				X = [0.6480358756730101, 0.4166705980322323]
				Gradient = [0.14626841329918083, -0.6559796254105521]
				Hessian = [[0.3056109865702364, 0.4110905711924468], [0.4110905711924468, 0.5579827453003126]]
				Gradient Difference = [0.10702240569232835, 0.03982095776983163]
				|| Gradient || = 0.6720890697540232
				||X optimum - X|| = 0.6812869703827736
				Rho = 126.75682308951973
				alpha = [0.04907724 0.06621531]
			Iteration 10:
				X = [0.6971131189367931, 0.4828859072555798]
				Gradient = [0.2532908189915092, -0.6161586676407205]
				Hessian = [[0.162302944433185, 0.23597192261973127], [0.23597192261973005, 0.346829767980648]]
				Gradient Difference = [3.7390315053316594, -2.1900947934634263]
				|| Gradient || = 0.6661889692078197
				||X optimum - X|| = 0.5992891185688942
				Rho = 14.715023546648307
				alpha = [0.09005494 0.12271638]
			Iteration 11:
				X = [0.7871680624475375, 0.6056022912318895]
				Gradient = [3.9923223243231685, -2.8062534611041468]
				Hessian = [[0.229237502475483, 0.36126313941584437], [0.36126313941584465, 0.5744312339699578]]
				Gradient Difference = [-2.6512962347058595, 1.721758506509774]
				|| Gradient || = 4.879927871316148
				||X optimum - X|| = 0.44815955453819195
				Rho = 62.44019835223983
				alpha = [0.01423136 0.03121626]
			Iteration 12:
				X = [0.801399418658571, 0.6368185534533237]
				Gradient = [1.3410260896173092, -1.0844949545943727]
				Hessian = [[0.20441446852103362, 0.3459350016260857], [0.345935001626086, 0.590997347679873]]
				Gradient Difference = [1.7158733302878872, -0.7700138845998072]
				|| Gradient || = 1.7246681650610187
				||X optimum - X|| = 0.41393592985495936
				Rho = 26.22901300486169
				alpha = [0.08437458 0.13850448]
			Iteration 13:
				X = [0.8857739990976425, 0.7753230332814596]
				Gradient = [3.0568994199051964, -1.85450883919418]
				Hessian = [[0.2835535849517219, 0.5058669370554237], [0.5058669370554234, 0.9075197211616034]]
				Gradient Difference = [-3.0527984712999614, 1.7441286118994315]
				|| Gradient || = 3.5754492162616534
				||X optimum - X|| = 0.25204626292803767
				Rho = 61.30806680889541
				alpha = [0.01666505 0.0385213 ]
			Iteration 14:
				X = [0.9024390471576949, 0.8138443326984145]
				Gradient = [0.004100948605234939, -0.1103802272947485]
				Hessian = [[0.32418784536059825, 0.5991426474622995], [0.5991426474622985, 1.1114223897115607]]
				Gradient Difference = [1.4893712238999752, -0.7146231052276963]
				|| Gradient || = 0.11045638214744823
				||X optimum - X|| = 0.21017152991781993
				Rho = 88.27454388592002
				alpha = [0.05467487 0.0980977 ]
			Iteration 15:
				X = [0.9571139159720536, 0.9119420314847472]
				Gradient = [1.4934721725052102, -0.8250033325224448]
				Hessian = [[0.45812220570693585, 0.87329830428357], [0.8732983042835649, 1.6700785997654906]]
				Gradient Difference = [-0.9814169296083649, 0.5264387224359846]
				|| Gradient || = 1.7061915568659258
				||X optimum - X|| = 0.09794601585713088
				Rho = 586.1094284134294
				alpha = [0.01012916 0.0221243 ]
			Iteration 16:
				X = [0.9672430710742953, 0.934066335490802]
				Gradient = [0.5120552428968453, -0.2985646100864603]
				Hessian = [[0.3908381574311072, 0.7652370682108781], [0.7652370682108781, 1.5053089584172756]]
				Gradient Difference = [-0.001459296200473359, 0.03492047123188069]
				|| Gradient || = 0.5927405825268145
				||X optimum - X|| = 0.07362244568238105
				Rho = 568.6751052871857
				alpha = [0.02615209 0.05144939]
			Iteration 17:
				X = [0.9933951614621828, 0.9855157261222033]
				Gradient = [0.510595946696372, -0.2636441388545796]
				Hessian = [[0.4254162479517665, 0.846614694316263], [0.8466146943162626, 1.6898288166640147]]
				Gradient Difference = [-0.7046335134928559, 0.35665862686746763]
				|| Gradient || = 0.5746446316943518
				||X optimum - X|| = 0.01591911058689084
				Rho = 1546.9426373525544
				alpha = [0.00218989 0.00613894]
			Iteration 18:
				X = [0.995585050331641, 0.9916546648839206]
				Gradient = [-0.19403756679648385, 0.09301448801288803]
				Hessian = [[0.4718678997115019, 0.9374894152695867], [0.9374894152695963, 1.8672459648286495]]
				Gradient Difference = [0.19997157558070272, -0.09659934779422397]
				|| Gradient || = 0.21517962800553314
				||X optimum - X|| = 0.009441207484946547
				Rho = 13470.614774945032
				alpha = [0.0037993  0.00709649]
			Iteration 19:
				X = [0.9993843516238765, 0.9987511579717694]
				Gradient = [0.005934008784218872, -0.003584859781335936]
				Hessian = [[0.49855408455797895, 0.9968564995665278], [0.9968564995665269, 1.9981619708866065]]
				Gradient Difference = [-0.00276271169861807, 0.0019441725473967608]
				|| Gradient || = 0.006932797408191493
				||X optimum - X|| = 0.0013923467005378506
				Rho = 1540095.2670048878
				alpha = [0.0005607  0.00113074]
			Iteration 20:
				X = [0.9999450514622257, 0.9998819025076234]
				Gradient = [0.0031712970856008025, -0.0016406872339391754]
				Hessian = [[0.49950187691514936, 0.998981661712977], [0.9989816617129871, 2.002918763560234]]
				Gradient Difference = [-0.0031310901493262246, 0.001620101835642096]
				|| Gradient || = 0.003570571355504764
				||X optimum - X|| = 0.00013025497882679872
				Rho = 52460934.59081859
				alpha = [5.44666175e-05 1.17030725e-04]
			Iteration 21:
				X = [0.9999995180797607, 0.9999989332327622]
				Gradient = [4.020693627457805e-05, -2.0585398297079394e-05]
				Hessian = [[0.4997948878056877, 0.9995988816743697], [0.9995988816743739, 2.00421553852443]]
				Gradient Difference = [-4.019726859437677e-05, 2.057963948143282e-05]
				|| Gradient || = 4.517030382493989e-05
				||X optimum - X|| = 1.170572277389174e-06
				Rho = 387548011220.39215
				alpha = [4.80995264e-07 1.06488849e-06]
			Iteration 22:
				X = [0.9999999990750245, 0.9999999981212548]
				Gradient = [9.667680201279789e-09, -5.758815646572657e-09]
				Hessian = [[0.49999010273487465, 0.9999833740500343], [0.9999833740500349, 2.0049720888379903]]
				Gradient Difference = [-9.674018464527372e-09, 5.761657817515697e-09]
				|| Gradient || = 1.1252910651268288e-08
				||X optimum - X|| = 2.0941019853046453e-09
				Rho = 5.330677622712992e+17
				alpha = [9.24648539e-10 1.87810548e-09]
Running: Quadratic
===================
	- Starting Point : [-0.2  1.2]
	------------------------------
		- Quasi Newton:
			- BFGS Method:
			---------------
			Iteration 0:
				X = [-0.2, 1.2]
				Gradient = [-172.64999999999998, 15.000000000000002]
				Hessian = [[0.012677616023947902, 0.10673478364544611], [0.10673478364544611, 0.9889061652614837]]
				Gradient Difference = [119.28306378517306, -12.886496896987111]
				|| Gradient || = 173.30038228463314
				||X optimum - X|| = 4.368065933568311
				Rho = 0.060718043544065244
				alpha = [ 0.13678742 -0.01188422]
			Iteration 1:
				X = [-0.06321257741912242, 1.1881157756228602]
				Gradient = [-53.36693621482692, 2.1135031030128903]
				Hessian = [[0.0031459424415952483, 0.036719189356943904], [0.036719189356943904, 0.47863418742905545]]
				Gradient Difference = [1.4210854715202004e-14, -8.881784197001252e-16]
				|| Gradient || = 53.40877059363799
				||X optimum - X|| = 4.233357479067986
				Rho = 1.1631807638811868e+31
				alpha = [1.20933394e-17 9.66985090e-17]
			Iteration 2:
				X = [-0.06321257741912241, 1.1881157756228602]
				Gradient = [-53.36693621482691, 2.1135031030128895]
				Hessian = [[0.004538573248703123, 0.02591047311223644], [0.025910473112236453, 0.09810102999251835]]
				Gradient Difference = [7.105427357601002e-15, -8.881784197001252e-16]
				|| Gradient || = 53.408770593637975
				||X optimum - X|| = 4.233357479067986
				Rho = -4.87598208411191e+31
				alpha = [9.23537946e-18 9.69737667e-17]
			Iteration 3:
				X = [-0.0632125774191224, 1.1881157756228602]
				Gradient = [-53.3669362148269, 2.1135031030128886]
				Hessian = [[0.0010794391935303506, 0.00676881798624962], [0.00676881798624962, -0.005943267354432083]]
				Gradient Difference = [1.4210854715202004e-14, 0.0]
				|| Gradient || = 53.40877059363797
				||X optimum - X|| = 4.233357479067986
				Rho = 4.587345157392872e+30
				alpha = [1.53397536e-17 9.61906890e-17]
			Iteration 4:
				X = [-0.06321257741912238, 1.1881157756228602]
				Gradient = [-53.366936214826886, 2.1135031030128886]
				Hessian = [[0.0008720460147750011, 0.001777425718197766], [0.001777425718197766, -0.07666486648451006]]
				Gradient Difference = [1.4210854715202004e-14, -8.881784197001252e-16]
				|| Gradient || = 53.40877059363795
				||X optimum - X|| = 4.233357479067986
				Rho = 1.413191043037107e+31
				alpha = [1.08138481e-17 9.33508186e-17]
			Iteration 5:
				X = [-0.06321257741912237, 1.1881157756228602]
				Gradient = [-53.36693621482687, 2.1135031030128877]
				Hessian = [[0.00466326776223406, 0.023244536174170494], [0.023244536174170494, 0.04444465264863634]]
				Gradient Difference = [3.552713678800501e-14, -1.7763568394002505e-15]
				|| Gradient || = 53.40877059363794
				||X optimum - X|| = 4.233357479067986
				Rho = 3.2339005236900045e+29
				alpha = [1.24381961e-16 7.46862254e-16]
			Iteration 6:
				X = [-0.06321257741912224, 1.1881157756228609]
				Gradient = [-53.366936214826836, 2.113503103012886]
				Hessian = [[0.0016311356210912194, 0.004541488760311471], [0.004541488760311468, -0.07036571108003964]]
				Gradient Difference = [3.552713678800501e-14, -1.7763568394002505e-15]
				|| Gradient || = 53.408770593637904
				||X optimum - X|| = 4.233357479067987
				Rho = 7.914328392549314e+29
				alpha = [4.98822737e-17 2.86340705e-16]
			Iteration 7:
				X = [-0.06321257741912219, 1.188115775622861]
				Gradient = [-53.3669362148268, 2.113503103012884]
				Hessian = [[0.003355008523728031, 0.010124880957060803], [0.010124880957060803, -0.05793326801866894]]
				Gradient Difference = [7.105427357601002e-15, -4.440892098500626e-16]
				|| Gradient || = 53.40877059363787
				||X optimum - X|| = 4.233357479067987
				Rho = 1.0631247400057339e+31
				alpha = [1.93424190e-17 9.76691454e-17]
			Iteration 8:
				X = [-0.06321257741912217, 1.188115775622861]
				Gradient = [-53.366936214826794, 2.1135031030128837]
				Hessian = [[0.0021204208329634847, 0.004973495975762492], [0.004973495975762493, -0.07942647149519552]]
				Gradient Difference = [4.502060522152547, -0.1768367241175013]
				|| Gradient || = 53.40877059363786
				||X optimum - X|| = 4.233357479067987
				Rho = 30.698392904631998
				alpha = [0.00866677 0.0364365 ]
			Iteration 9:
				X = [-0.05454581123245286, 1.2245522725398483]
				Gradient = [-48.86487569267425, 1.9366663788953824]
				Hessian = [[0.0019071196497798268, 0.0049848399979257755], [0.004984839997925775, -0.07552737518617622]]
				Gradient Difference = [0.6196075298003336, -0.01968485993854885]
				|| Gradient || = 48.903238677245604
				||X optimum - X|| = 4.235430320943214
				Rho = 1720.271724547636
				alpha = [0.00108354 0.00457539]
			Iteration 10:
				X = [-0.05346227141439435, 1.2291276627394792]
				Gradient = [-48.24526816287391, 1.9169815189568336]
				Hessian = [[0.0018302452775043193, 0.005869193605554566], [0.005869193605554566, -0.06558430233093578]]
				Gradient Difference = [9.237055564881302e-14, -2.6645352591003757e-15]
				|| Gradient || = 48.283337894677885
				||X optimum - X|| = 4.235718498329576
				Rho = 8.155609253101026e+28
				alpha = [1.53422100e-16 7.16892361e-16]
			Iteration 11:
				X = [-0.0534622714143942, 1.2291276627394798]
				Gradient = [-48.24526816287382, 1.9169815189568309]
				Hessian = [[0.0009027063328614579, 0.004790461156900972], [0.004790461156900972, -0.050912245407810794]]
				Gradient Difference = [2.1316282072803006e-14, 0.0]
				|| Gradient || = 48.28333789467779
				||X optimum - X|| = 4.235718498329576
				Rho = 2.4379825552865174e+30
				alpha = [1.92423428e-17 1.02114821e-16]
			Iteration 12:
				X = [-0.05346227141439418, 1.2291276627394798]
				Gradient = [-48.2452681628738, 1.9169815189568309]
				Hessian = [[0.0009576916222314451, 0.0064869060703429265], [0.006486906070342927, -0.023490892170319688]]
				Gradient Difference = [1.4210854715202004e-14, -4.440892098500626e-16]
				|| Gradient || = 48.28333789467777
				||X optimum - X|| = 0.23528217165191917
				Rho = 9.354952124946182e+30
				alpha = [1.07288515e-17 1.02616531e-16]
			Iteration 13:
				X = [-0.053462271414394164, 1.2291276627394798]
				Gradient = [-48.245268162873785, 1.9169815189568304]
				Hessian = [[nan, nan], [nan, nan]]
				Gradient Difference = [0.0, 0.0]
				|| Gradient || = 48.28333789467776
				||X optimum - X|| = 0.23528217165191917
				Rho = inf
				alpha = [2.57367514e-17 2.72843665e-16]
			Iteration 14:
				X = [-0.053462271414394136, 1.22912766273948]
				Gradient = [-48.245268162873785, 1.9169815189568304]
				Hessian = [[nan, nan], [nan, nan]]
				Gradient Difference = [nan, nan]
				|| Gradient || = 48.28333789467776
				||X optimum - X|| = 0.23528217165191917
				Rho = nan
				alpha = [nan nan]
			Iteration 15:
				X = [nan, nan]
				Gradient = [nan, nan]
				Hessian = [[nan, nan], [nan, nan]]
				Gradient Difference = [nan, nan]
				|| Gradient || = nan
				||X optimum - X|| = nan
				Rho = nan
				alpha = [nan nan]
	- Starting Point : [3.8 0.1]
	------------------------------
		- Quasi Newton:
			- BFGS Method:
			---------------
			Iteration 0:
				X = [3.8, 0.1]
				Gradient = [22.850000000000005, 433.40000000000003]
				Hessian = [[0.9979075930290758, -0.04614251503645012], [-0.04614251503645012, 0.0023648629657295013]]
				Gradient Difference = [-22.55733396534444, -487.7107939515628]
				|| Gradient || = 434.0019383597267
				||X optimum - X|| = 0.22360679774997913
				Rho = 0.018178643342339533
				alpha = [-0.0059322  -0.11251707]
			Iteration 1:
				X = [3.794067800839124, -0.012517072924449937]
				Gradient = [0.29266603465556496, -54.310793951562715]
				Hessian = [[0.15994125608692739, -0.003704541425363375], [-0.0037045414253633747, 0.00021563983603214605]]
				Gradient Difference = [-0.4009839216686126, 63.78894372372751]
				|| Gradient || = 54.311582494500584
				||X optimum - X|| = 0.2063122579146249
				Rho = 0.9151864520414983
				alpha = [-0.30044266  0.0152409 ]
			Iteration 2:
				X = [3.4936251442320625, 0.0027238259895244928]
				Gradient = [-0.10831788701304762, 9.478149772164794]
				Hessian = [[0.2306517118612377, -0.006027941659101554], [-0.006027941659101554, 0.00027856994489655704]]
				Gradient Difference = [-0.004722710337582592, -8.879647750986646]
				|| Gradient || = 9.478768689457217
				||X optimum - X|| = 0.5063821815408011
				Rho = 46.589004528759794
				alpha = [ 0.0524367  -0.00244513]
			Iteration 3:
				X = [3.546061841604394, 0.00027869122721908965]
				Gradient = [-0.11304059735063021, 0.5985020211781487]
				Hessian = [[0.42952455053108407, -0.008297860903347406], [-0.008297860903347406, 0.0002459101624677859]]
				Gradient Difference = [0.007102483281485772, -3.2092670540402235]
				|| Gradient || = 0.6090836116689697
				||X optimum - X|| = 0.4539382439455772
				Rho = 340.98592380909923
				alpha = [ 0.02968074 -0.00084813]
			Iteration 4:
				X = [3.57574258415965, -0.0005694355737805738]
				Gradient = [-0.10593811406914444, -2.610765032862075]
				Hessian = [[1.9557326513742483, -0.012137233151178864], [-0.012137233151178864, 0.000171362270916057]]
				Gradient Difference = [0.006431820548000039, -0.9277513368893366]
				|| Gradient || = 2.6129134966217
				||X optimum - X|| = 0.42425779798655955
				Rho = 2679.172085195451
				alpha = [ 0.02383926 -0.00023705]
			Iteration 5:
				X = [3.599581839895297, -0.0008064816552929579]
				Gradient = [-0.0995062935211444, -3.5385163697514117]
				Hessian = [[3.2675070530034667, -0.007427521283374004], [-0.007427521283374004, 0.0001133874585725258]]
				Gradient Difference = [0.04036992198363494, -2.6591514858503573]
				|| Gradient || = 3.5399151969290203
				||X optimum - X|| = 0.40041897227066536
				Rho = 129.50660813812038
				alpha = [ 0.15165991 -0.00060136]
			Iteration 6:
				X = [3.751241748962893, -0.0014078445389744823]
				Gradient = [-0.05913637153750946, -6.197667855601769]
				Hessian = [[4.03670700767139, 0.003693965832593795], [0.0036939658325937956, 0.00015074066717278778]]
				Gradient Difference = [0.0356643185736657, 0.8740731829325501]
				|| Gradient || = 6.197949980340117
				||X optimum - X|| = 0.24876223484541687
				Rho = 182.48388850045978
				alpha = [0.1471952 0.0002635]
			Iteration 7:
				X = [3.8984369501459732, -0.001144343389967526]
				Gradient = [-0.023472052963843765, -5.323594672669219]
				Hessian = [[3.6165898558577525, 0.004451122132260279], [0.004451122132260281, 0.00018788341801254305]]
				Gradient Difference = [0.026586631961438834, 4.102793299127904]
				|| Gradient || = 5.323646417272885
				||X optimum - X|| = 0.10156949649105132
				Rho = 149.47548874547368
				alpha = [0.11441498 0.00088919]
			Iteration 8:
				X = [4.012851927656974, -0.0002551562155825985]
				Gradient = [0.0031145789975950697, -1.2208013735413152]
				Hessian = [[3.8660175718113408, -0.00042157600709025276], [-0.00042157600709025276, 0.00020731469303412483]]
				Gradient Difference = [-0.0013950230782894554, 1.0366696728627958]
				|| Gradient || = 1.220805346581794
				||X optimum - X|| = 0.012854460284058596
				Rho = 4318.8941989039395
				alpha = [-0.00583022  0.0002155 ]
			Iteration 9:
				X = [4.007021708861868, -3.965125231611733e-05]
				Gradient = [0.0017195559193056143, -0.1841317006785195]
				Hessian = [[3.994965793025858, -0.0008227761780873963], [-0.000822776178087398, 0.00020764205538327312]]
				Gradient Difference = [-0.001646245190994234, 0.18080941804735803]
				|| Gradient || = 0.18413972973620743
				||X optimum - X|| = 0.00702182081533296
				Rho = 55233.65770895549
				alpha = [-6.72545891e-03  3.88981305e-05]
			Iteration 10:
				X = [4.000296249954969, -7.5312179366944e-07]
				Gradient = [7.331072831138012e-05, -0.0033222826311614605]
				Hessian = [[4.002171191294025, -0.0008572453536683459], [-0.0008572453536683459, 0.00020777059816531489]]
				Gradient Difference = [-7.315303414464089e-05, 0.003308715585335803]
				|| Gradient || = 0.0033230913836671213
				||X optimum - X|| = 0.00029625091225465183
				Rho = 41482323.7551979
				alpha = [-2.95607347e-04  7.50163915e-07]
			Iteration 11:
				X = [4.000000642608097, -2.9578787180847806e-09]
				Gradient = [1.5769416673923096e-07, -1.3567045825657604e-05]
				Hessian = [[4.000272244489567, -0.0008689647928030887], [-0.0008689647928030887, 0.00020791843128706728]]
				Gradient Difference = [-1.5773333984839602e-07, 1.3548347214115606e-05]
				|| Gradient || = 1.3567962259886965e-05
				||X optimum - X|| = 6.426149048160398e-07
				Rho = 7071884129229.432
				alpha = [-6.42749338e-07  2.95401582e-09]
			Iteration 12:
				X = [3.999999999858759, -3.862899813854707e-12]
				Gradient = [-3.917310916506123e-11, -1.8698611541996652e-08]
				Hessian = [[4.002455749630901, -0.0008315179591091041], [-0.0008315179591091024, 0.00020832954106830547]]
				Gradient Difference = [3.8967495860900854e-11, 1.8653850428849226e-08]
				|| Gradient || = 1.8698652575278575e-08
				||X optimum - X|| = 1.4129361162427862e-10
				Rho = 1.2926515764128883e+19
				alpha = [1.40454666e-10 3.85374593e-12]
	- Starting Point : [1.9 0.6]
	------------------------------
		- Quasi Newton:
			- BFGS Method:
			---------------
			Iteration 0:
				X = [1.9, 0.6]
				Gradient = [410.47499999999997, 650.0999999999999]
				Hessian = [[0.735791707505168, -0.4410501876758149], [-0.4410501876758149, 0.26567657001558653]]
				Gradient Difference = [-409.4241721423595, -682.109211991869]
				|| Gradient || = 768.8431150924093
				||X optimum - X|| = 2.1840329667841556
				Rho = 0.0016512607443926934
				alpha = [-0.40651475 -0.64382786]
			Iteration 1:
				X = [1.4934852498994662, -0.04382785563154157]
				Gradient = [1.0508278576404466, -32.00921199186901]
				Hessian = [[0.0073773928670443426, -0.002375605641463189], [-0.0023756056414631892, 0.001492595360774856]]
				Gradient Difference = [-1.2682278634781505, 42.31297142093267]
				|| Gradient || = 32.02645611875913
				||X optimum - X|| = 2.5068978984794734
				Rho = 0.3402342143698025
				alpha = [-0.10987515  0.06616895]
			Iteration 2:
				X = [1.3836101010910173, 0.022341098479081098]
				Gradient = [-0.21740000583770386, 10.30375942906366]
				Hessian = [[0.009269781913333488, -0.0032887622053371537], [-0.0032887622053371537, 0.001902745393308646]]
				Gradient Difference = [-0.38859505665603583, -9.025798721462584]
				|| Gradient || = 10.306052645632882
				||X optimum - X|| = 2.616485281402173
				Rho = 7.499785564637146
				alpha = [ 0.02608151 -0.0158958 ]
			Iteration 3:
				X = [1.409691615371343, 0.0064452982763983195]
				Gradient = [-0.6059950624937397, 1.2779607076010766]
				Hessian = [[0.013000752110867259, -0.003968566595460104], [-0.003968566595460104, 0.0017579378387536258]]
				Gradient Difference = [-0.021314716159138603, -1.3367866954722887]
				|| Gradient || = 1.414359779525364
				||X optimum - X|| = 2.590316403327477
				Rho = 342.3268895480139
				alpha = [ 0.00502802 -0.0022654 ]
			Iteration 4:
				X = [1.4147196350551514, 0.004179899232626034]
				Gradient = [-0.6273097786528783, -0.05882598787121207]
				Hessian = [[0.02544269193987777, -0.005793640960265785], [-0.005793640960265785, 0.0017286175071257774]]
				Gradient Difference = [-0.012489441783807398, -1.4222160390841503]
				|| Gradient || = 0.6300619455597578
				||X optimum - X|| = 2.5852837439876817
				Rho = 303.52519180676853
				alpha = [ 0.00792204 -0.00238611]
			Iteration 5:
				X = [1.42264167913373, 0.0017937910300396148]
				Gradient = [-0.6397992204366857, -1.4810420269553624]
				Hessian = [[0.10259889948585058, -0.011414802220428386], [-0.011414802220428386, 0.0016912805569922066]]
				Gradient Difference = [-0.0016093325566062244, -0.6888165309464611]
				|| Gradient || = 1.6133284005680428
				||X optimum - X|| = 2.5773589450879477
				Rho = 1286.3106562786818
				alpha = [ 0.00769759 -0.00114661]
			Iteration 6:
				X = [1.4303392678514308, 0.0006471792367556011]
				Gradient = [-0.6414085529932919, -2.1698585579018235]
				Hessian = [[0.23803548183217293, -0.016215285348989954], [-0.016215285348989954, 0.00147325117177582]]
				Gradient Difference = [0.014218136642998425, -2.322184504076215]
				|| Gradient || = 2.262673439352822
				||X optimum - X|| = 2.5696608136458954
				Rho = 110.3332384903916
				alpha = [ 0.04103931 -0.00365171]
			Iteration 7:
				X = [1.4713785732246012, -0.0030045329477514835]
				Gradient = [-0.6271904163502935, -4.4920430619780385]
				Hessian = [[0.5591740558315463, -0.018483065660813584], [-0.018483065660813584, 0.0009907459337785457]]
				Gradient Difference = [0.04751685825567353, -2.698882288834837]
				|| Gradient || = 4.535616682329613
				||X optimum - X|| = 2.528623211782627
				Rho = 75.64458376918604
				alpha = [ 0.07645381 -0.00355216]
			Iteration 8:
				X = [1.54783238613114, -0.0065566968122967185]
				Gradient = [-0.57967355809462, -7.190925350812876]
				Hessian = [[1.2398191583921114, -0.01221414071886915], [-0.01221414071886915, 0.0005155280709480146]]
				Gradient Difference = [0.11171467916379585, -4.316477992974027]
				|| Gradient || = 7.2142517862157645
				||X optimum - X|| = 2.452176379622882
				Rho = 27.131062659709183
				alpha = [ 0.19122807 -0.00358976]
			Iteration 9:
				X = [1.7390604552481288, -0.0101464611969741]
				Gradient = [-0.4679588789308241, -11.507403343786903]
				Hessian = [[4.034805547915622, 0.020323008085016494], [0.020323008085016494, 0.0005469212520277272]]
				Gradient Difference = [0.1315943315837541, -4.49373434670723]
				|| Gradient || = 11.516914397049591
				||X optimum - X|| = 2.26096231187024
				Rho = 17.581082944110165
				alpha = [4.3963134e-01 2.1667385e-04]
			Iteration 10:
				X = [2.1786917949364604, -0.009929787347436242]
				Gradient = [-0.33636454734707, -16.001137690494133]
				Hessian = [[3.710236599595264, 0.006486219911999927], [0.006486219911999927, 0.00031838321424325225]]
				Gradient Difference = [0.38143364281902686, 41.1869677765809]
				|| Gradient || = 16.004672708270668
				||X optimum - X|| = 1.8213352735036286
				Rho = 0.7789974972999362
				alpha = [1.68235679 0.0155873 ]
			Iteration 11:
				X = [3.86104858734792, 0.00565751432736428]
				Gradient = [0.04506909547195688, 25.18583008608677]
				Hessian = [[2.7814530442115237, -0.006446260101999791], [-0.006446260101999793, 0.00025516938165667477]]
				Gradient Difference = [-0.13211018441487635, -24.18277488944817]
				|| Gradient || = 25.185870410779934
				||X optimum - X|| = 0.1390665399956905
				Rho = 6.386478498886781
				alpha = [-0.21156982 -0.00531909]
			Iteration 12:
				X = [3.6494787696613082, 0.0003384272229426822]
				Gradient = [-0.08704108894291947, 1.0030551966386037]
				Hessian = [[3.9331073983611367, -0.001900341321906071], [-0.0019003413219060693, 0.00021284162149067621]]
				Gradient Difference = [0.061609586420973445, -3.2886388732501155]
				|| Gradient || = 1.0068246514006682
				||X optimum - X|| = 0.3505213937139008
				Rho = 55.552366265749804
				alpha = [ 0.24856666 -0.00081704]
			Iteration 13:
				X = [3.898045426167273, -0.00047861125023846167]
				Gradient = [-0.02543150252194602, -2.285583676611512]
				Hessian = [[4.087659554610304, -0.0008218128339267002], [-0.0008218128339267002, 0.00021947835755887308]]
				Gradient Difference = [0.023826672098692277, 2.085489752490482]
				|| Gradient || = 2.285725159356111
				||X optimum - X|| = 0.10195569721276923
				Rho = 313.1356345879194
				alpha = [0.09568144 0.00043814]
			Iteration 14:
				X = [3.99372686778244, -4.047244957645853e-05]
				Gradient = [-0.0016048304232537415, -0.20009392412103033]
				Hessian = [[4.078439348662666, -0.001345764302069244], [-0.001345764302069244, 0.00021290786049662288]]
				Gradient Difference = [0.0016375733369348707, 0.21042531365376976]
				|| Gradient || = 0.2001003596969282
				||X optimum - X|| = 0.006273262774519058
				Rho = 51448.86659588775
				alpha = [6.39556066e-03 4.25974156e-05]
			Iteration 15:
				X = [4.000122428440749, 2.1249660090290437e-06]
				Gradient = [3.2742913681129086e-05, 0.01033138953273944]
				Hessian = [[4.109722440693016, -0.001163179276480417], [-0.0011631792764804187, 0.0002093317354489326]]
				Gradient Difference = [-3.2075498114917844e-05, -0.01047561826677724]
				|| Gradient || = 0.010331441418098173
				||X optimum - X|| = 0.00012244688066557802
				Rho = 37852516.833229594
				alpha = [-1.19636372e-04 -2.15556980e-06]
			Iteration 16:
				X = [4.000002792068425, -3.060378796591619e-08]
				Gradient = [6.674155662112449e-07, -0.00014422873403780037]
				Hessian = [[4.028670391636792, -0.0007122480946182303], [-0.0007122480946182303, 0.00020891139100827913]]
				Gradient Difference = [-6.966984233650956e-07, 0.0001458597010029948]
				|| Gradient || = 0.0001442302782555888
				||X optimum - X|| = 2.792236143966928e-06
				Rho = 152792369236.91544
				alpha = [-2.91065660e-06  3.09679752e-08]
			Iteration 17:
				X = [3.999999881411821, 3.6418718723646015e-10]
				Gradient = [-2.928285715385066e-08, 1.6309669651944288e-06]
				Hessian = [[4.006767773737909, -0.0007708791276438125], [-0.0007708791276438125, 0.00020946906638754796]]
				Gradient Difference = [2.9421573747634107e-08, -1.6179179357615628e-06]
				|| Gradient || = 1.6312298204969825e-06
				||X optimum - X|| = 1.1858873804491357e-07
				Rho = 244493806286004.7
				alpha = [ 1.19132633e-07 -3.61584237e-10]
			Iteration 18:
				X = [4.000000000544454, 2.6029506363324995e-12]
				Gradient = [1.387165937834461e-10, 1.3049029432865988e-08]
				Hessian = [[4.0059261738139655, -0.0008607778251211173], [-0.0008607778251211173, 0.00020862327297847144]]
				Gradient Difference = [-1.390630943894303e-10, -1.316313695254459e-08]
				|| Gradient || = 1.3049766719493253e-08
				||X optimum - X|| = 5.444604815689273e-10
				Rho = 9.052621832815918e+18
				alpha = [-5.45745953e-10 -2.62643429e-12]